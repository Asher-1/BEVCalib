#!/usr/bin/env python3
"""
BEVCalib è‡ªå®šä¹‰æ•°æ®é›†å‡†å¤‡è„šæœ¬ï¼ˆæµå¼å¤„ç†ç‰ˆæœ¬ï¼‰

ä» rosbag å’Œé…ç½®æ–‡ä»¶æå–æ•°æ®ï¼Œè½¬æ¢ä¸º BEVCalib è®­ç»ƒæ ¼å¼ã€‚
é‡‡ç”¨æµå¼å¤„ç†ï¼Œå‡å°‘å†…å­˜å ç”¨ã€‚

ä½¿ç”¨æ–¹æ³•:
    python prepare_custom_dataset.py \\
        --bag_dir /path/to/bags \\
        --config_dir /path/to/config \\
        --output_dir /path/to/output \\
        --camera_name traffic_2 \\
        --target_fps 10.0
"""

import os
import re
import argparse
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from PIL import Image
import cv2
from tqdm import tqdm
from scipy.spatial.transform import Rotation as R, Slerp
import struct
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp
import time
from datetime import timedelta


@dataclass
class ImageMetadata:
    """å›¾åƒå…ƒæ•°æ®ï¼ˆä¸åŒ…å«å›¾åƒæ•°æ®ï¼‰"""
    timestamp: float
    file_path: str


@dataclass
class PointCloudMetadata:
    """ç‚¹äº‘å…ƒæ•°æ®ï¼ˆä¸åŒ…å«ç‚¹äº‘æ•°æ®ï¼‰"""
    timestamp: float
    file_path: str


@dataclass
class PoseMetadata:
    """ä½å§¿å…ƒæ•°æ®ï¼ˆSensingç³»åœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
    
    æ³¨æ„ï¼šä¸C++å¯¹é½ï¼Œå­˜å‚¨çš„æ˜¯ Sensingâ†’World å˜æ¢
    - å«ä¹‰ï¼šSensingç³»åœ¨Worldç³»ä¸­çš„ä½å§¿
    - ä½œç”¨ï¼šå°†Sensingç³»çš„ç‚¹å˜æ¢åˆ°Worldç³»
    
    C++å‚è€ƒï¼šlidar_online_calibrator.cpp:849-852
        sensing_pose.second = vehicle_pose * iso_vehicle_sensing_;
        å…¶ä¸­ï¼švehicle_pose = Vehicleâ†’World
              iso_vehicle_sensing_ = Sensingâ†’Vehicle
              ç»“æœï¼šsensing_pose = Sensingâ†’World
    """
    timestamp: float
    position: np.ndarray  # (3,) xyz - Sensingåœ¨Worldç³»ä¸­çš„ä½ç½®
    orientation: np.ndarray  # (4,) quaternion (x, y, z, w) - Sensingåœ¨Worldç³»ä¸­çš„å§¿æ€


class UndistortionUtils:
    """ç‚¹äº‘å»ç•¸å˜å·¥å…·ç±»"""
    
    @staticmethod
    def quat_to_matrix(q):
        """å››å…ƒæ•°è½¬æ—‹è½¬çŸ©é˜µ (x, y, z, w)"""
        x, y, z, w = q
        return np.array([
            [1 - 2*(y**2 + z**2), 2*(x*y - w*z), 2*(x*z + w*y)],
            [2*(x*y + w*z), 1 - 2*(x**2 + z**2), 2*(y*z - w*x)],
            [2*(x*z - w*y), 2*(y*z + w*x), 1 - 2*(x**2 + y**2)]
        ])
    
    @staticmethod
    def isometry_to_vec6(R_mat, t):
        """å°†æ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡è½¬æ¢ä¸º6Då‘é‡ [rx, ry, rz, tx, ty, tz]"""
        # ä½¿ç”¨Rodrigueså…¬å¼ï¼šR -> angle-axis
        r = R.from_matrix(R_mat).as_rotvec()
        return np.concatenate([r, t])
    
    @staticmethod
    def vec6_to_isometry(v):
        """å°†6Då‘é‡è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡"""
        r_vec = v[:3]
        t = v[3:6]
        R_mat = R.from_rotvec(r_vec).as_matrix()
        return R_mat, t
    
    @staticmethod
    def motion_interpolate(poses: List[PoseMetadata], timestamp: float):
        """ä½å§¿æ’å€¼ï¼ˆä¸¥æ ¼å‚è€ƒC++çš„motion_interpolateå®ç°ï¼‰
        
        Args:
            poses: ä½å§¿åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰
            timestamp: ç›®æ ‡æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            
        Returns:
            (R, t): æ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡ï¼Œå¦‚æœå¤±è´¥è¿”å›None
            
        Note:
            å‚è€ƒ math_utils.cpp:313-346
            C++ç‰ˆæœ¬åªæ”¯æŒæ’å€¼ï¼Œä¸æ”¯æŒå¤–æ¨ã€‚æ—¶é—´æˆ³è¶…å‡ºèŒƒå›´ç›´æ¥è¿”å›falseã€‚
        """
        if not poses or len(poses) < 2:
            return None
        
        # æŸ¥æ‰¾timestampå‰åçš„ä¸¤ä¸ªä½å§¿è¿›è¡Œæ’å€¼ï¼ˆä¸¥æ ¼æŒ‰ç…§C++é€»è¾‘ï¼‰
        for i in range(len(poses) - 1):
            t1 = poses[i].timestamp
            t2 = poses[i + 1].timestamp
            
            # åªåœ¨èŒƒå›´å†…æ’å€¼ï¼ˆå¯¹åº”C++çš„ if (t1 <= t && t2 >= t)ï¼‰
            if t1 <= timestamp <= t2:
                # è®¡ç®—æ’å€¼ç³»æ•°
                alpha = (timestamp - t1) / (t2 - t1)
                break
        else:
            # æ—¶é—´æˆ³ä¸åœ¨ä»»ä½•åŒºé—´å†…ï¼Œè¿”å›Noneï¼ˆå¯¹åº”C++çš„return falseï¼‰
            return None
        
        # ä½å§¿1
        R1 = UndistortionUtils.quat_to_matrix(poses[i].orientation)
        t1_vec = poses[i].position
        
        # ä½å§¿2
        R2 = UndistortionUtils.quat_to_matrix(poses[i + 1].orientation)
        t2_vec = poses[i + 1].position
        
        # è®¡ç®—ç›¸å¯¹è¿åŠ¨
        R_delta = R1.T @ R2
        t_delta = R1.T @ (t2_vec - t1_vec)
        
        # è½¬æ¢ä¸º6Då‘é‡å¹¶æ’å€¼/å¤–æ¨
        v_delta = UndistortionUtils.isometry_to_vec6(R_delta, t_delta)
        v_interp = v_delta * alpha
        
        # è½¬æ¢å›çŸ©é˜µ
        R_interp, t_interp = UndistortionUtils.vec6_to_isometry(v_interp)
        
        # åº”ç”¨åˆ°pose1
        R_result = R1 @ R_interp
        t_result = t1_vec + R1 @ t_interp
        
        return R_result, t_result
    
    @staticmethod
    def motion_extrapolate(poses: List[PoseMetadata], timestamp: float):
        """ä½å§¿å¤–æ¨ï¼ˆç”¨äºæ—¶é—´æˆ³è¶…å‡ºèŒƒå›´çš„æƒ…å†µï¼‰
        
        Args:
            poses: ä½å§¿åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰
            timestamp: ç›®æ ‡æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            
        Returns:
            (R, t): æ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡ï¼Œå¦‚æœå¤±è´¥è¿”å›None
            
        Note:
            å½“timestampåœ¨poseèŒƒå›´å¤–æ—¶ï¼Œä½¿ç”¨æœ€è¿‘çš„ä¸¤ä¸ªposeè¿›è¡Œå¤–æ¨
            å¤–æ¨ä½¿ç”¨ä¸æ’å€¼ç›¸åŒçš„æ•°å­¦å…¬å¼ï¼Œä½†alphaä¼šè¶…å‡º[0,1]èŒƒå›´
        """
        if not poses or len(poses) < 2:
            return None
        
        # ç¡®å®šå¤–æ¨æ–¹å‘å’Œä½¿ç”¨çš„poseå¯¹
        if timestamp < poses[0].timestamp:
            # å‘å‰å¤–æ¨ï¼šä½¿ç”¨å‰ä¸¤ä¸ªpose
            i = 0
            t1 = poses[0].timestamp
            t2 = poses[1].timestamp
        elif timestamp > poses[-1].timestamp:
            # å‘åå¤–æ¨ï¼šä½¿ç”¨åä¸¤ä¸ªpose
            i = len(poses) - 2
            t1 = poses[i].timestamp
            t2 = poses[i + 1].timestamp
        else:
            # åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥ä½¿ç”¨æ’å€¼
            return None
        
        # è®¡ç®—å¤–æ¨ç³»æ•°ï¼ˆä¼šè¶…å‡º[0,1]èŒƒå›´ï¼‰
        if t2 == t1:
            return None
        alpha = (timestamp - t1) / (t2 - t1)
        
        # ä½å§¿1
        R1 = UndistortionUtils.quat_to_matrix(poses[i].orientation)
        t1_vec = poses[i].position
        
        # ä½å§¿2
        R2 = UndistortionUtils.quat_to_matrix(poses[i + 1].orientation)
        t2_vec = poses[i + 1].position
        
        # è®¡ç®—ç›¸å¯¹è¿åŠ¨
        R_delta = R1.T @ R2
        t_delta = R1.T @ (t2_vec - t1_vec)
        
        # è½¬æ¢ä¸º6Då‘é‡å¹¶å¤–æ¨
        v_delta = UndistortionUtils.isometry_to_vec6(R_delta, t_delta)
        v_extrap = v_delta * alpha  # alphaå¯ä»¥<0æˆ–>1
        
        # è½¬æ¢å›çŸ©é˜µ
        R_extrap, t_extrap = UndistortionUtils.vec6_to_isometry(v_extrap)
        
        # åº”ç”¨åˆ°pose1
        R_result = R1 @ R_extrap
        t_result = t1_vec + R1 @ t_extrap
        
        return R_result, t_result
    
    @staticmethod
    def undistort_pointcloud(points_raw: np.ndarray,
                            cloud_timestamp: float,
                            target_timestamp: float,
                            poses: List[PoseMetadata],
                            debug: bool = False) -> np.ndarray:
        """ç‚¹äº‘å»ç•¸å˜ï¼ˆå®Œå…¨å¯¹é½C++å®ç°ï¼‰
        
        å‚è€ƒ: ~/codetree/repo/calibration/modules/calib_utils/src/math_utils.cpp:169-252
        
        âœ… å…³é”®å‡è®¾ï¼ˆä¸C++ä¸€è‡´ï¼‰ï¼š
            1. è¾“å…¥posesæ˜¯ Sensingâ†’World å˜æ¢ï¼ˆSensingåœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
            2. LiDARç³» = Sensingç³»ï¼ˆiso_vehicle_lidar = Identityï¼‰
        
        ğŸ¯ å»ç•¸å˜åŸç†ï¼š
            - å°†ç‚¹äº‘ä»æ¿€å…‰é›·è¾¾æ‰«ææ—¶åˆ»(cloud_timestamp)è½¬æ¢åˆ°ç›®æ ‡æ—¶åˆ»(target_timestamp)
            - ç›®çš„ï¼šæ¶ˆé™¤è½¦è¾†è¿åŠ¨é€ æˆçš„ç‚¹äº‘ç•¸å˜ï¼Œä½¿ç‚¹äº‘ä¸å›¾åƒåœ¨ç©ºé—´ä¸Šå¯¹é½
            - è¾“å‡ºçš„ç‚¹äº‘åœ¨é€»è¾‘ä¸Šå¯¹åº”äºtarget_timestampæ—¶åˆ»çš„LiDARåæ ‡ç³»
        
        Args:
            points_raw: åŸå§‹ç‚¹äº‘ (N, 5): x, y, z, intensity, timestamp (LiDARåæ ‡ç³»)
                       å…¶ä¸­timestampå•ä½æ˜¯2å¾®ç§’
            cloud_timestamp: ç‚¹äº‘æ‰«æå¼€å§‹æ—¶åˆ»ï¼ˆç§’ï¼‰
            target_timestamp: ç›®æ ‡æ—¶åˆ»ï¼ˆé€šå¸¸æ˜¯å›¾åƒæ›å…‰æ—¶åˆ»ï¼Œç§’ï¼‰
            poses: GNSSä½å§¿åˆ—è¡¨ï¼ˆSensingâ†’Worldï¼Œå·²è½¬æ¢ï¼ï¼‰
            debug: æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
            
        Returns:
            å»ç•¸å˜åçš„ç‚¹äº‘ (N, 4): x, y, z, intensity
            âœ… ç©ºé—´ä½ç½®å¯¹åº”äºtarget_timestampæ—¶åˆ»çš„LiDARåæ ‡ç³»
            âœ… ä¸è¯¥æ—¶åˆ»çš„å›¾åƒå®Œå…¨å¯¹é½ï¼ˆæ—¶é—´å’Œç©ºé—´åŒé‡å¯¹é½ï¼‰
            âœ… ä¸åŒ…å«timestampï¼ˆæ‰€æœ‰ç‚¹å·²ç»Ÿä¸€åˆ°target_timestampï¼ŒåŸå§‹æ—¶é—´æˆ³å·²æ— æ„ä¹‰ï¼‰
            âœ… ç¬¦åˆKITTIæ ‡å‡†æ ¼å¼
        
        C++å‚è€ƒï¼š
            - math_utils.cpp:184-188: lidar_pose_data = vehicle_poses * iso_vehicle_lidar
            - math_utils.cpp:200: delta_stamp = max_inner_stamp * 2 (å•ä½:2us)
            - math_utils.cpp:215: dt = timestamp * 2.0e-6 (å•ä½:2us)
        """
        if points_raw.shape[1] < 5:
            # æ²¡æœ‰timestampï¼Œæ— æ³•å»ç•¸å˜ï¼Œç›´æ¥è¿”å›å‰4åˆ—
            return points_raw[:, :4]
        
        if not poses or len(poses) == 0:
            # æ²¡æœ‰ä½å§¿æ•°æ®ï¼Œæ— æ³•å»ç•¸å˜
            return points_raw[:, :4]
        
        # æ‰¾åˆ°ç‚¹äº‘æ‰«æçš„æœ€å¤§å†…éƒ¨æ—¶é—´æˆ³ï¼ˆå•ä½ï¼š2å¾®ç§’ï¼‰
        # C++å‚è€ƒï¼šmath_utils.cpp:190-200
        max_inner_timestamp_2us = points_raw[:, 4].max()
        delta_time_us = max_inner_timestamp_2us * 2  # è½¬æ¢ä¸ºå¾®ç§’
        end_timestamp = cloud_timestamp + delta_time_us * 1e-6  # è½¬æ¢ä¸ºç§’
        
        # æ’å€¼è·å–ä¸‰ä¸ªå…³é”®æ—¶åˆ»çš„ä½å§¿ï¼ˆSensingâ†’Worldå˜æ¢ï¼‰
        # C++å‚è€ƒï¼šmath_utils.cpp:198-205
        start_pose = UndistortionUtils.motion_interpolate(poses, cloud_timestamp)
        end_pose = UndistortionUtils.motion_interpolate(poses, end_timestamp)
        target_pose = UndistortionUtils.motion_interpolate(poses, target_timestamp)
        
        if start_pose is None or end_pose is None or target_pose is None:
            # æ’å€¼å¤±è´¥ï¼Œè¿”å›åŸå§‹ç‚¹äº‘ï¼ˆå»æ‰timestampï¼‰
            # C++å‚è€ƒï¼šmath_utils.cpp:247-250
            print(f"âš ï¸  å»ç•¸å˜å¤±è´¥ï¼šæ’å€¼è¿”å›None")
            print(f"  cloud_ts={cloud_timestamp:.6f}, end_ts={end_timestamp:.6f}, target_ts={target_timestamp:.6f}")
            print(f"  start_pose={'æœ‰æ•ˆ' if start_pose else 'None'}, end_pose={'æœ‰æ•ˆ' if end_pose else 'None'}, target_pose={'æœ‰æ•ˆ' if target_pose else 'None'}")
            return points_raw[:, :4]
        
        R_start, t_start = start_pose  # Sensingâ†’Worldï¼ˆå·²è½¬æ¢ï¼ï¼‰
        R_end, t_end = end_pose
        R_target, t_target = target_pose
        
        # ğŸ” DEBUG: æ‰“å°poseä¿¡æ¯
        if debug:
            print(f"\nğŸ” å»ç•¸å˜è°ƒè¯•ä¿¡æ¯ (å®Œå…¨å¯¹é½C++):")
            print(f"  cloud_ts={cloud_timestamp:.6f}, target_ts={target_timestamp:.6f}, delta={end_timestamp-cloud_timestamp:.6f}s")
            print(f"  å‡è®¾ï¼šLiDARç³» = Sensingç³» (iso_vehicle_lidar = Identity)")
            print(f"  start_pose (Sensingâ†’World): t=[{t_start[0]:.2f}, {t_start[1]:.2f}, {t_start[2]:.2f}]")
            print(f"  end_pose (Sensingâ†’World): t=[{t_end[0]:.2f}, {t_end[1]:.2f}, {t_end[2]:.2f}]")
            print(f"  target_pose (Sensingâ†’World): t=[{t_target[0]:.2f}, {t_target[1]:.2f}, {t_target[2]:.2f}]")
        
        R_lidar_start = R_start
        t_lidar_start = t_start
        R_lidar_end = R_end
        t_lidar_end = t_end
        R_lidar_target = R_target
        t_lidar_target = t_target
        
        # è®¡ç®—è¿åŠ¨å¢é‡ï¼ˆLiDARåæ ‡ç³»ï¼‰
        # âœ… æœ€ç»ˆä¿®å¤ï¼šå»ç•¸å˜å˜æ¢ï¼ˆå¯¹é½C++é€»è¾‘ï¼‰
        # 
        # C++ä¸­poseçš„å«ä¹‰ï¼š
        # - lidar_pose = (Vehicleâ†’World) @ (LiDARâ†’Vehicle) = LiDARâ†’World
        # 
        # å»ç•¸å˜æµç¨‹ï¼š
        # 1. ç‚¹påœ¨(start+dt)æ—¶åˆ»çš„LiDARç³»
        # 2. å˜æ¢åˆ°Worldç³»ï¼šP_world = LiDARâ†’World(start+dt) * p
        # 3. å˜æ¢åˆ°targetæ—¶åˆ»çš„LiDARç³»ï¼špu = Worldâ†’LiDAR(target) * P_world
        #                              = Worldâ†’LiDAR(target) * LiDARâ†’World(start+dt) * p
        # 
        # å…¶ä¸­ï¼šLiDARâ†’World(start+dt) â‰ˆ LiDARâ†’World(start) * exp(v*dt)
        # 
        # C++å®ç°ï¼š
        # - delta = inv(start) * end  ï¼ˆä»startåˆ°endçš„è¿åŠ¨ï¼‰
        # - iso_target_start = inv(target) * start  ï¼ˆä»startçš„LiDARåˆ°targetçš„LiDARï¼‰
        # - delta2 = iso_target_start * delta2  ï¼ˆç»„åˆå˜æ¢ï¼‰
        # - pu = delta2 * p  ï¼ˆåº”ç”¨åˆ°ç‚¹ï¼‰
        
        # delta = inv(start) * end ï¼ˆä»startåˆ°endçš„è¿åŠ¨ï¼‰
        R_delta = R_lidar_start.T @ R_lidar_end
        t_delta = R_lidar_start.T @ (t_lidar_end - t_lidar_start)
        v_full = UndistortionUtils.isometry_to_vec6(R_delta, t_delta)
        v_per_second = v_full / (delta_time_us * 1e-6)
        
        # iso_target_start = inv(target) * start ï¼ˆä»startçš„LiDARåˆ°targetçš„LiDARï¼‰
        R_target_start = R_lidar_target.T @ R_lidar_start  # âœ… æ¢å¤ï¼štarget^{-1} * start
        t_target_start = R_lidar_target.T @ (t_lidar_start - t_lidar_target)  # âœ… æ¢å¤
        
        # å‘é‡åŒ–å¤„ç†æ‰€æœ‰ç‚¹
        xyz = points_raw[:, :3]  # (N, 3) LiDARåæ ‡ç³»
        intensity = points_raw[:, 3:4]  # (N, 1)
        ts_us = points_raw[:, 4]  # (N,)
        
        # è®¡ç®—æ¯ä¸ªç‚¹çš„æ—¶é—´åç§»ï¼ˆç§’ï¼‰
        dt = ts_us * 2.0e-6  # (N,) uint: 2us
        
        # è®¡ç®—æ¯ä¸ªç‚¹çš„è¿åŠ¨å¢é‡ v2 = v * dt
        v_points = v_per_second[np.newaxis, :] * dt[:, np.newaxis]  # (N, 6)
        r_vecs = v_points[:, :3]  # (N, 3)
        t_vecs = v_points[:, 3:6]  # (N, 3)
        
        # æ‰¹é‡è®¡ç®—delta2 (å¯¹åº”C++çš„Vec2Isometry)
        R_delta2 = R.from_rotvec(r_vecs).as_matrix()  # (N, 3, 3)
        
        # âœ… æœ€ç»ˆä¿®å¤ï¼šdelta2 = iso_target_start * delta2ï¼ˆå®Œå…¨å¯¹é½C++ï¼‰
        # 
        # å…³é”®ç†è§£ï¼šdelta2ä¸æ˜¯LiDARç³»ä¸­çš„å¢é‡ï¼Œè€Œæ˜¯poseçš„å³ä¹˜å¢é‡
        # å³ï¼špose(start+dt) = pose(start) * delta2
        # å…¶ä¸­poseè¡¨ç¤ºLiDARâ†’Worldçš„å˜æ¢
        # 
        # æ‰€ä»¥æœ€ç»ˆå˜æ¢ï¼š
        # delta2_final = iso_target_start * delta2
        #              = [inv(target) * start] * delta2
        #              = inv(target) * [start * delta2]
        #              = inv(target) * (start+dt)
        #              = Worldâ†’LiDAR(target) * LiDARâ†’World(start+dt)
        # 
        # åº”ç”¨åˆ°ç‚¹ï¼š
        # pu = delta2_final * p
        #    = Worldâ†’LiDAR(target) * LiDARâ†’World(start+dt) * p
        # 
        # ç‰©ç†å«ä¹‰ï¼šç‚¹pä»(start+dt)æ—¶åˆ»çš„LiDARç³»å˜æ¢åˆ°targetæ—¶åˆ»çš„LiDARç³»
        
        # é½æ¬¡å˜æ¢çŸ©é˜µä¹˜æ³•ï¼šiso_target_start * delta2
        R_combined = np.einsum('ij,njk->nik', R_target_start, R_delta2)  # (N, 3, 3)
        t_combined = np.einsum('ij,nj->ni', R_target_start, t_vecs) + t_target_start  # (N, 3)
        
        # åº”ç”¨åˆ°ç‚¹ï¼špu = delta2 * p ï¼ˆå¯¹åº”C++ç¬¬225è¡Œï¼‰
        xyz_undistorted = np.einsum('nij,nj->ni', R_combined, xyz) + t_combined  # (N, 3)
        
        # æ‹¼æ¥å¼ºåº¦ï¼ˆä¸ä¿ç•™timestampï¼‰
        # æ³¨æ„ï¼šå»ç•¸å˜åæ‰€æœ‰ç‚¹éƒ½åœ¨target_timestampæ—¶åˆ»ï¼ŒåŸå§‹timestampå·²æ— æ„ä¹‰
        # è¾“å‡ºæ ¼å¼ï¼š(N, 4) = [x, y, z, intensity]ï¼ˆç¬¦åˆKITTIæ ‡å‡†ï¼‰
        points_undistorted = np.hstack([xyz_undistorted, intensity])  # (N, 4)
        
        # ğŸ” DEBUG: æ‰“å°ç»“æœç»Ÿè®¡
        if debug:
            print(f"  Raw cloud:")
            print(f"    X: [{xyz[:, 0].min():.2f}, {xyz[:, 0].max():.2f}], mean={xyz[:, 0].mean():.2f}")
            print(f"    Y: [{xyz[:, 1].min():.2f}, {xyz[:, 1].max():.2f}], mean={xyz[:, 1].mean():.2f}")
            print(f"    Z: [{xyz[:, 2].min():.2f}, {xyz[:, 2].max():.2f}], mean={xyz[:, 2].mean():.2f}")
            print(f"  Undistorted cloud:")
            print(f"    X: [{xyz_undistorted[:, 0].min():.2f}, {xyz_undistorted[:, 0].max():.2f}], mean={xyz_undistorted[:, 0].mean():.2f}")
            print(f"    Y: [{xyz_undistorted[:, 1].min():.2f}, {xyz_undistorted[:, 1].max():.2f}], mean={xyz_undistorted[:, 1].mean():.2f}")
            print(f"    Z: [{xyz_undistorted[:, 2].min():.2f}, {xyz_undistorted[:, 2].max():.2f}], mean={xyz_undistorted[:, 2].mean():.2f}")
            diff = xyz_undistorted - xyz
            print(f"  Difference (mean Â± std):")
            print(f"    X: {diff[:, 0].mean():.3f} Â± {diff[:, 0].std():.3f}m")
            print(f"    Y: {diff[:, 1].mean():.3f} Â± {diff[:, 1].std():.3f}m")
            print(f"    Z: {diff[:, 2].mean():.3f} Â± {diff[:, 2].std():.3f}m\n")
        
        return points_undistorted.astype(np.float32)


class ConfigParser:
    """é…ç½®æ–‡ä»¶è§£æå™¨"""
    
    @staticmethod
    def parse_cameras_cfg(filepath: str) -> Dict:
        """è§£æ cameras.cfg æ–‡ä»¶"""
        with open(filepath, 'r') as f:
            content = f.read()
        
        cameras = {}
        config_pattern = r'config\s*\{(.*?)\n\}'
        config_blocks = re.findall(config_pattern, content, re.DOTALL)
        
        for block in config_blocks:
            camera = ConfigParser._parse_camera_block(block)
            if camera:
                cameras[camera['camera_dev']] = camera
        
        return cameras
    
    @staticmethod
    def _parse_camera_block(block: str) -> Optional[Dict]:
        """è§£æå•ä¸ªç›¸æœºé…ç½®å—"""
        
        def get_value(pattern, text, default=None):
            match = re.search(pattern, text)
            return match.group(1).strip().strip('"') if match else default
        
        def get_float(pattern, text, default=0.0):
            val = get_value(pattern, text)
            return float(val) if val is not None else default
        
        def get_int(pattern, text, default=0):
            val = get_value(pattern, text)
            return int(val) if val is not None else default
        
        camera_dev = get_value(r'camera_dev:\s*"([^"]+)"', block)
        if not camera_dev:
            return None
        
        pos_x = get_float(r'position\s*\{[^}]*x:\s*([-\d.e]+)', block)
        pos_y = get_float(r'position\s*\{[^}]*y:\s*([-\d.e]+)', block)
        pos_z = get_float(r'position\s*\{[^}]*z:\s*([-\d.e]+)', block)
        
        ori_qx = get_float(r'orientation\s*\{[^}]*qx:\s*([-\d.e]+)', block)
        ori_qy = get_float(r'orientation\s*\{[^}]*qy:\s*([-\d.e]+)', block)
        ori_qz = get_float(r'orientation\s*\{[^}]*qz:\s*([-\d.e]+)', block)
        ori_qw = get_float(r'orientation\s*\{[^}]*qw:\s*([-\d.e]+)', block)
        
        intrinsic = {
            'img_width': get_int(r'img_width:\s*(\d+)', block, 1920),
            'img_height': get_int(r'img_height:\s*(\d+)', block, 1080),
            'f_x': get_float(r'f_x:\s*([-\d.e]+)', block),
            'f_y': get_float(r'f_y:\s*([-\d.e]+)', block),
            'o_x': get_float(r'o_x:\s*([-\d.e]+)', block),
            'o_y': get_float(r'o_y:\s*([-\d.e]+)', block),
        }
        
        # è§£æç•¸å˜ç³»æ•°ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        # å®é™…é…ç½®æ ¼å¼éƒ½æ˜¯å¸¦ä¸‹åˆ’çº¿çš„ï¼šk_1, k_2, p_1, p_2
        # æ ¹æ®model_typeåŒºåˆ†ï¼š
        # - PINHOLE: k_1, k_2, p_1, p_2 (é’ˆå­”ç›¸æœºï¼Œæœ‰å¾„å‘å’Œåˆ‡å‘ç•¸å˜)
        # - KANNALA_BRANDT: k_1, k_2, k_3, k_4 (é±¼çœ¼ç›¸æœºï¼Œåªæœ‰å¾„å‘ç•¸å˜)
        
        # æå–æ¨¡å‹ç±»å‹
        model_type_raw = get_value(r'model_type:\s*(\w+)', block, 'PINHOLE')
        
        # æå–ç•¸å˜ç³»æ•°ï¼ˆå¸¦ä¸‹åˆ’çº¿ï¼‰
        k_1 = get_float(r'k_1:\s*([-\d.e]+)', block, None)
        k_2 = get_float(r'k_2:\s*([-\d.e]+)', block, None)
        p_1 = get_float(r'p_1:\s*([-\d.e]+)', block, None)
        p_2 = get_float(r'p_2:\s*([-\d.e]+)', block, None)
        k_3 = get_float(r'k_3:\s*([-\d.e]+)', block, None)
        k_4 = get_float(r'k_4:\s*([-\d.e]+)', block, None)
        
        if model_type_raw == 'KANNALA_BRANDT':
            # é±¼çœ¼æ¨¡å‹ï¼šåªæœ‰å¾„å‘ç•¸å˜ k_1, k_2, k_3, k_4
            distortion = {
                'k1': k_1 if k_1 is not None else 0.0,
                'k2': k_2 if k_2 is not None else 0.0,
                'k3': k_3 if k_3 is not None else 0.0,
                'k4': k_4 if k_4 is not None else 0.0,
                'model_type': 'fisheye',
            }
        else:
            # PINHOLEé’ˆå­”æ¨¡å‹ï¼šå¾„å‘ç•¸å˜ k_1, k_2 + åˆ‡å‘ç•¸å˜ p_1, p_2
            distortion = {
                'k1': k_1 if k_1 is not None else 0.0,
                'k2': k_2 if k_2 is not None else 0.0,
                'p1': p_1 if p_1 is not None else 0.0,
                'p2': p_2 if p_2 is not None else 0.0,
                'k3': 0.0,  # PINHOLEé€šå¸¸åªç”¨k1, k2
                'model_type': 'pinhole',
            }
        
        return {
            'camera_dev': camera_dev,
            'position': np.array([pos_x, pos_y, pos_z]),
            'orientation': np.array([ori_qx, ori_qy, ori_qz, ori_qw]),
            'intrinsic': intrinsic,
            'distortion': distortion
        }
    
    @staticmethod
    def parse_lidars_cfg(filepath: str) -> Dict:
        """è§£æ lidars.cfg æ–‡ä»¶ï¼ˆåŒ…å«vehicle_to_sensingå’Œsensor_to_lidarï¼‰"""
        with open(filepath, 'r') as f:
            content = f.read()
        
        def find_block(text, name):
            m = re.search(rf'{name}\s*\{{', text)
            if not m:
                return None
            start = m.end() - 1
            depth, i = 0, start
            while i < len(text):
                if text[i] == '{':
                    depth += 1
                elif text[i] == '}':
                    depth -= 1
                    if depth == 0:
                        return text[start + 1 : i]
                i += 1
            return None
        
        result = {}
        
        # 1. è§£ævehicle_to_sensingï¼ˆåœ¨æ ¹çº§åˆ«ï¼‰
        v2s_blk = find_block(content, 'vehicle_to_sensing')
        if v2s_blk:
            pos = find_block(v2s_blk, 'position')
            v2s_position = None
            if pos:
                x = re.search(r'x:\s*([-\d.e]+)', pos)
                y = re.search(r'y:\s*([-\d.e]+)', pos)
                z = re.search(r'z:\s*([-\d.e]+)', pos)
                if x and y and z:
                    v2s_position = np.array([float(x.group(1)), float(y.group(1)), float(z.group(1))])
            
            ori = find_block(v2s_blk, 'orientation')
            v2s_orientation = None
            if ori:
                qx = re.search(r'qx:\s*([-\d.e]+)', ori)
                qy = re.search(r'qy:\s*([-\d.e]+)', ori)
                qz = re.search(r'qz:\s*([-\d.e]+)', ori)
                qw = re.search(r'qw:\s*([-\d.e]+)', ori)
                if qx and qy and qz and qw:
                    v2s_orientation = [float(qx.group(1)), float(qy.group(1)), float(qz.group(1)), float(qw.group(1))]
            
            if v2s_position is not None and v2s_orientation is not None:
                result['vehicle_to_sensing'] = {
                    'position': v2s_position,
                    'orientation': v2s_orientation  # [qx, qy, qz, qw]
                }
        
        # 2. è§£æsensor_to_lidar
        blk = find_block(content, 'sensor_to_lidar')
        if not blk:
            config_blk = find_block(content, 'config')
            if config_blk:
                blk = find_block(config_blk, 'sensor_to_lidar')
            if not blk:
                raise ValueError(f'åœ¨ {filepath} ä¸­æœªæ‰¾åˆ° sensor_to_lidar')
        
        pos = find_block(blk, 'position')
        position = None
        if pos:
            x = re.search(r'x:\s*([-\d.e]+)', pos)
            y = re.search(r'y:\s*([-\d.e]+)', pos)
            z = re.search(r'z:\s*([-\d.e]+)', pos)
            if x and y and z:
                position = np.array([float(x.group(1)), float(y.group(1)), float(z.group(1))])
        
        ori = find_block(blk, 'orientation')
        orientation = None
        if ori:
            qx = re.search(r'qx:\s*([-\d.e]+)', ori)
            qy = re.search(r'qy:\s*([-\d.e]+)', ori)
            qz = re.search(r'qz:\s*([-\d.e]+)', ori)
            qw = re.search(r'qw:\s*([-\d.e]+)', ori)
            if qx and qy and qz and qw:
                orientation = np.array([
                    float(qx.group(1)), float(qy.group(1)),
                    float(qz.group(1)), float(qw.group(1))
                ])
        
        if position is None or orientation is None:
            raise ValueError(f'sensor_to_lidar çš„ position æˆ– orientation ä¸å®Œæ•´: {filepath}')
        
        # å°†sensor_to_lidarçš„positionå’Œorientationæ·»åŠ åˆ°resultä¸­
        result['position'] = position
        result['orientation'] = orientation
        
        return result


class PointCloudIO:
    """ç‚¹äº‘æ–‡ä»¶ I/O å·¥å…·"""
    
    @staticmethod
    def save_ply(points: np.ndarray, filepath: str):
        """ä¿å­˜ç‚¹äº‘ä¸º PLY æ ¼å¼ï¼ˆASCIIï¼Œæ–¹ä¾¿æŸ¥çœ‹å’Œå¯è§†åŒ–ï¼‰
        
        Args:
            points: (N, 3) æˆ– (N, 4) çš„ç‚¹äº‘æ•°æ®
            filepath: ä¿å­˜è·¯å¾„
        """
        if points.shape[1] == 3:
            # æ·»åŠ å¼ºåº¦é€šé“
            intensity = np.zeros((points.shape[0], 1), dtype=np.float32)
            points = np.hstack([points, intensity])
        
        with open(filepath, 'w') as f:
            # PLY header
            f.write("ply\n")
            f.write("format ascii 1.0\n")
            f.write(f"element vertex {points.shape[0]}\n")
            f.write("property float x\n")
            f.write("property float y\n")
            f.write("property float z\n")
            f.write("property float intensity\n")
            f.write("end_header\n")
            
            # ç‚¹äº‘æ•°æ®
            for point in points:
                f.write(f"{point[0]:.6f} {point[1]:.6f} {point[2]:.6f} {point[3]:.6f}\n")
    
    @staticmethod
    def load_ply(filepath: str) -> np.ndarray:
        """ä» PLY æ–‡ä»¶åŠ è½½ç‚¹äº‘
        
        Returns:
            (N, 4) çš„ç‚¹äº‘æ•°æ® [x, y, z, intensity]
        """
        with open(filepath, 'r') as f:
            # è¯»å– header
            line = f.readline()
            if not line.startswith('ply'):
                raise ValueError(f"ä¸æ˜¯æœ‰æ•ˆçš„ PLY æ–‡ä»¶: {filepath}")
            
            # è·³è¿‡ headerï¼Œæ‰¾åˆ° vertex æ•°é‡
            num_vertices = 0
            while True:
                line = f.readline()
                if line.startswith('element vertex'):
                    num_vertices = int(line.split()[-1])
                elif line.startswith('end_header'):
                    break
            
            # è¯»å–ç‚¹äº‘æ•°æ®
            points = []
            for _ in range(num_vertices):
                line = f.readline().strip()
                if line:
                    values = [float(v) for v in line.split()]
                    points.append(values[:4])  # x, y, z, intensity
            
            return np.array(points, dtype=np.float32)
    
    @staticmethod
    def ply_to_bin(ply_path: str, bin_path: str):
        """å°† PLY è½¬æ¢ä¸º BIN æ ¼å¼"""
        points = PointCloudIO.load_ply(ply_path)
        points.astype(np.float32).tofile(bin_path)


class ProtobufUtils:
    """Protobufæ¶ˆæ¯å¤„ç†å·¥å…·"""
    
    @staticmethod
    def extract_header_timestamp(data: bytes) -> Optional[float]:
        """ä»protobufæ¶ˆæ¯ä¸­æå–header.timestamp_sec()
        
        å‚è€ƒC++:
          image_msg.header().timestamp_sec()
          cloud_msg->header().timestamp_sec()
        
        Protobuf wire format:
          - field 1 (header): nested message
            - field 1 (timestamp_sec): double (64-bit)
        
        Args:
            data: protobufæ¶ˆæ¯çš„bytesæ•°æ®
            
        Returns:
            timestamp_sec (float)ï¼Œå¦‚æœè§£æå¤±è´¥è¿”å›None
        """
        # è·³è¿‡è‡ªå®šä¹‰header ($$$$å¼€å¤´)
        pos = 0
        if data.startswith(b'$$$$'):
            if len(data) < 8:
                return None
            # è¯»å–headeré•¿åº¦ï¼ˆ4å­—èŠ‚ï¼Œå°ç«¯ï¼‰
            header_len = struct.unpack('<I', data[4:8])[0]
            # è·³è¿‡ "$$$$" + é•¿åº¦å­—æ®µ + headerå†…å®¹
            pos = 8 + header_len
            if pos >= len(data):
                return None
        while pos < len(data):
            # è§£ætag
            if pos >= len(data):
                break
            tag = data[pos]
            pos += 1
            
            field_num = tag >> 3
            wire_type = tag & 7
            
            # field 1 æ˜¯ header (wire_type=2: length-delimited)
            if field_num == 1 and wire_type == 2:
                # è¯»å–é•¿åº¦
                length, pos_new = ProtobufUtils._decode_varint(data, pos)
                if pos_new >= len(data):
                    break
                pos = pos_new
                
                # è¯»å–headerå†…å®¹
                header_data = data[pos:pos+length]
                pos += length
                
                # åœ¨headerä¸­æŸ¥æ‰¾field 1 (timestamp_sec, wire_type=1: 64-bit)
                h_pos = 0
                while h_pos < len(header_data):
                    if h_pos >= len(header_data):
                        break
                    h_tag = header_data[h_pos]
                    h_pos += 1
                    
                    h_field_num = h_tag >> 3
                    h_wire_type = h_tag & 7
                    
                    if h_field_num == 1 and h_wire_type == 1:  # timestamp_sec (double)
                        if h_pos + 8 <= len(header_data):
                            timestamp_sec = struct.unpack('<d', header_data[h_pos:h_pos+8])[0]
                            return timestamp_sec
                        break
                    elif h_wire_type == 0:  # varint
                        _, h_pos = ProtobufUtils._decode_varint(header_data, h_pos)
                    elif h_wire_type == 1:  # 64-bit
                        h_pos += 8
                    elif h_wire_type == 2:  # length-delimited
                        l, h_pos = ProtobufUtils._decode_varint(header_data, h_pos)
                        h_pos += l
                    elif h_wire_type == 5:  # 32-bit
                        h_pos += 4
                    else:
                        break
                break
            elif wire_type == 0:  # varint
                _, pos = ProtobufUtils._decode_varint(data, pos)
            elif wire_type == 1:  # 64-bit
                pos += 8
            elif wire_type == 2:  # length-delimited
                length, pos = ProtobufUtils._decode_varint(data, pos)
                pos += length
            elif wire_type == 5:  # 32-bit
                pos += 4
            else:
                break
        
        return None
    
    @staticmethod
    def _decode_varint(buf: bytes, pos: int):
        """è§£æprotobuf varint"""
        n, sh = 0, 0
        while pos < len(buf):
            b = buf[pos]
            pos += 1
            n |= (b & 0x7F) << sh
            if not (b & 0x80):
                return n, pos
            sh += 7
            if sh >= 35:
                break
        return n, pos


class PointCloudParser:
    """ç‚¹äº‘è§£æå™¨ï¼ˆproto æ ¼å¼ï¼‰- å®Œå…¨å¯¹é½Self-Cali-GSå®ç°"""
    
    # DataType å¸¸é‡ï¼ˆä¸ PointCloud2.proto ä¸€è‡´ï¼‰
    _DT_INT8 = 1
    _DT_UINT8 = 2
    _DT_INT16 = 3
    _DT_UINT16 = 4
    _DT_INT32 = 5
    _DT_UINT32 = 6
    _DT_FLOAT32 = 7
    _DT_FLOAT64 = 8
    
    @staticmethod
    def _decode_varint(buf: bytes, pos: int):
        """è§£æ protobuf varint"""
        n, sh = 0, 0
        while pos < len(buf):
            b = buf[pos]
            pos += 1
            n |= (b & 0x7F) << sh
            if not (b & 0x80):
                return n, pos
            sh += 7
            if sh >= 35:
                break
        return n, pos
    
    @staticmethod
    def _parse_pointcloud2_wire(data: bytes):
        """æ‰‹åŠ¨è§£æ PointCloud2 protobuf wire format
        
        è¿”å›: (point_step, data_blob, fields_list)
          - point_step: æ¯ä¸ªç‚¹çš„å­—èŠ‚æ•°
          - data_blob: ç‚¹äº‘æ•°æ®
          - fields_list: [(name, offset, datatype), ...]
        """
        point_step = None
        data_blob = None
        fields_list = []
        pos = 0
        
        while pos < len(data):
            tag, pos = PointCloudParser._decode_varint(data, pos)
            if pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 0:  # Varint
                v, pos = PointCloudParser._decode_varint(data, pos)
                if field_num == 6:  # point_step
                    point_step = v
            elif wire == 2:  # Length-delimited
                L, pos = PointCloudParser._decode_varint(data, pos)
                if pos + L > len(data):
                    break
                chunk = data[pos:pos + L]
                pos += L
                
                if field_num == 4:  # fields (repeated PointField)
                    # è§£æ PointField æ¶ˆæ¯
                    i = 0
                    while i < len(chunk):
                        start_i = i
                        name, offset, datatype = None, 0, PointCloudParser._DT_FLOAT32
                        
                        # è§£æå•ä¸ª PointField
                        while i < len(chunk):
                            t, i = PointCloudParser._decode_varint(chunk, i)
                            if i >= len(chunk):
                                break
                            fn, w = t >> 3, t & 7
                            if w == 0:  # Varint
                                v, i = PointCloudParser._decode_varint(chunk, i)
                                if fn == 2:  # offset
                                    offset = v
                                elif fn == 3:  # datatype
                                    datatype = v
                            elif w == 2:  # Length-delimited (string)
                                ln, i = PointCloudParser._decode_varint(chunk, i)
                                if fn == 1 and i + ln <= len(chunk):  # name
                                    name = chunk[i:i + ln].decode('utf-8', errors='ignore').strip().lower()
                                i += ln
                            elif w == 5:  # Fixed32
                                if i + 4 > len(chunk):
                                    break
                                i += 4
                            elif w == 1:  # Fixed64
                                if i + 8 > len(chunk):
                                    break
                                i += 8
                            else:
                                break
                        
                        # ä¿å­˜æˆåŠŸè§£æçš„ PointField
                        if name and name in ('x', 'y', 'z'):
                            fields_list.append((name, offset, datatype))
                        
                        # é¿å…æ­»å¾ªç¯
                        if i == start_i:
                            i += 1
                elif field_num == 8:  # data (bytes)
                    data_blob = chunk
        
        # éªŒè¯è§£æç»“æœ
        if point_step and point_step > 0 and data_blob is not None and len(data_blob) >= point_step:
            return (point_step, data_blob, fields_list)
        return None
    
    @staticmethod
    def _datatype_to_fmt_scale(dt: int):
        """å°† DataType è½¬æ¢ä¸º struct format å’Œ scale"""
        if dt in (PointCloudParser._DT_INT16, PointCloudParser._DT_UINT16):
            return ('h' if dt == PointCloudParser._DT_INT16 else 'H', 0.01)
        if dt in (PointCloudParser._DT_INT32, PointCloudParser._DT_UINT32):
            return ('i' if dt == PointCloudParser._DT_INT32 else 'I', 1.0)
        if dt == PointCloudParser._DT_FLOAT32:
            return ('f', 1.0)
        if dt == PointCloudParser._DT_FLOAT64:
            return ('d', 1.0)
        return ('f', 1.0)
    
    @staticmethod
    def _read_xyz_from_fields(buf: bytes, offset: int, step: int, fields_map: dict):
        """ä» buffer ä¸­è¯»å– x, y, z"""
        try:
            x_info = fields_map['x']
            y_info = fields_map['y']
            z_info = fields_map['z']
        except KeyError:
            return None
        
        need = max(x_info[0], y_info[0], z_info[0]) + 8
        if offset + need > len(buf):
            return None
        
        def _read_value(info):
            off, fmt, scale = info
            if fmt == 'h':
                return struct.unpack_from('<h', buf, offset + off)[0] * scale
            elif fmt == 'H':
                return struct.unpack_from('<H', buf, offset + off)[0] * scale
            elif fmt == 'i':
                return struct.unpack_from('<i', buf, offset + off)[0] * scale
            elif fmt == 'I':
                return struct.unpack_from('<I', buf, offset + off)[0] * scale
            elif fmt == 'f':
                return struct.unpack_from('<f', buf, offset + off)[0] * scale
            elif fmt == 'd':
                return struct.unpack_from('<d', buf, offset + off)[0] * scale
            return struct.unpack_from('<f', buf, offset + off)[0] * scale
        
        return (_read_value(x_info), _read_value(y_info), _read_value(z_info))
    
    @staticmethod
    def parse_proto_pointcloud2(data: bytes) -> Optional[np.ndarray]:
        """è§£æ PointCloud2 proto æ•°æ®
        
        å‚è€ƒ: ~/develop/code/github/Self-Cali-GS/surround_calibration/data/lidar_utils.py
        """
        if data is None or len(data) < 16:
            return None
        
        # å°è¯•å¤šä¸ªå€™é€‰ä½ç½®ï¼ˆå¯èƒ½æœ‰ä¸åŒçš„å‰ç¼€ï¼‰
        candidates = [data]
        if len(data) > 4:
            candidates.append(data[4:])
        if len(data) > 8:
            candidates.append(data[8:])
        
        # ä½¿ç”¨ wire format è§£æ
        for to_parse in candidates:
            result = PointCloudParser._parse_pointcloud2_wire(to_parse)
            if result is None:
                continue
            
            step, raw, flist = result
            if not step or step <= 0:
                continue
            
            n = len(raw) // step
            if n < 50:
                continue
            
            # æ„å»º fields_map
            fields_map = {}
            for name, off, dt in flist:
                fmt, scale = PointCloudParser._datatype_to_fmt_scale(dt)
                fields_map[name] = (off, fmt, scale)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„ x, y, zï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„ï¼ˆINT16ï¼‰
            if len(fields_map) != 3:
                fields_map = {'x': (0, 'h', 0.01), 'y': (2, 'h', 0.01), 'z': (4, 'h', 0.01)}
            
            # æå–æ‰€æœ‰ç‚¹ï¼ˆåŒ…å«intensityå’Œtimestampï¼‰
            # CompressedPoint æ ¼å¼: x,y,z(int16), intensity(uint8), ring(uint8), timestamp(uint16)
            # offset: 0-1(x), 2-3(y), 4-5(z), 6(intensity), 7(ring), 8-9(timestamp)
            pts = []
            for i in range(min(n, 500000)):  # é™åˆ¶æœ€å¤§ç‚¹æ•°
                base = i * step
                xyz = PointCloudParser._read_xyz_from_fields(raw, base, step, fields_map)
                if xyz is None:
                    continue
                x, y, z = xyz
                
                # éªŒè¯ç‚¹åæ ‡
                if (np.isnan(x) or np.isnan(y) or np.isnan(z) or 
                    np.isinf(x) or np.isinf(y) or np.isinf(z) or
                    abs(x) > 500 or abs(y) > 500 or abs(z) > 100):
                    continue
                
                # è¯»å–intensityï¼ˆoffset 6ï¼Œuint8ï¼‰
                intensity = 0.0
                if base + 6 < len(raw):
                    intensity = float(raw[base + 6])
                
                # è¯»å–timestampï¼ˆoffset 8-9ï¼Œuint16ï¼‰
                timestamp_raw = 0
                if base + 9 < len(raw):
                    timestamp_raw = struct.unpack_from('<H', raw, base + 8)[0]
                
                # è¿”å› (x, y, z, intensity, timestamp)
                # timestampå•ä½æ˜¯2å¾®ç§’ï¼ˆæ ¹æ®C++ä»£ç ï¼‰
                pts.append([x, y, z, intensity, float(timestamp_raw)])
            
            if len(pts) >= 50:
                return np.array(pts, dtype=np.float32)
        
        # Fallback: å°è¯•ç›´æ¥æŒ‰floatæ ¼å¼è¯»å–ï¼ˆå¦‚æœwire formatå¤±è´¥ï¼‰
        # å‚è€ƒSelf-Cali-GS: å°è¯•ä¸åŒçš„èµ·å§‹åç§»é‡
        for offset_start in [0, 20, 40, 60, 80, 100, 150, 200, 300, 400, 500]:
            if len(data) < offset_start + 16:
                continue
            rem = len(data) - offset_start
            if rem < 16 or rem % 16 != 0:
                continue
            n = rem // 16
            pts, ok = [], 0
            for i in range(min(2000, n)):
                o = offset_start + i * 16
                try:
                    x, y, z, _ = struct.unpack_from('ffff', data, o)
                    if not (np.isnan(x) or np.isnan(y) or np.isnan(z)) and abs(x) < 5000 and abs(y) < 5000 and abs(z) < 500:
                        pts.append([x, y, z, 0.0, 0.0])  # æ·»åŠ dummy intensityå’Œtimestamp
                        ok += 1
                except Exception:
                    continue
            if ok > 50:
                # å¦‚æœæ‰¾åˆ°è¶³å¤Ÿçš„æœ‰æ•ˆç‚¹ï¼Œå¤„ç†å‰©ä½™çš„ç‚¹
                for i in range(min(2000, n), n):
                    o = offset_start + i * 16
                    try:
                        x, y, z, _ = struct.unpack_from('ffff', data, o)
                        if not (np.isnan(x) or np.isnan(y) or np.isnan(z)) and abs(x) < 5000 and abs(y) < 5000 and abs(z) < 500:
                            pts.append([x, y, z, 0.0, 0.0])
                    except Exception:
                        continue
                return np.array(pts, dtype=np.float32) if pts else None
        
        return None


class BEVCalibDatasetPreparer:
    """BEVCalib æ•°æ®é›†å‡†å¤‡å™¨ï¼ˆæµå¼å¤„ç†ç‰ˆæœ¬ï¼‰"""
    
    # å®šä½ topics (æŒ‰ç…§ç”¨æˆ·è¦æ±‚ï¼Œåªä½¿ç”¨/localization/pose)
    LOCALIZATION_TOPICS = [
        '/localization/pose',  # ä¼˜å…ˆä½¿ç”¨è¿™ä¸ªtopicï¼Œä¸C++å‚è€ƒä»£ç ä¸€è‡´
        # '/localiztaion/gnss/calibration_pose',  # æ³¨æ„æ‹¼å†™é”™è¯¯æ˜¯åŸå§‹æ•°æ®ä¸­çš„
        # '/sensors/gnss/pose'
    ]
    
    def __init__(
        self,
        bag_path: str,
        config_dir: str,
        output_dir: str,
        camera_name: str = "traffic_2",
        target_fps: float = 10.0,
        max_time_diff: float = 0.055,  # 55msï¼Œå‚è€ƒC++: kMaxLidarCameraDelta = 55000us
        lidar_topic: str = '/sensors/lidar/combined_point_cloud_proto',
        pose_topic: str = None,  # æ”¹ä¸ºå¯é€‰ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ£€æµ‹
        batch_size: int = 500,  # æ¯æ‰¹å¤„ç†çš„å¸§æ•°ï¼ˆå¢åŠ é»˜è®¤å€¼ä»¥æå‡é€Ÿåº¦ï¼‰
        num_workers: int = 4,  # å¹¶è¡Œå¤„ç†çš„å·¥ä½œçº¿ç¨‹æ•°
        max_frames: int = None,  # æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    ):
        self.bag_path = Path(bag_path)
        self.config_dir = Path(config_dir)
        self.output_dir = Path(output_dir)
        self.camera_name = camera_name
        self.target_fps = target_fps
        self.max_time_diff = max_time_diff
        self.lidar_topic = lidar_topic
        self.pose_topic = pose_topic  # å¦‚æœä¸ºNoneï¼Œåˆ™è‡ªåŠ¨æ£€æµ‹
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.max_frames = max_frames  # æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir = self.output_dir / 'temp'
        self.temp_dir.mkdir(exist_ok=True)
        self.temp_image_dir = self.temp_dir / 'images'
        self.temp_pc_dir = self.temp_dir / 'pointclouds'
        self.temp_image_dir.mkdir(exist_ok=True)
        self.temp_pc_dir.mkdir(exist_ok=True)
        
        # å…ƒæ•°æ®åˆ—è¡¨ï¼ˆä¸å­˜å‚¨å®é™…æ•°æ®ï¼‰
        self.image_metadata: List[ImageMetadata] = []
        self.pc_metadata: List[PointCloudMetadata] = []
        self.pose_metadata: List[PoseMetadata] = []
        
        # ä»bagä¸­æå–çš„ Sensingâ†’Vehicle å˜æ¢ï¼ˆä¼˜å…ˆçº§é«˜äºæœ¬åœ°é…ç½®ï¼‰
        # C++å‘½åï¼šT_vehicle_to_sensingï¼ˆä»å³å¾€å·¦è¯»ï¼šSensingâ†’Vehicleï¼‰
        # æ³¨æ„ï¼šå¿…é¡»åœ¨_compute_transforms()ä¹‹å‰åˆå§‹åŒ–
        self.vehicle_to_sensing_from_bag: Optional[np.ndarray] = None
        
        # è®¡æ•°å™¨
        self.image_counter = 0
        self.pc_counter = 0
        
        # è°ƒè¯•é€‰é¡¹
        self.verbose = True
        
        # åŠ è½½é…ç½®å¹¶è®¡ç®—å˜æ¢çŸ©é˜µ
        self._load_configs()
        self._compute_transforms()
    
    def _load_configs(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        cameras_cfg = self.config_dir / 'cameras.cfg'
        lidars_cfg = self.config_dir / 'lidars.cfg'
        
        if not cameras_cfg.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ° cameras.cfg: {cameras_cfg}")
        if not lidars_cfg.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ° lidars.cfg: {lidars_cfg}")
        
        cameras = ConfigParser.parse_cameras_cfg(str(cameras_cfg))
        if self.camera_name not in cameras:
            raise ValueError(f"æœªæ‰¾åˆ°ç›¸æœº {self.camera_name}ï¼Œå¯ç”¨: {list(cameras.keys())}")
        
        self.camera_config = cameras[self.camera_name]
        self.lidar_config = ConfigParser.parse_lidars_cfg(str(lidars_cfg))
        
        print(f"å·²åŠ è½½é…ç½®:")
        print(f"  ç›¸æœº: {self.camera_name}")
        print(f"  å›¾åƒå°ºå¯¸: {self.camera_config['intrinsic']['img_width']}x{self.camera_config['intrinsic']['img_height']}")
        print(f"  å†…å‚ fx={self.camera_config['intrinsic']['f_x']:.2f}, fy={self.camera_config['intrinsic']['f_y']:.2f}")
    
    def _extract_vehicle_to_sensing_from_pc_msg(self, data: bytes) -> Optional[np.ndarray]:
        """ä»ç‚¹äº‘protobufæ¶ˆæ¯ä¸­æå– vehicle_to_sensing (Sensingâ†’Vehicle) å˜æ¢
        
        **å‘½åçº¦å®š**: vehicle_to_sensing = Sensingâ†’Vehicle
        
        å‚è€ƒï¼šlidar_online_calibrator.cpp:1038-1054 + proto_utils.cpp:569-588
        
        Returns:
            T_sensing_to_vehicle: Sensingâ†’Vehicleçš„4x4å˜æ¢çŸ©é˜µï¼Œå¦‚æœæå–å¤±è´¥è¿”å›None
        """
        try:
            # æ‰‹åŠ¨è§£æprotobuf wire formatä»¥æŸ¥æ‰¾lidar_configså­—æ®µ
            # å¯»æ‰¾vehicle_to_sensingçš„positionå’Œorientation
            
            # å°è¯•ä½¿ç”¨protobufååºåˆ—åŒ–ï¼ˆå¦‚æœæ¶ˆæ¯åŒ…å«lidar_configsï¼‰
            # æ³¨æ„ï¼šæˆ‘ä»¬ä¸éœ€è¦å®Œæ•´çš„protoå®šä¹‰ï¼Œåªéœ€è¦æå–ç‰¹å®šå­—æ®µ
            
            # ç®€åŒ–æ–¹æ¡ˆï¼šå°è¯•æœç´¢ç‰¹å®šçš„å­—èŠ‚æ¨¡å¼
            # vehicle_to_sensingåŒ…å«: position(x,y,z) + orientation(qw,qx,qy,qz)
            
            # æš‚æ—¶è¿”å›Noneï¼Œä½¿ç”¨fallbacké€»è¾‘
            return None
            
        except Exception as e:
            return None
    
    def _get_vehicle_to_sensing_transform(self) -> np.ndarray:
        """è·å– Sensingâ†’Vehicle çš„å˜æ¢
        
        å‚è€ƒï¼šproto_utils.cpp:569-588
        
        **C++å‘½åçº¦å®š**ï¼ˆä»å³å¾€å·¦è¯»ï¼‰ï¼š
        - vehicle_to_sensing = Sensingâ†’Vehicle (Sensingåœ¨Vehicleç³»ä¸­çš„ä½å§¿)
        - T_vehicle_to_sensingè¡¨ç¤ºå°†Vehicleç³»å˜æ¢åˆ°Sensingç³» = Sensingâ†’Vehicle
        
        ä¼˜å…ˆçº§ï¼š
        1. ä»bagä¸­çš„ç‚¹äº‘æ¶ˆæ¯æå–ï¼ˆself.vehicle_to_sensing_from_bagï¼‰
        2. ä»æœ¬åœ°lidars.cfgçš„vehicle_to_sensingå­—æ®µè¯»å–
        3. é»˜è®¤å•ä½çŸ©é˜µï¼ˆVehicle == Sensingï¼‰
        
        Returns:
            T_vehicle_to_sensing: Sensingâ†’Vehicleçš„4x4å˜æ¢çŸ©é˜µï¼ˆä»å³å¾€å·¦è¯»ï¼‰
        """
        # ä¼˜å…ˆä½¿ç”¨ä»bagä¸­æå–çš„é…ç½®
        if self.vehicle_to_sensing_from_bag is not None:
            return self.vehicle_to_sensing_from_bag
        
        # å°è¯•ä»æœ¬åœ°lidars.cfgè¯»å–vehicle_to_sensing = Sensingâ†’Vehicle
        # æŒ‰C++è§„èŒƒå‘½åï¼šT_vehicle_to_sensingï¼ˆä»å³å¾€å·¦è¯»ï¼šSensingâ†’Vehicleï¼‰
        T_vehicle_to_sensing = np.eye(4)
        
        # æ£€æŸ¥lidar_configæ˜¯å¦åŒ…å«vehicle_to_sensing
        if isinstance(self.lidar_config, dict) and 'vehicle_to_sensing' in self.lidar_config:
            v2s = self.lidar_config['vehicle_to_sensing']
            if 'position' in v2s and 'orientation' in v2s:
                pos = v2s['position']
                ori = v2s['orientation']  # [qx, qy, qz, qw]
                
                # æ„å»ºå˜æ¢çŸ©é˜µï¼šSensingâ†’Vehicle
                r = R.from_quat(ori)
                T_vehicle_to_sensing[:3, :3] = r.as_matrix()
                T_vehicle_to_sensing[:3, 3] = pos
                
                print(f"âœ“ ä»lidars.cfgè¯»å– vehicle_to_sensing")
                print(f"  (C++å‘½å: T_vehicle_to_sensing = Sensingâ†’Vehicle)")
                print(f"  position: {pos}")
                print(f"  orientation: {ori}")
                return T_vehicle_to_sensing
        
        # é»˜è®¤ï¼šVehicle == Sensingï¼ˆå•ä½çŸ©é˜µï¼‰
        print(f"â„¹ï¸  ä½¿ç”¨é»˜è®¤å‡è®¾: Vehicle == Sensing (å•ä½çŸ©é˜µ)")
        return T_vehicle_to_sensing
    
    def _convert_poses_to_sensing_frame(self):
        """å°†Vehicleç³»çš„poseè½¬æ¢ä¸ºSensingç³»ï¼ˆå¯¹é½C++å®ç°ï¼‰
        
        C++å‚è€ƒï¼šlidar_online_calibrator.cpp:849-852
            sensing_pose.second = vehicle_pose * iso_vehicle_sensing_;
            lidar_pose_data_.push_back(sensing_pose);
        
        å˜æ¢ç†è§£ï¼š
        - è¾“å…¥ï¼švehicle_pose = Vehicleâ†’Worldï¼ˆVehicleåœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
        - ä¸­é—´ï¼šT_vehicle_to_sensing = Sensingâ†’Vehicleï¼ˆä»configè¯»å–ï¼‰
        - è¾“å‡ºï¼šsensing_pose = (Vehicleâ†’World) @ (Sensingâ†’Vehicle) = Sensingâ†’World
        
        å«ä¹‰ï¼šSensingåœ¨Worldç³»ä¸­çš„ä½å§¿
        """
        print(f"  è½¬æ¢ä½å§¿åˆ°Sensingåæ ‡ç³»...")
        
        for i, pose in enumerate(self.pose_metadata):
            # æ„å»ºVehicleç³»çš„poseï¼ˆVehicleâ†’Worldï¼‰
            R_vehicle = UndistortionUtils.quat_to_matrix(pose.orientation)
            t_vehicle = pose.position
            
            iso_vehicle = np.eye(4)
            iso_vehicle[:3, :3] = R_vehicle
            iso_vehicle[:3, 3] = t_vehicle
            
            # è½¬æ¢åˆ°Sensingç³»ï¼šsensing_pose = vehicle_pose * T_vehicle_to_sensing
            # å…¶ä¸­T_vehicle_to_sensing = Sensingâ†’Vehicleï¼ˆC++å‘½åçº¦å®šï¼‰
            iso_sensing = iso_vehicle @ self.T_vehicle_to_sensing
            
            # æ›´æ–°poseï¼ˆç°åœ¨æ˜¯Sensingç³»ï¼‰
            R_sensing = iso_sensing[:3, :3]
            t_sensing = iso_sensing[:3, 3]
            
            # è½¬æ¢å›å››å…ƒæ•°
            r = R.from_matrix(R_sensing)
            pose.orientation = r.as_quat()  # [x, y, z, w]
            pose.position = t_sensing
        
        print(f"  âœ“ å·²è½¬æ¢ {len(self.pose_metadata)} ä¸ªä½å§¿åˆ°Sensingç³»")
    
    def _compute_transforms(self):
        """è®¡ç®—å˜æ¢çŸ©é˜µ
        
        å‚è€ƒï¼šproto_utils.cpp:193-201, 274-323 + åæ ‡ç³»æ–‡æ¡£
        
        **C++å‘½åçº¦å®š**ï¼ˆä»å³å¾€å·¦è¯»ï¼‰ï¼š
        - T_A_to_B è¡¨ç¤ºå°†Aç³»åæ ‡å˜æ¢åˆ°Bç³» = Bâ†’A çš„å˜æ¢ = Båœ¨Aç³»ä¸­çš„ä½å§¿
        - ä¾‹å¦‚ï¼šT_sensing_to_camera = Cameraâ†’Sensing (å°†Sensingç³»å˜æ¢åˆ°Cameraç³»)
        
        **configæ–‡ä»¶å«ä¹‰**ï¼š
        - cameras.cfg: sensor_to_cam = Cameraâ†’Sensing (Cameraåœ¨Sensingç³»ä¸­çš„ä½å§¿)
        - lidars.cfg: sensor_to_lidar = LiDARâ†’Sensing (LiDARåœ¨Sensingç³»ä¸­çš„ä½å§¿)
        - lidars.cfg: vehicle_to_sensing = Sensingâ†’Vehicle (Sensingåœ¨Vehicleç³»ä¸­çš„ä½å§¿)
        
        **åæ ‡ç³»å®šä¹‰**ï¼š
        - Vehicleç³»ï¼šåè½´ä¸­å¿ƒï¼Œå‰å·¦ä¸Š=XYZ
        - Sensingç³»ï¼šè™šæ‹Ÿç³»ï¼Œå‰å·¦ä¸Š=XYZ
        - LiDARç³»ï¼šå‰å·¦ä¸Š=XYZï¼ˆä¸KITTI Velodyneä¸€è‡´ï¼‰
        - Cameraç³»ï¼šå…‰è½´=Zï¼Œå³ä¸‹å‰=XYZï¼ˆOpenCVæ ‡å‡†ï¼‰
        """
        # 1. ä»configè¯»å– sensor_to_cam = Cameraâ†’Sensing
        # æŒ‰C++è§„èŒƒå‘½åï¼šT_sensing_to_cameraï¼ˆä»å³å¾€å·¦è¯»ï¼šCameraâ†’Sensingï¼‰
        T_sensing_to_camera = np.eye(4)
        r = R.from_quat(self.camera_config['orientation'])
        T_sensing_to_camera[:3, :3] = r.as_matrix()
        T_sensing_to_camera[:3, 3] = self.camera_config['position']
        
        # 2. å–é€†å¾—åˆ° Sensingâ†’Camera (ä»å³å¾€å·¦è¯»)
        T_camera_to_sensing = np.linalg.inv(T_sensing_to_camera)
        
        # 3. ä»configè¯»å– sensor_to_lidar = LiDARâ†’Sensing
        # æŒ‰C++è§„èŒƒå‘½åï¼šT_sensing_to_lidarï¼ˆä»å³å¾€å·¦è¯»ï¼šLiDARâ†’Sensingï¼‰
        T_sensing_to_lidar = np.eye(4)
        r = R.from_quat(self.lidar_config['orientation'])
        T_sensing_to_lidar[:3, :3] = r.as_matrix()
        T_sensing_to_lidar[:3, 3] = self.lidar_config['position']
        
        # 4. å–é€†å¾—åˆ° Sensingâ†’LiDAR (ä»å³å¾€å·¦è¯»)
        T_lidar_to_sensing = np.linalg.inv(T_sensing_to_lidar)
        
        # 5. è®¡ç®— LiDARâ†’Camera (KITTIæ ‡å‡†TrçŸ©é˜µ)
        # å˜æ¢é“¾ï¼šLiDAR â†’ Sensing â†’ Camera
        # T_camera_to_lidar = T_camera_to_sensing @ T_sensing_to_lidar
        #                   = (Sensingâ†’Camera) @ (LiDARâ†’Sensing)
        #                   = LiDAR â†’ Camera
        self.T_camera_to_lidar = T_camera_to_sensing @ T_sensing_to_lidar
        
        # 6. å–é€†å¾—åˆ° Cameraâ†’LiDAR (ä»å³å¾€å·¦è¯»)
        self.T_lidar_to_camera = np.linalg.inv(self.T_camera_to_lidar)
        
        # 7. ä¿å­˜ç”¨äºå»ç•¸å˜å’ŒæŠ•å½±çš„å˜æ¢
        self.T_sensing_to_lidar = T_sensing_to_lidar    # LiDAR â†’ Sensing (ä»å³å¾€å·¦è¯»)
        self.T_lidar_to_sensing = T_lidar_to_sensing    # Sensing â†’ LiDAR (ä»å³å¾€å·¦è¯»)
        self.T_sensing_to_camera = T_sensing_to_camera  # Camera â†’ Sensing (ä»å³å¾€å·¦è¯»)
        self.T_camera_to_sensing = T_camera_to_sensing  # Sensing â†’ Camera (ä»å³å¾€å·¦è¯»)
        
        # 8. è·å–å¹¶ç¼“å­˜ Vehicleâ†’Sensing å˜æ¢ï¼ˆé¢‘ç¹ä½¿ç”¨ï¼Œæå‰è®¡ç®—ï¼‰
        self.T_vehicle_to_sensing = self._get_vehicle_to_sensing_transform()
        
        # 9. å†…å‚çŸ©é˜µ
        intrinsic = self.camera_config['intrinsic']
        self.K = np.array([
            [intrinsic['f_x'], 0, intrinsic['o_x']],
            [0, intrinsic['f_y'], intrinsic['o_y']],
            [0, 0, 1]
        ])
        
        print(f"âœ“ å˜æ¢çŸ©é˜µå·²è®¡ç®— (C++å‘½åçº¦å®šï¼Œä»å³å¾€å·¦è¯»):")
        print(f"  T_camera_to_lidar: LiDAR â†’ Camera (KITTI TrçŸ©é˜µ)")
        print(f"  T_lidar_to_camera: Camera â†’ LiDAR")
        print(f"  T_lidar_to_sensing: Sensing â†’ LiDAR (å»ç•¸å˜ç”¨)")
        print(f"  T_vehicle_to_sensing: Sensing â†’ Vehicle (å·²ç¼“å­˜)")
    
    def extract_data_from_bag(self):
        """ä» rosbag æå–æ•°æ®ï¼ˆæµå¼å¤„ç†+å¹¶è¡ŒåŠ é€Ÿï¼‰"""
        print(f"\n{'='*80}")
        print(f"é˜¶æ®µ 1/3: ä» rosbag æå–æ•°æ®")
        print(f"{'='*80}")
        
        start_time = time.time()
        
        bag_files = self._find_bag_files()
        if not bag_files:
            raise ValueError(f"æœªæ‰¾åˆ° bag æ–‡ä»¶: {self.bag_path}")
        
        print(f"æ‰¾åˆ° {len(bag_files)} ä¸ª bag æ–‡ä»¶")
        
        try:
            from rosbags.rosbag1 import Reader
            use_rosbags = True
        except ImportError:
            try:
                import rosbag
                use_rosbags = False
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£… rosbag æˆ– rosbags: pip install rosbags")
        
        # ç¡®å®šå›¾åƒ topic
        possible_topics = [
            f'/sensors/camera/{self.camera_name}_raw_data/compressed_proto',
            f'/sensors/camera/{self.camera_name}/compressed_proto',
        ]
        
        image_topic = None
        detected_pose_topic = None
        
        # å…³é”®ä¿®å¤ï¼šæ‰«ææ‰€æœ‰bagæ–‡ä»¶ä»¥æ”¶é›†æ‰€æœ‰å¯ç”¨topics
        # ï¼ˆå› ä¸ºä¸åŒçš„Topic Groupæœ‰ä¸åŒçš„topicsï¼ï¼‰
        print(f"\næ‰«ææ‰€æœ‰bagæ–‡ä»¶ä»¥æ£€æµ‹topics...")
        all_available_topics = set()
        
        # ğŸ” ä¼˜åŒ–ï¼šæŒ‰æ–‡ä»¶ååˆ†ç»„ï¼Œç¡®ä¿æ¯ä¸ªTopic Groupéƒ½è¢«æ‰«æ
        from collections import defaultdict
        bags_by_group = defaultdict(list)
        for bf in bag_files:
            # æå–Topic Groupåç§°ï¼ˆå¦‚ Heavy_Topic_Group, Light_Topic_Groupç­‰ï¼‰
            parts = bf.parts
            group_name = 'default'
            for i, p in enumerate(parts):
                if 'Topic_Group' in p:
                    group_name = p
                    break
            bags_by_group[group_name].append(bf)
        
        # ä»æ¯ä¸ªGroupæ‰«æè‡³å°‘1ä¸ªbag
        bags_to_scan = []
        for group, blist in bags_by_group.items():
            bags_to_scan.append(blist[0])  # æ¯ç»„æ‰«æç¬¬ä¸€ä¸ª
        
        print(f"  å‘ç° {len(bags_by_group)} ä¸ªTopic Groups: {list(bags_by_group.keys())}")
        print(f"  æ‰«æ {len(bags_to_scan)} ä¸ªä»£è¡¨æ€§bagæ–‡ä»¶...")
        
        if use_rosbags:
            for bag_file in bags_to_scan:
                try:
                    with Reader(str(bag_file)) as reader:
                        all_available_topics.update(reader.topics.keys())
                except Exception as e:
                    print(f"  è­¦å‘Š: æ— æ³•è¯»å– {bag_file.name}: {e}")
        else:
            import rosbag as rb
            for bag_file in bags_to_scan:
                try:
                    with rb.Bag(str(bag_file), 'r') as bag:
                        info = bag.get_type_and_topic_info()
                        all_available_topics.update(info[1].keys())
                except Exception as e:
                    print(f"  è­¦å‘Š: æ— æ³•è¯»å– {bag_file.name}: {e}")
        
        print(f"  âœ“ æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(all_available_topics)} ä¸ªä¸åŒçš„topics")
        
        # æŸ¥æ‰¾å›¾åƒtopic
        for t in possible_topics:
            if t in all_available_topics:
                image_topic = t
                print(f"  âœ“ æ‰¾åˆ°å›¾åƒ topic: {t}")
                break
        
        # æŸ¥æ‰¾ä½å§¿topicï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šï¼‰
        if self.pose_topic is None:
            for t in self.LOCALIZATION_TOPICS:
                if t in all_available_topics:
                    detected_pose_topic = t
                    print(f"  âœ“ æ‰¾åˆ°ä½å§¿ topic: {t}")
                    break
            if detected_pose_topic is None:
                print(f"  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•ä½å§¿topicï¼Œå°†è·³è¿‡ç‚¹äº‘å»ç•¸å˜")
                print(f"     å°è¯•çš„topics: {self.LOCALIZATION_TOPICS}")
        else:
            if self.pose_topic in all_available_topics:
                detected_pose_topic = self.pose_topic
                print(f"  âœ“ ä½¿ç”¨æŒ‡å®šä½å§¿ topic: {self.pose_topic}")
        
        # ä½¿ç”¨æ£€æµ‹åˆ°çš„topicæˆ–æŒ‡å®šçš„topic
        self.active_pose_topic = detected_pose_topic or self.pose_topic
        
        # å¦‚æœè®¾ç½®äº†max_framesï¼Œå¼ºåˆ¶ä¸²è¡Œæå–ä»¥ä¾¿æå‰ç»ˆæ­¢
        if self.max_frames is not None:
            print(f"\nâš ï¸  è®¾ç½®äº†max_frames={self.max_frames}ï¼Œä½¿ç”¨ä¸²è¡Œæå–ä»¥ä¾¿æå‰ç»ˆæ­¢")
            force_serial = True
        else:
            force_serial = False
        
        # å¹¶è¡Œæå–ï¼ˆå¦‚æœæœ‰å¤šä¸ªbagæ–‡ä»¶ä¸”æœªè®¾ç½®max_framesï¼‰
        if len(bag_files) > 1 and self.num_workers > 1 and not force_serial:
            print(f"\nä½¿ç”¨ {self.num_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç† bag æ–‡ä»¶...")
            self._extract_parallel(bag_files, image_topic, possible_topics, use_rosbags)
        else:
            # ä¸²è¡Œæå–
            # å…³é”®ä¿®å¤ï¼šå¯¹äºmax_framesæ¨¡å¼ï¼Œä¼˜å…ˆå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰ï¼Œå¿«é€Ÿè¾¾åˆ°é˜ˆå€¼ï¼
            if self.max_frames is not None:
                # å¿«é€Ÿæ¨¡å¼ï¼šä¼˜å…ˆå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰ï¼Œç„¶åæ˜¯Light/Medium/Tinyï¼ˆç‚¹äº‘+ä½å§¿ï¼‰
                sorted_bags = sorted(bag_files, key=lambda x: (
                    1 if 'Heavy_Topic_Group' not in x.name else 0,
                    x.name
                ))
                print(f"  ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼ˆmax_frames={self.max_frames}ï¼‰ï¼šä¼˜å…ˆå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰ï¼Œå¿«é€Ÿæ”¶é›†æ•°æ®")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šä¼˜å…ˆå¤„ç†Light/Medium/Tiny bagsï¼ˆç‚¹äº‘+ä½å§¿ï¼‰ï¼Œæœ€åå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰
                sorted_bags = sorted(bag_files, key=lambda x: (
                    0 if 'Heavy_Topic_Group' not in x.name else 1,
                    x.name
                ))
                print(f"  ä¼˜åŒ–å¤„ç†é¡ºåºï¼šä¼˜å…ˆå¤„ç†Light/Medium/Tiny bagsï¼ˆç‚¹äº‘+ä½å§¿ï¼‰ï¼Œæœ€åå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰")
            
            for bag_file in sorted_bags:
                # æå‰ç»ˆæ­¢æ£€æŸ¥ï¼ˆä»…é’ˆå¯¹å›¾åƒå’Œç‚¹äº‘ï¼Œä½å§¿éœ€è¦å®Œæ•´ï¼‰
                if self.max_frames is not None:
                    # ä¿®æ­£ï¼šä½¿ç”¨1.1å€ä½œä¸ºç¼“å†²ï¼Œè€Œä¸æ˜¯1.5å€
                    img_count = len(self.image_metadata)
                    pc_count = len(self.pc_metadata)
                    threshold = self.max_frames * 1.1
                    
                    # å…³é”®ä¿®å¤ï¼šå¦‚æœå›¾åƒå’Œç‚¹äº‘éƒ½è¾¾åˆ°é˜ˆå€¼ï¼Œåˆ™å®Œå…¨åœæ­¢æå–ï¼ˆåªæå–ä½å§¿ï¼‰
                    if img_count >= threshold and pc_count >= threshold:
                        # æ³¨æ„ï¼šä½å§¿ä¸é™åˆ¶ï¼Œç»§ç»­æå–ä»¥ç¡®ä¿æ—¶é—´è¦†ç›–
                        print(f"\nâœ“ å›¾åƒå’Œç‚¹äº‘å·²è¶³å¤Ÿï¼ˆå›¾åƒ:{img_count}, ç‚¹äº‘:{pc_count}ï¼‰")
                        print(f"   ç»§ç»­æå–ä½å§¿æ•°æ®ä»¥ç¡®ä¿æ—¶é—´èŒƒå›´å®Œæ•´...")
                        # åˆ‡æ¢åˆ°ä»…æå–ä½å§¿æ¨¡å¼
                        try:
                            if use_rosbags:
                                self._extract_poses_only(bag_file, use_rosbags=True)
                            else:
                                self._extract_poses_only(bag_file, use_rosbags=False)
                        except Exception as e:
                            print(f"  è­¦å‘Š: {e}")
                        continue
                    # å…³é”®ä¿®å¤ï¼šå¦‚æœä»»ä¸€æ•°æ®ç±»å‹å·²è¾¾åˆ°é˜ˆå€¼ï¼Œè·³è¿‡ä¸»è¦åŒ…å«è¯¥ç±»å‹çš„bags
                    elif img_count >= threshold and 'Heavy_Topic_Group' in bag_file.name:
                        print(f"\nâ­ï¸  è·³è¿‡ {bag_file.name}ï¼ˆå›¾åƒæ•°å·²è¶³å¤Ÿ:{img_count}ï¼‰")
                        continue
                    elif pc_count >= threshold and 'Heavy_Topic_Group' not in bag_file.name:
                        print(f"\nâ­ï¸  è·³è¿‡ {bag_file.name}ï¼ˆç‚¹äº‘æ•°å·²è¶³å¤Ÿ:{pc_count}ï¼‰")
                        # ä½†ä»éœ€è¦å¤„ç†ä½å§¿
                        try:
                            if use_rosbags:
                                self._extract_poses_only(bag_file, use_rosbags=True)
                            else:
                                self._extract_poses_only(bag_file, use_rosbags=False)
                        except Exception as e:
                            print(f"  è­¦å‘Š: {e}")
                        continue
                
                print(f"\nå¤„ç†: {bag_file.name}")
                try:
                    if use_rosbags:
                        self._extract_streaming_rosbags(bag_file, image_topic, possible_topics)
                    else:
                        self._extract_streaming_rosbag(bag_file, image_topic, possible_topics)
                except Exception as e:
                    print(f"  è­¦å‘Š: {e}")
        
        # æ’åºå…ƒæ•°æ®
        self.image_metadata.sort(key=lambda x: x.timestamp)
        self.pc_metadata.sort(key=lambda x: x.timestamp)
        self.pose_metadata.sort(key=lambda x: x.timestamp)
        
        # âœ… å…³é”®ä¿®å¤ï¼šå°†Vehicleç³»çš„poseè½¬æ¢ä¸ºSensingç³»ï¼ˆå¯¹é½C++å®ç°ï¼‰
        # C++å‚è€ƒï¼šlidar_online_calibrator.cpp:849-852
        #   sensing_pose.second = vehicle_pose * iso_vehicle_sensing_;
        if len(self.pose_metadata) > 0:
            self._convert_poses_to_sensing_frame()
        
        extract_time = time.time() - start_time
        
        print(f"\nâœ“ æ•°æ®æå–å®Œæˆ:")
        print(f"  å›¾åƒ: {len(self.image_metadata)} å¸§")
        print(f"  ç‚¹äº‘: {len(self.pc_metadata)} å¸§")
        print(f"  ä½å§¿: {len(self.pose_metadata)} ä¸ª")
        if len(self.pose_metadata) == 0:
            print(f"  âš ï¸  è­¦å‘Šï¼šæœªæå–åˆ°ä½å§¿æ•°æ®ï¼ç‚¹äº‘å»ç•¸å˜å°†è·³è¿‡ï¼")
            print(f"    æ£€æµ‹åˆ°çš„ä½å§¿topic: {self.active_pose_topic or 'æœªæ‰¾åˆ°'}")
            print(f"    å¯èƒ½çš„åŸå› ï¼š1) bagä¸­æ²¡æœ‰ä½å§¿æ•°æ®ï¼›2) topicåç§°ä¸åŒ¹é…")
        print(f"  è€—æ—¶: {timedelta(seconds=int(extract_time))}")
        print(f"  é€Ÿåº¦: {len(self.image_metadata) / extract_time:.2f} å¸§/ç§’")
        
        # ä¿å­˜æå–é˜¶æ®µçš„è€—æ—¶
        self._extract_time = extract_time
    
    def _extract_parallel(self, bag_files: List[Path], image_topic: Optional[str],
                         possible_topics: List[str], use_rosbags: bool):
        """å¹¶è¡Œå¤„ç†å¤šä¸ªbagæ–‡ä»¶"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import threading
        
        # çº¿ç¨‹é”ä¿æŠ¤å…ƒæ•°æ®åˆ—è¡¨
        lock = threading.Lock()
        
        def process_single_bag(bag_file: Path):
            """å¤„ç†å•ä¸ªbagæ–‡ä»¶"""
            try:
                if use_rosbags:
                    # åˆ›å»ºä¸´æ—¶å…ƒæ•°æ®åˆ—è¡¨
                    temp_images = []
                    temp_pcs = []
                    temp_poses = []
                    
                    # æå–æ•°æ®
                    self._extract_streaming_rosbags_to_lists(
                        bag_file, image_topic, possible_topics,
                        temp_images, temp_pcs, temp_poses
                    )
                    
                    # åˆå¹¶åˆ°ä¸»åˆ—è¡¨ï¼ˆéœ€è¦åŠ é”ï¼‰
                    with lock:
                        self.image_metadata.extend(temp_images)
                        self.pc_metadata.extend(temp_pcs)
                        self.pose_metadata.extend(temp_poses)
                    
                    return len(temp_images), len(temp_pcs), len(temp_poses)
                else:
                    # rosbagåº“æš‚ä¸æ”¯æŒå¹¶è¡Œï¼ˆGILé™åˆ¶ï¼‰
                    return 0, 0, 0
            except Exception as e:
                print(f"  é”™è¯¯å¤„ç† {bag_file.name}: {e}")
                return 0, 0, 0
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            futures = {executor.submit(process_single_bag, bf): bf for bf in bag_files}
            
            for future in tqdm(as_completed(futures), total=len(bag_files),
                             desc="  å¹¶è¡Œå¤„ç†bagæ–‡ä»¶", unit="bag"):
                bag_file = futures[future]
                try:
                    n_images, n_pcs, n_poses = future.result()
                    print(f"  âœ“ {bag_file.name}: {n_images} å›¾åƒ, {n_pcs} ç‚¹äº‘, {n_poses} ä½å§¿")
                except Exception as e:
                    print(f"  âœ— {bag_file.name}: é”™è¯¯ - {e}")
    
    def _find_bag_files(self) -> List[Path]:
        """æŸ¥æ‰¾ bag æ–‡ä»¶"""
        if self.bag_path.is_file():
            return [self.bag_path]
        elif self.bag_path.is_dir():
            return sorted(self.bag_path.glob('**/*.bag'))
        return []
    
    def _extract_poses_only(self, bag_file: Path, use_rosbags: bool = True):
        """åªæå–ä½å§¿æ•°æ®ï¼ˆç¡®ä¿æ—¶é—´èŒƒå›´å®Œæ•´ï¼‰
        
        å‚è€ƒC++å®ç°ï¼Œä½å§¿æ•°æ®éœ€è¦è¦†ç›–æ‰€æœ‰å›¾åƒ/ç‚¹äº‘çš„æ—¶é—´èŒƒå›´
        """
        pose_count_before = len(self.pose_metadata)
        
        if use_rosbags:
            from rosbags.rosbag1 import Reader
            
            with Reader(str(bag_file)) as reader:
                # æ£€æŸ¥ä½å§¿topicæ˜¯å¦åœ¨å½“å‰bagä¸­
                if self.active_pose_topic and self.active_pose_topic not in reader.topics:
                    return
                
                # åªå…³æ³¨ä½å§¿topic
                for connection, timestamp, rawdata in reader.messages():
                    if self.active_pose_topic and connection.topic == self.active_pose_topic:
                        try:
                            data = self._extract_string_msg(rawdata)
                            if data:
                                # åˆ›å»ºä¸´æ—¶msgå¯¹è±¡
                                class TempMsg:
                                    def __init__(self, d):
                                        self.data = d
                                ts_sec = timestamp / 1e9
                                pose_data = self._decode_pose_msg(TempMsg(data), fallback_timestamp=ts_sec)
                                if pose_data:
                                    self.pose_metadata.append(pose_data)
                        except Exception as e:
                            pass
                    elif not self.active_pose_topic and connection.topic in self.LOCALIZATION_TOPICS:
                        # è‡ªåŠ¨æ£€æµ‹ä½å§¿topic
                        try:
                            data = self._extract_string_msg(rawdata)
                            if data:
                                class TempMsg:
                                    def __init__(self, d):
                                        self.data = d
                                ts_sec = timestamp / 1e9
                                pose_data = self._decode_pose_msg(TempMsg(data), fallback_timestamp=ts_sec)
                                if pose_data:
                                    self.active_pose_topic = connection.topic
                                    self.pose_metadata.append(pose_data)
                        except Exception as e:
                            pass
        else:
            import rosbag as rb
            with rb.Bag(str(bag_file), 'r') as bag:
                for topic, msg, t in bag.read_messages(topics=self.LOCALIZATION_TOPICS):
                    try:
                        pose_data = self._decode_pose_msg(msg)
                        if pose_data:
                            if not self.active_pose_topic:
                                self.active_pose_topic = topic
                            self.pose_metadata.append(pose_data)
                    except Exception as e:
                        pass
        
        pose_count_after = len(self.pose_metadata)
        if pose_count_after > pose_count_before:
            print(f"    æå– {pose_count_after - pose_count_before} ä¸ªä½å§¿")
    
    def _extract_streaming_rosbags(self, bag_file: Path, image_topic: Optional[str],
                                   possible_topics: List[str]):
        """ä½¿ç”¨ rosbags æµå¼æå–"""
        temp_images = []
        temp_pcs = []
        temp_poses = []
        
        self._extract_streaming_rosbags_to_lists(
            bag_file, image_topic, possible_topics,
            temp_images, temp_pcs, temp_poses
        )
        
        # åˆå¹¶åˆ°ä¸»åˆ—è¡¨
        self.image_metadata.extend(temp_images)
        self.pc_metadata.extend(temp_pcs)
        self.pose_metadata.extend(temp_poses)
    
    def _extract_streaming_rosbags_to_lists(self, bag_file: Path, image_topic: Optional[str],
                                           possible_topics: List[str],
                                           out_images: list, out_pcs: list, out_poses: list):
        """ä½¿ç”¨ rosbags æµå¼æå–ï¼ˆè¾“å‡ºåˆ°æŒ‡å®šåˆ—è¡¨ï¼‰"""
        from rosbags.rosbag1 import Reader
        
        image_buffer = []
        pc_buffer = []
        
        topics_to_check = [image_topic] if image_topic else possible_topics
        
        with Reader(str(bag_file)) as reader:
            available = list(reader.topics.keys())
            topics_to_check = [t for t in topics_to_check if t in available]
            
            # æ£€æŸ¥ä½å§¿topicæ˜¯å¦å¯ç”¨
            pose_topic_available = self.active_pose_topic and self.active_pose_topic in available
            
            msg_count = 0
            for connection, timestamp, rawdata in tqdm(reader.messages(), 
                                                      desc=f"  æå–æ•°æ®",
                                                      unit="msg"):
                # ğŸ”¥ æå‰ç»ˆæ­¢æ£€æŸ¥ï¼šæ¯10æ¡æ¶ˆæ¯æ£€æŸ¥ä¸€æ¬¡ï¼ˆå¿«é€Ÿæ¨¡å¼ç”¨æ›´ç»†ç²’åº¦ï¼‰
                msg_count += 1
                if self.max_frames is not None and msg_count % 10 == 0:
                    img_count = len(self.image_metadata) + len(image_buffer)
                    pc_count = len(self.pc_metadata) + len(pc_buffer)
                    if img_count >= self.max_frames * 1.1 and pc_count >= self.max_frames * 1.1:
                        print(f"\n  âš¡ æå‰ç»ˆæ­¢ï¼šå·²æ”¶é›†è¶³å¤Ÿæ•°æ® (å›¾åƒ:{img_count}, ç‚¹äº‘:{pc_count})")
                        break
                
                # bag_record_timeç”¨ä½œfallbackï¼ˆå½“headeræ—¶é—´æˆ³æå–å¤±è´¥æ—¶ï¼‰
                bag_record_time = timestamp / 1e9
                
                # æå–å›¾åƒ
                if connection.topic in topics_to_check:
                    data = self._extract_string_msg(rawdata)
                    if data:
                        # âœ… å…³é”®ä¿®å¤ï¼šä»headeræå–æ—¶é—´æˆ³ï¼ˆå‚è€ƒC++: image_msg.header().timestamp_sec()ï¼‰
                        header_ts = ProtobufUtils.extract_header_timestamp(data)
                        ts_sec = header_ts if header_ts is not None else bag_record_time
                        
                        image = self._decode_image_msg_from_bytes(data)
                        if image is not None:
                            image_buffer.append((ts_sec, image))
                            
                            # æ‰¹é‡ä¿å­˜
                            if len(image_buffer) >= self.batch_size:
                                self._save_image_batch(image_buffer)
                                image_buffer.clear()
                
                # æå–ç‚¹äº‘
                elif connection.topic == self.lidar_topic:
                    data = self._extract_string_msg(rawdata)
                    if data:
                        # âœ… å…³é”®ä¿®å¤ï¼šä»headeræå–æ—¶é—´æˆ³ï¼ˆå‚è€ƒC++: cloud_msg->header().timestamp_sec()ï¼‰
                        header_ts = ProtobufUtils.extract_header_timestamp(data)
                        ts_sec = header_ts if header_ts is not None else bag_record_time
                        
                        # å°è¯•ä»é¦–ä¸ªç‚¹äº‘æ¶ˆæ¯æå– vehicle_to_sensing (Sensingâ†’Vehicle)
                        if self.vehicle_to_sensing_from_bag is None:
                            v2s = self._extract_vehicle_to_sensing_from_pc_msg(data)
                            if v2s is not None:
                                self.vehicle_to_sensing_from_bag = v2s
                                print(f"âœ“ ä»bagç‚¹äº‘æ¶ˆæ¯ä¸­æå–åˆ° vehicle_to_sensing")
                                print(f"   (C++å‘½å: T_vehicle_to_sensing = Sensingâ†’Vehicle)")
                        
                        points = PointCloudParser.parse_proto_pointcloud2(data)
                        if points is not None and points.shape[0] >= 50:
                            pc_buffer.append((ts_sec, points))
                            
                            # æ‰¹é‡ä¿å­˜
                            if len(pc_buffer) >= self.batch_size:
                                self._save_pc_batch(pc_buffer)
                                pc_buffer.clear()
                
                # æå–ä½å§¿
                elif pose_topic_available and connection.topic == self.active_pose_topic:
                    data = self._extract_string_msg(rawdata)
                    if data:
                        # åˆ›å»ºä¸€ä¸ªä¸´æ—¶msgå¯¹è±¡ä»¥é‡ç”¨_decode_pose_msg
                        class TempMsg:
                            def __init__(self, d):
                                self.data = d
                        pose = self._decode_pose_msg(TempMsg(data), fallback_timestamp=bag_record_time)
                        if pose:
                            out_poses.append(pose)
        
        # ä¿å­˜å‰©ä½™çš„æ•°æ®
        if image_buffer:
            self._save_image_batch(image_buffer)
        if pc_buffer:
            self._save_pc_batch(pc_buffer)
    
    def _extract_streaming_rosbag(self, bag_file: Path, image_topic: Optional[str],
                                  possible_topics: List[str]):
        """ä½¿ç”¨ rosbag æµå¼æå–"""
        import rosbag
        
        image_buffer = []
        pc_buffer = []
        
        # æ£€æŸ¥å¯ç”¨topics
        with rosbag.Bag(str(bag_file), 'r') as bag:
            info = bag.get_type_and_topic_info()[1]
            available_topics = list(info.keys())
            pose_topic_available = self.active_pose_topic and self.active_pose_topic in available_topics
        
        with rosbag.Bag(str(bag_file), 'r') as bag:
            msg_count = 0
            for topic, msg, t in tqdm(bag.read_messages(),
                                     desc=f"  æå–æ•°æ®",
                                     unit="msg"):
                # ğŸ”¥ æå‰ç»ˆæ­¢æ£€æŸ¥ï¼šæ¯10æ¡æ¶ˆæ¯æ£€æŸ¥ä¸€æ¬¡ï¼ˆå¿«é€Ÿæ¨¡å¼ç”¨æ›´ç»†ç²’åº¦ï¼‰
                msg_count += 1
                if self.max_frames is not None and msg_count % 10 == 0:
                    img_count = len(self.image_metadata) + len(image_buffer)
                    pc_count = len(self.pc_metadata) + len(pc_buffer)
                    if img_count >= self.max_frames * 1.1 and pc_count >= self.max_frames * 1.1:
                        print(f"\n  âš¡ æå‰ç»ˆæ­¢ï¼šå·²æ”¶é›†è¶³å¤Ÿæ•°æ® (å›¾åƒ:{img_count}, ç‚¹äº‘:{pc_count})")
                        break
                
                # âš ï¸ æ³¨æ„ï¼št.to_sec()æ˜¯bagè®°å½•æ—¶é—´ï¼Œä¸æ˜¯ä¼ æ„Ÿå™¨æ•°æ®æ—¶é—´æˆ³
                bag_record_time = t.to_sec()  # ç”¨ä½œfallback
                
                # æå–å›¾åƒ
                if (image_topic and topic == image_topic) or topic in possible_topics:
                    if hasattr(msg, 'data'):
                        data = msg.data
                        if isinstance(data, str):
                            data = data.encode('latin-1')
                        elif not isinstance(data, bytes):
                            data = None
                        
                        if data:
                            # âœ… å…³é”®ä¿®å¤ï¼šä»headeræå–æ—¶é—´æˆ³ï¼ˆå‚è€ƒC++: image_msg.header().timestamp_sec()ï¼‰
                            header_ts = ProtobufUtils.extract_header_timestamp(data)
                            ts_sec = header_ts if header_ts is not None else bag_record_time
                            
                            image = self._decode_image_msg_from_bytes(data)
                            if image is not None:
                                image_buffer.append((ts_sec, image))
                                if len(image_buffer) >= self.batch_size:
                                    self._save_image_batch(image_buffer)
                                    image_buffer.clear()
                
                # æå–ç‚¹äº‘
                elif topic == self.lidar_topic:
                    if hasattr(msg, 'data'):
                        data = msg.data
                        if isinstance(data, str):
                            data = data.encode('latin-1')
                        elif not isinstance(data, bytes):
                            continue
                        
                        # âœ… å…³é”®ä¿®å¤ï¼šä»headeræå–æ—¶é—´æˆ³ï¼ˆå‚è€ƒC++: cloud_msg->header().timestamp_sec()ï¼‰
                        header_ts = ProtobufUtils.extract_header_timestamp(data)
                        ts_sec = header_ts if header_ts is not None else bag_record_time
                        
                        # å°è¯•ä»é¦–ä¸ªç‚¹äº‘æ¶ˆæ¯æå– vehicle_to_sensing (Sensingâ†’Vehicle)
                        if self.vehicle_to_sensing_from_bag is None:
                            v2s = self._extract_vehicle_to_sensing_from_pc_msg(data)
                            if v2s is not None:
                                self.vehicle_to_sensing_from_bag = v2s
                                print(f"âœ“ ä»bagç‚¹äº‘æ¶ˆæ¯ä¸­æå–åˆ° vehicle_to_sensing")
                                print(f"   (C++å‘½å: T_vehicle_to_sensing = Sensingâ†’Vehicle)")
                        
                        points = PointCloudParser.parse_proto_pointcloud2(data)
                        if points is not None and points.shape[0] >= 50:
                            pc_buffer.append((ts_sec, points))
                            if len(pc_buffer) >= self.batch_size:
                                self._save_pc_batch(pc_buffer)
                                pc_buffer.clear()
                
                # æå–ä½å§¿
                elif pose_topic_available and topic == self.active_pose_topic:
                    pose = self._decode_pose_msg(msg, fallback_timestamp=bag_record_time)
                    if pose is not None:
                        self.pose_metadata.append(pose)
        
        if image_buffer:
            self._save_image_batch(image_buffer)
        if pc_buffer:
            self._save_pc_batch(pc_buffer)
    
    def _save_image_batch(self, batch: List[Tuple[float, np.ndarray]]):
        """ä¿å­˜ä¸€æ‰¹å›¾åƒåˆ°ä¸´æ—¶ç›®å½•"""
        for ts, image in batch:
            filename = f"{self.image_counter:06d}.jpg"
            filepath = self.temp_image_dir / filename
            cv2.imwrite(str(filepath), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
            
            self.image_metadata.append(ImageMetadata(
                timestamp=ts,
                file_path=str(filepath)
            ))
            self.image_counter += 1
            
            del image  # ç«‹å³é‡Šæ”¾
    
    def _save_pc_batch(self, batch: List[Tuple[float, np.ndarray]]):
        """ä¿å­˜ä¸€æ‰¹ç‚¹äº‘åˆ°ä¸´æ—¶ç›®å½•ï¼ˆBIN æ ¼å¼ï¼Œä¿ç•™timestampç”¨äºå»ç•¸å˜ï¼‰"""
        for ts, points in batch:
            filename = f"{self.pc_counter:06d}.bin"
            filepath = self.temp_pc_dir / filename
            
            # ä¿å­˜ç‚¹äº‘ï¼ˆå¯èƒ½æ˜¯(N,4)æˆ–(N,5)ï¼Œä¿æŒåŸæ ·ï¼‰
            # (N,5)æ ¼å¼ï¼šx, y, z, intensity, timestampï¼ˆç”¨äºå»ç•¸å˜ï¼‰
            # (N,4)æ ¼å¼ï¼šx, y, z, intensityï¼ˆå·²ç»å»ç•¸å˜æˆ–æ— timestampï¼‰
            if points.shape[1] == 3:
                # æ·»åŠ å¼ºåº¦é€šé“ï¼ˆå…¨0ï¼‰
                intensity = np.zeros((points.shape[0], 1), dtype=np.float32)
                points = np.hstack([points, intensity])
            
            # ä¿å­˜ä¸º BIN æ ¼å¼
            points.astype(np.float32).tofile(str(filepath))
            
            self.pc_metadata.append(PointCloudMetadata(
                timestamp=ts,
                file_path=str(filepath)
            ))
            self.pc_counter += 1
            
            del points  # ç«‹å³é‡Šæ”¾
    
    def _extract_string_msg(self, rawdata: bytes) -> Optional[bytes]:
        """æå– std_msgs/String"""
        try:
            if len(rawdata) < 4:
                return None
            length = struct.unpack('<I', rawdata[:4])[0]
            if 0 < length < len(rawdata):
                return rawdata[4:4+length]
            return rawdata
        except:
            return rawdata
    
    def _decode_pose_msg(self, msg, fallback_timestamp: float = None) -> Optional[PoseMetadata]:
        """è§£ç ä½å§¿æ¶ˆæ¯ï¼ˆprotobuf æ ¼å¼ï¼‰- å‚è€ƒSelf-Cali-GSå®ç°"""
        try:
            if hasattr(msg, 'data'):
                data = msg.data
                if isinstance(data, str):
                    data = data.encode('latin-1')
                elif not isinstance(data, bytes):
                    return None
                
                # æå– String åŒ…è£…
                data = self._extract_string_msg(data)
                if not data or len(data) < 48:  # è‡³å°‘éœ€è¦6ä¸ªdouble (position+euler)
                    return None
                
                # å°è¯•wire formatè§£æ (å‚è€ƒSelf-Cali-GS)
                position, euler_angles, timestamp = self._parse_proto_localization_wire(data)
                
                if position is not None and euler_angles is not None:
                    # âœ… éªŒè¯positionä¸æ˜¯å…¨é›¶ï¼ˆå‚è€ƒSelf-Cali-GSï¼‰
                    if np.max(np.abs(position)) < 1e-6:
                        return None  # positionå…¨é›¶ï¼Œæ— æ•ˆæ•°æ®
                    
                    # ä»æ¬§æ‹‰è§’è®¡ç®—å››å…ƒæ•°
                    r = R.from_euler('xyz', euler_angles, degrees=False)
                    orientation = r.as_quat()  # [x, y, z, w]
                    
                    # å¦‚æœæ²¡æœ‰æå–åˆ°æ—¶é—´æˆ³ï¼Œä½¿ç”¨fallback
                    if timestamp is None:
                        timestamp = fallback_timestamp
                    
                    if timestamp is None:
                        return None
                    
                    return PoseMetadata(
                        timestamp=timestamp,
                        position=position,
                        orientation=orientation
                    )
            
            return None
        except Exception as e:
            return None
    
    def _parse_proto_localization_wire(self, data: bytes) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[float]]:
        """æŒ‰ç…§wire formatè§£æå®šä½protoï¼ˆå®Œå…¨å¯¹é½Self-Cali-GSå®ç°ï¼‰
        
        Returns:
            (position, euler_angles, timestamp)
        """
        position = None
        euler_angles = None
        timestamp = None
        
        try:
            # è·³è¿‡DeepRouteçš„é¢å¤–header: $$$$ + <4 bytes length>
            if data[:4] == b'$$$$':
                if len(data) < 8:
                    return None, None, None
                data = data[8:]  # è·³è¿‡4å­—èŠ‚marker + 4å­—èŠ‚length
            # æ–¹æ³•1: å°è¯•JSONæ ¼å¼ï¼ˆæŸäº›bagä½¿ç”¨JSONï¼‰
            try:
                text = data.decode('utf-8', errors='ignore').strip()
                if text.startswith('{'):
                    import json
                    j = json.loads(text)
                    
                    # æå–timestamp
                    if 'measurement_time' in j:
                        timestamp = float(j['measurement_time']) / 1e6
                    
                    # æå–position
                    if 'position' in j:
                        p = j['position']
                        if isinstance(p, dict):
                            position = np.array([float(p.get('x', 0)), float(p.get('y', 0)), float(p.get('z', 0))])
                        elif isinstance(p, (list, tuple)):
                            position = np.array([float(p[0]), float(p[1]), float(p[2])])
                    
                    # æå–euler_angles
                    if 'euler_angles' in j:
                        e = j['euler_angles']
                        if isinstance(e, dict):
                            euler_angles = np.array([float(e.get('x', 0)), float(e.get('y', 0)), float(e.get('z', 0))])
                        else:
                            euler_angles = np.array([float(e[0]), float(e[1]), float(e[2])])
                    
                    if position is not None and euler_angles is not None:
                        return position, euler_angles, timestamp
            except:
                pass
            
            # æ–¹æ³•2: Wire formatè§£æ
            i = 0
            while i < len(data) - 1:
                tag = data[i]
                i += 1
                
                field_number = tag >> 3
                wire_type = tag & 0x7
                
                if wire_type == 0:  # Varint
                    while i < len(data):
                        byte = data[i]
                        i += 1
                        if (byte & 0x80) == 0:
                            break
                elif wire_type == 1:  # Fixed64 (sfixed64, double)
                    if i + 8 > len(data):
                        break
                    val = struct.unpack_from('<q', data, i)[0]  # int64
                    i += 8
                    # field 2 é€šå¸¸æ˜¯ measurement_time (å¾®ç§’)
                    if field_number == 2 and 1.5e15 < val < 2e15:
                        timestamp = float(val) / 1e6  # å¾®ç§’ â†’ ç§’ï¼ˆæ˜¾å¼è½¬æ¢ï¼‰
                elif wire_type == 2:  # Length-delimited
                    if i >= len(data):
                        break
                    # è¯»å–é•¿åº¦
                    length = 0
                    shift = 0
                    while i < len(data):
                        byte = data[i]
                        i += 1
                        length |= (byte & 0x7F) << shift
                        if (byte & 0x80) == 0:
                            break
                        shift += 7
                    
                    if i + length > len(data):
                        break
                    
                    payload = data[i:i+length]
                    i += length
                    
                    # Point3D å¯èƒ½æ˜¯24 bytes (3ä¸ªçº¯double) æˆ– 27 bytes (å¸¦tagçš„double)
                    if length == 24:
                        try:
                            coords = struct.unpack_from('<ddd', payload, 0)
                            if field_number == 5:  # position
                                position = np.array(coords, dtype=float)
                            elif field_number == 6:  # euler_angles
                                euler_angles = np.array(coords, dtype=float)
                        except:
                            pass
                    elif length == 27:
                        # DeepRouteæ ¼å¼: æ¯ä¸ªdoubleå‰æœ‰tag (field + wire_type)
                        # tag (1 byte) + double (8 bytes) = 9 bytes per value
                        try:
                            j = 0
                            coords = []
                            while j < len(payload) - 8:
                                if (payload[j] & 0x7) == 1:  # Fixed64 (double)
                                    val = struct.unpack_from('<d', payload, j+1)[0]
                                    coords.append(val)
                                    j += 9
                                else:
                                    j += 1
                            
                            if len(coords) == 3:
                                if field_number == 5:  # position
                                    position = np.array(coords, dtype=float)
                                elif field_number == 6:  # euler_angles
                                    euler_angles = np.array(coords, dtype=float)
                        except:
                            pass
                elif wire_type == 5:  # Fixed32
                    if i + 4 > len(data):
                        break
                    i += 4
                else:
                    break
            
            # æ–¹æ³•3: Fallbackå¯å‘å¼æœç´¢ - æœç´¢è¿ç»­6ä¸ªdouble (position+euler)
            # è¿™æ˜¯æœ€é²æ£’çš„æ–¹æ³•ï¼Œå¯¹é½Self-Cali-GS
            if position is None or euler_angles is None:
                for i in range(0, len(data) - 47, 1):
                    try:
                        d = [struct.unpack_from('<d', data, i + k * 8)[0] for k in range(6)]
                        # Self-Cali-GSçš„éªŒè¯æ¡ä»¶ï¼ˆåŠ å¼ºç‰ˆï¼‰ï¼š
                        # 1. positionåœ¨åˆç†èŒƒå›´å†…ï¼ˆ< 1e6ç±³ï¼Œå³1000å…¬é‡Œï¼‰
                        # 2. eulerè§’åº¦åº”åœ¨ [-4, 4] èŒƒå›´å†…ï¼ˆ~Â±229åº¦ï¼‰
                        if not all(abs(v) < 1e6 and not (np.isnan(v) or np.isinf(v)) for v in d[0:3]):
                            continue
                        if not all(abs(v) < 4 for v in d[3:6]):  # euleræ›´ä¸¥æ ¼
                            continue
                        
                        position = np.array(d[0:3], dtype=float)
                        euler_angles = np.array(d[3:6], dtype=float)
                        
                        # æœç´¢timestampï¼ˆåœ¨æ‰¾åˆ°pos+eulerä¹‹åï¼‰
                        if timestamp is None:
                            for j in range(0, min(i, len(data) - 8)):
                                try:
                                    v = struct.unpack_from('<q', data, j)[0]  # int64
                                    if 1.5e15 < v < 2e15:
                                        timestamp = float(v) / 1e6  # å¾®ç§’ â†’ ç§’ï¼ˆæ˜¾å¼è½¬æ¢ï¼‰
                                        break
                                except:
                                    continue
                        break
                    except:
                        continue
            
            # æ–¹æ³•4: åªæœç´¢euler_angles (3ä¸ªdouble)ï¼Œä½œä¸ºæœ€åçš„fallback
            if position is None and euler_angles is None:
                for i in range(0, len(data) - 23, 1):
                    try:
                        d = [struct.unpack_from('<d', data, i + k * 8)[0] for k in range(3)]
                        if all(abs(v) < 4 for v in d):  # eulerèŒƒå›´æ£€æŸ¥
                            euler_angles = np.array(d, dtype=float)
                            # å¦‚æœåªæœ‰eulerï¼Œpositionè®¾ä¸ºé›¶ï¼ˆè™½ç„¶ä¸ç†æƒ³ï¼‰
                            break
                    except:
                        continue
            
            # æœ€åæœç´¢æ—¶é—´æˆ³ï¼ˆå¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼‰
            if timestamp is None:
                for i in range(0, len(data) - 8, 1):
                    try:
                        val = struct.unpack_from('<q', data, i)[0]  # int64
                        if 1.5e15 < val < 2e15:  # å¾®ç§’èŒƒå›´éªŒè¯
                            timestamp = float(val) / 1e6  # å¾®ç§’ â†’ ç§’ï¼ˆæ˜¾å¼è½¬æ¢ï¼‰
                            break
                    except:
                        continue
            
            return position, euler_angles, timestamp
            
        except Exception:
            return None, None, None
    
    def _extract_proto_timestamp(self, data: bytes) -> Optional[float]:
        """ä» protobuf ä¸­æå–æ—¶é—´æˆ³"""
        try:
            # æŸ¥æ‰¾æ—¶é—´æˆ³ï¼ˆé€šå¸¸æ˜¯ int64 æˆ– doubleï¼‰
            # Protobuf tag for timestamp é€šå¸¸æ˜¯ field 3 æˆ– 4
            for i in range(min(200, len(data) - 8)):
                try:
                    # å°è¯•è¯»å–ä¸º uint64 (nanoseconds since epoch)
                    ts_ns = struct.unpack('<Q', data[i:i+8])[0]
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆç†çš„æ—¶é—´æˆ³ï¼ˆ2020-2030å¹´ï¼‰
                    if 1577836800e9 < ts_ns < 1893456000e9:
                        return ts_ns / 1e9
                    
                    # å°è¯•è¯»å–ä¸º double (seconds since epoch)
                    ts_sec = struct.unpack('<d', data[i:i+8])[0]
                    if 1577836800 < ts_sec < 1893456000:
                        return ts_sec
                except:
                    pass
            
            return None
        except:
            return None
    
    def _decode_image(self, rawdata: bytes) -> Optional[np.ndarray]:
        """è§£ç å›¾åƒï¼ˆrosbagsï¼‰"""
        try:
            data = self._extract_string_msg(rawdata)
            if not data:
                return None
            
            # JPEG
            jpeg_start = data.find(b'\xff\xd8')
            if jpeg_start != -1:
                jpeg_end = data.rfind(b'\xff\xd9')
                if jpeg_end > jpeg_start:
                    img_array = np.frombuffer(data[jpeg_start:jpeg_end+2], np.uint8)
                    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                    if image is not None:
                        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # PNG
            png_start = data.find(b'\x89PNG')
            if png_start != -1:
                img_array = np.frombuffer(data[png_start:], np.uint8)
                image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                if image is not None:
                    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except:
            pass
        return None
    
    def _decode_image_msg_from_bytes(self, data: bytes) -> Optional[np.ndarray]:
        """ä»bytesè§£ç å›¾åƒ"""
        try:
            jpeg_start = data.find(b'\xff\xd8')
            if jpeg_start != -1:
                jpeg_end = data.rfind(b'\xff\xd9')
                if jpeg_end > jpeg_start:
                    img_array = np.frombuffer(data[jpeg_start:jpeg_end+2], np.uint8)
                    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                    if image is not None:
                        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except:
            pass
        return None
    
    def _decode_image_msg(self, msg) -> Optional[np.ndarray]:
        """è§£ç å›¾åƒï¼ˆrosbagï¼‰"""
        try:
            if hasattr(msg, 'data'):
                data = msg.data
                if isinstance(data, str):
                    data = data.encode('latin-1')
                elif not isinstance(data, bytes):
                    return None
                return self._decode_image_msg_from_bytes(data)
        except:
            pass
        return None
    
    def _process_single_frame(self, args):
        """å¤„ç†å•å¸§æ•°æ®ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰"""
        idx, img_idx, pc_idx, image_dir, velodyne_dir = args
        
        # å¤åˆ¶å›¾åƒ
        src_img = Path(self.image_metadata[img_idx].file_path)
        dst_img = image_dir / f"{idx:06d}.png"
        img = Image.open(src_img)
        img.save(dst_img)
        
        # è¯»å–å¹¶å»ç•¸å˜ç‚¹äº‘
        src_pc = Path(self.pc_metadata[pc_idx].file_path)
        dst_pc = velodyne_dir / f"{idx:06d}.bin"
        
        # è¯»å–åŸå§‹ç‚¹äº‘
        points_data = np.fromfile(str(src_pc), dtype=np.float32)
        
        # åˆ¤æ–­æ˜¯å¦æœ‰timestampï¼ˆ5åˆ—ï¼‰
        if len(points_data) % 5 == 0:
            # (N, 5): x, y, z, intensity, timestamp
            points_raw = points_data.reshape(-1, 5)
            
            if self.pose_metadata and len(self.pose_metadata) > 0:
                # æœ‰poseæ•°æ®ï¼Œåº”ç”¨å»ç•¸å˜
                # âœ… å»ç•¸å˜åŸç†ï¼šå°†ç‚¹äº‘ä»æ¿€å…‰é›·è¾¾æ‰«ææ—¶åˆ»(cloud_ts)è½¬æ¢åˆ°å›¾åƒæ—¶åˆ»(target_ts)
                # âœ… å»ç•¸å˜åçš„ç‚¹äº‘åœ¨ç©ºé—´ä¸Šå¯¹åº”äºå›¾åƒæ—¶åˆ»ï¼Œæ¶ˆé™¤äº†è¿åŠ¨ç•¸å˜
                cloud_ts = self.pc_metadata[pc_idx].timestamp  # LiDARæ‰«æå¼€å§‹æ—¶åˆ»
                target_ts = self.image_metadata[img_idx].timestamp  # å›¾åƒæ›å…‰æ—¶åˆ»ï¼ˆç›®æ ‡å¯¹é½æ—¶åˆ»ï¼‰
                
                # ğŸ” æ·»åŠ è°ƒè¯•ä¿¡æ¯
                if idx == 0:  # åªåœ¨ç¬¬ä¸€å¸§æ‰“å°
                    print(f"\nğŸ” å»ç•¸å˜è°ƒè¯•ä¿¡æ¯ï¼ˆFrame {idx}ï¼‰ - å®Œå…¨å¯¹é½C++:")
                    print(f"  cloud_ts: {cloud_ts:.6f}")
                    print(f"  target_ts: {target_ts:.6f}")
                    print(f"  æ—¶é—´å·®: {abs(target_ts - cloud_ts)*1000:.1f}ms")
                    print(f"  å‡è®¾ï¼šLiDARç³» = Sensingç³» (iso_vehicle_lidar = Identity)")
                    print(f"  posesæ˜¯Sensingâ†’Worldå˜æ¢ï¼ˆSensingåœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰")
                
                # ç‚¹äº‘å»ç•¸å˜ï¼ˆposeså·²ç»æ˜¯Sensingç³»ï¼ŒLiDARç³»=Sensingç³»ï¼‰
                points_undistorted = UndistortionUtils.undistort_pointcloud(
                    points_raw, cloud_ts, target_ts, self.pose_metadata,
                    debug=(idx == 0)  # åªåœ¨ç¬¬ä¸€å¸§å¯ç”¨è¯¦ç»†è°ƒè¯•
                )
                
                # ğŸ” æ‰“å°å»ç•¸å˜å‰åçš„ç‚¹äº‘èŒƒå›´
                if idx == 0:
                    print(f"\n  å»ç•¸å˜å‰ç‚¹äº‘èŒƒå›´:")
                    print(f"    X: [{points_raw[:, 0].min():.2f}, {points_raw[:, 0].max():.2f}]")
                    print(f"    Y: [{points_raw[:, 1].min():.2f}, {points_raw[:, 1].max():.2f}]")
                    print(f"    Z: [{points_raw[:, 2].min():.2f}, {points_raw[:, 2].max():.2f}]")
                    print(f"  å»ç•¸å˜åç‚¹äº‘èŒƒå›´:")
                    print(f"    X: [{points_undistorted[:, 0].min():.2f}, {points_undistorted[:, 0].max():.2f}]")
                    print(f"    Y: [{points_undistorted[:, 1].min():.2f}, {points_undistorted[:, 1].max():.2f}]")
                    print(f"    Z: [{points_undistorted[:, 2].min():.2f}, {points_undistorted[:, 2].max():.2f}]")
                    
                    # æ£€æŸ¥ç‚¹äº‘æ˜¯å¦æœ‰å¼‚å¸¸å¤§çš„å˜åŒ–
                    max_shift = np.abs(points_undistorted[:, :3] - points_raw[:, :3]).max()
                    print(f"  æœ€å¤§ä½ç§»: {max_shift:.2f}m")
                    if max_shift > 10.0:
                        print(f"  âš ï¸  è­¦å‘Šï¼šä½ç§»è¿‡å¤§ï¼ˆ>{max_shift:.1f}mï¼‰ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜ï¼")
            else:
                # æ²¡æœ‰poseæ•°æ®ï¼Œç›´æ¥ä½¿ç”¨å‰4åˆ—
                points_undistorted = points_raw[:, :4]
                print(f"  âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰poseæ•°æ®, æ•°æ®å¼‚å¸¸ï¼Œç›´æ¥ä½¿ç”¨å‰4åˆ—")
        elif len(points_data) % 4 == 0:
            # (N, 4): x, y, z, intensityï¼Œæ— timestamp
            points_raw = points_data.reshape(-1, 4)
            points_undistorted = points_raw
        else:
            return False  # æ ¼å¼å¼‚å¸¸
        
        # âœ… å…³é”®ä¿®å¤ï¼šå°†ç‚¹äº‘ä»Sensingç³»è½¬æ¢åˆ°LiDARç³»
        # KITTI-Odometryæ ‡å‡†è¦æ±‚ç‚¹äº‘åœ¨LiDARç³»ï¼Œè¿™æ ·æŠ•å½±æ—¶å¯ä»¥ç›´æ¥ä½¿ç”¨Trï¼ˆLiDARâ†’Cameraï¼‰
        # å˜æ¢é“¾ï¼šSensingç³» â†’ LiDARç³»
        # P_lidar = T_lidar_to_sensing @ P_sensing
        
        # è½¬æ¢ç‚¹äº‘åˆ°LiDARç³»ï¼ˆä½¿ç”¨C++å‘½åçº¦å®šï¼‰
        points_homo = np.hstack([points_undistorted[:, :3], np.ones((points_undistorted.shape[0], 1))])
        points_lidar = (self.T_lidar_to_sensing @ points_homo.T).T  # (N, 4)
        
        # ç»„åˆä¸ºæœ€ç»ˆç‚¹äº‘ï¼š[x, y, z, intensity]ï¼ˆLiDARç³»ï¼‰
        points_final = np.hstack([points_lidar[:, :3], points_undistorted[:, 3:4]])
        
        if idx == 0 and self.verbose:
            print(f"\n  è½¬æ¢åˆ°LiDARç³»:")
            print(f"    å»ç•¸å˜åï¼ˆSensingç³»ï¼‰èŒƒå›´:")
            print(f"      X: [{points_undistorted[:, 0].min():.2f}, {points_undistorted[:, 0].max():.2f}]")
            print(f"      Y: [{points_undistorted[:, 1].min():.2f}, {points_undistorted[:, 1].max():.2f}]")
            print(f"      Z: [{points_undistorted[:, 2].min():.2f}, {points_undistorted[:, 2].max():.2f}]")
            print(f"    è½¬æ¢åï¼ˆLiDARç³»ï¼‰èŒƒå›´:")
            print(f"      X: [{points_final[:, 0].min():.2f}, {points_final[:, 0].max():.2f}]")
            print(f"      Y: [{points_final[:, 1].min():.2f}, {points_final[:, 1].max():.2f}]")
            print(f"      Z: [{points_final[:, 2].min():.2f}, {points_final[:, 2].max():.2f}]")
        
        # ä¿å­˜ç‚¹äº‘ï¼ˆLiDARç³»ï¼Œç¬¦åˆKITTIæ ‡å‡†ï¼‰
        # æ ¼å¼ï¼š(N, 4) = [x, y, z, intensity]
        points_final.astype(np.float32).tofile(str(dst_pc))
        return True
    
    def sync_and_save(self, sequence_id: str = "00"):
        """åŒæ­¥å¹¶ç”Ÿæˆæœ€ç»ˆæ•°æ®é›†ï¼ˆå‚è€ƒC++çš„GetSyncCalibrationDataé€»è¾‘ï¼‰
        
        å‚è€ƒï¼šlidar_online_calibrator.cpp:525-744
        - ä¸¥æ ¼ä½¿ç”¨motion_interpolateè¿›è¡Œä½å§¿æ’å€¼
        - å¦‚æœæ’å€¼å¤±è´¥ï¼Œè·³è¿‡è¯¥å¸§ï¼ˆä¸åšæ—¶é—´æˆ³æ ¡æ­£ï¼‰
        - ä½¿ç”¨æ—¶é—´å·®é˜ˆå€¼è¿›è¡Œæ•°æ®å¯¹é½ï¼ˆkMaxLidarCameraDelta=55msï¼‰
        
        ğŸ¯ æ—¶é—´å¯¹é½åŸç†ï¼š
            1. æ¯ä¸€å¸§æ•°æ®çš„é€»è¾‘æ—¶åˆ» = å›¾åƒæ›å…‰æ—¶åˆ» (image_timestamp)
            2. ç‚¹äº‘é€šè¿‡å»ç•¸å˜ä»LiDARæ‰«ææ—¶åˆ»è½¬æ¢åˆ°å›¾åƒæ—¶åˆ»
            3. ä½å§¿ä½¿ç”¨motion_interpolateæ’å€¼åˆ°å›¾åƒæ—¶åˆ»
            4. æœ€ç»ˆï¼šå›¾åƒã€ç‚¹äº‘ã€ä½å§¿ åœ¨å›¾åƒæ—¶åˆ»å®Œå…¨å¯¹é½
        """
        print(f"\n{'='*80}")
        print(f"é˜¶æ®µ 2/3: åŒæ­¥æ•°æ®")
        print(f"{'='*80}")
        
        sync_start_time = time.time()
        
        if not self.image_metadata or not self.pc_metadata:
            raise ValueError("å›¾åƒæˆ–ç‚¹äº‘æ•°æ®ä¸ºç©º")
        
        # æ‰“å°æ—¶é—´æˆ³èŒƒå›´ç”¨äºè¯Šæ–­
        if self.pose_metadata:
            data_ts_min = min(self.image_metadata[0].timestamp, self.pc_metadata[0].timestamp)
            data_ts_max = max(self.image_metadata[-1].timestamp, self.pc_metadata[-1].timestamp)
            pose_ts_min = self.pose_metadata[0].timestamp
            pose_ts_max = self.pose_metadata[-1].timestamp
            
            print(f"\næ—¶é—´æˆ³èŒƒå›´:")
            print(f"  æ•°æ®: [{data_ts_min:.3f}, {data_ts_max:.3f}]")
            print(f"  ä½å§¿: [{pose_ts_min:.3f}, {pose_ts_max:.3f}]")
            
            if data_ts_min < pose_ts_min or data_ts_max > pose_ts_max:
                print(f"  âš ï¸  è­¦å‘Š: æ•°æ®æ—¶é—´æˆ³è¶…å‡ºä½å§¿èŒƒå›´ï¼Œè¿™äº›å¸§å°†è·³è¿‡å»ç•¸å˜")
                print(f"     å‚è€ƒC++å®ç°ï¼Œmotion_interpolateå¤±è´¥æ—¶ä¼šè·³è¿‡è¯¥å¸§")
        
        # åˆ›å»ºæœ€ç»ˆç›®å½•
        seq_dir = self.output_dir / 'sequences' / sequence_id
        seq_dir.mkdir(parents=True, exist_ok=True)
        image_dir = seq_dir / 'image_2'
        velodyne_dir = seq_dir / 'velodyne'
        image_dir.mkdir(exist_ok=True)
        velodyne_dir.mkdir(exist_ok=True)
        
        # ========================================================================
        # åŒæ­¥å›¾åƒå’Œç‚¹äº‘ - å®Œå…¨å¯¹é½C++ get_sync_obstacles_innerå®ç°
        # ========================================================================
        synced_pairs = []
        rejected_pairs = 0  # ç»Ÿè®¡å› æ—¶é—´å·®è¿‡å¤§è€Œè¢«æ‹’ç»çš„å¯¹æ•°
        rejected_details = []  # å­˜å‚¨æ‹’ç»é…å¯¹çš„è¯¦ç»†ä¿¡æ¯
        
        img_idx = 0
        pc_idx = 0
        
        print(f"\nå¼€å§‹åŒæ­¥ï¼ˆå¯¹é½C++å®ç°ï¼‰:")
        print(f"  å›¾åƒæ•°é‡: {len(self.image_metadata)}")
        print(f"  ç‚¹äº‘æ•°é‡: {len(self.pc_metadata)}")
        print(f"  åŒæ­¥é˜ˆå€¼: {self.max_time_diff*1000:.0f}ms (kMaxLidarCameraDelta)")
        
        with tqdm(total=min(len(self.image_metadata), len(self.pc_metadata)),
                 desc="åŒæ­¥æ•°æ®") as pbar:
            while img_idx < len(self.image_metadata) and pc_idx < len(self.pc_metadata):
                # è·å–å½“å‰å›¾åƒå’Œç‚¹äº‘çš„æ—¶é—´æˆ³ï¼ˆå¾®ç§’ï¼‰
                image_time = self.image_metadata[img_idx].timestamp
                cloud_time = self.pc_metadata[pc_idx].timestamp
                
                # âœ… C++é€»è¾‘ï¼šæ‰¾åˆ°æœ€å¤§æ—¶é—´æˆ³ä½œä¸ºå‚è€ƒç‚¹
                max_stamp = max(image_time, cloud_time)
                stamp_lower_bound = max_stamp - self.max_time_diff
                
                # âœ… C++é€»è¾‘ï¼šç§»é™¤è¿‡æ—§çš„æ•°æ®ï¼ˆæ—¶é—´æˆ³ < max_stamp - kMaxLidarCameraDeltaï¼‰
                is_data_sync = True
                
                if image_time < stamp_lower_bound:
                    # å›¾åƒè¿‡æ—§ï¼Œè·³è¿‡
                    img_idx += 1
                    is_data_sync = False
                    pbar.update(1)
                    continue
                
                if cloud_time < stamp_lower_bound:
                    # ç‚¹äº‘è¿‡æ—§ï¼Œè·³è¿‡
                    pc_idx += 1
                    is_data_sync = False
                    pbar.update(1)
                    continue
                
                # âœ… C++é€»è¾‘ï¼šæ£€æŸ¥å›¾åƒå’Œç‚¹äº‘çš„æ—¶é—´å·®
                lidar_camera_delta = abs(image_time - cloud_time)
                
                if lidar_camera_delta <= self.max_time_diff:
                    # æ—¶é—´å·®åœ¨é˜ˆå€¼å†…ï¼Œé…å¯¹æˆåŠŸ
                    synced_pairs.append((img_idx, pc_idx))
                    img_idx += 1
                    pc_idx += 1
                    pbar.update(1)
                else:
                    # æ—¶é—´å·®è¿‡å¤§ï¼Œç§»é™¤æ—¶é—´æˆ³è¾ƒå°çš„é‚£ä¸ª
                    rejected_pairs += 1
                    delta_ms = lidar_camera_delta * 1000
                    exceed_ms = delta_ms - self.max_time_diff * 1000
                    rejected_details.append((img_idx, pc_idx, delta_ms, exceed_ms))
                    
                    if image_time < cloud_time:
                        img_idx += 1
                    else:
                        pc_idx += 1
                    pbar.update(1)
        
        # å…³é”®ï¼šè¿‡æ»¤æ‰æ—¶é—´æˆ³åœ¨poseèŒƒå›´ä¹‹å¤–çš„å¸§ï¼ˆå‚è€ƒæ‚¨çš„æŒ‡ç¤ºï¼‰
        if self.pose_metadata:
            pose_ts_min = self.pose_metadata[0].timestamp
            pose_ts_max = self.pose_metadata[-1].timestamp
            
            synced_pairs_filtered = []
            for img_idx, pc_idx in synced_pairs:
                pc_ts = self.pc_metadata[pc_idx].timestamp
                # æ£€æŸ¥ç‚¹äº‘æ—¶é—´æˆ³æ˜¯å¦åœ¨poseèŒƒå›´å†…
                # æ³¨æ„ï¼šè¿˜è¦è€ƒè™‘ç‚¹äº‘æ‰«æçš„end_timestamp
                temp_pc_file = self.temp_dir / 'pointclouds' / f'{pc_idx:06d}.bin'
                if temp_pc_file.exists():
                    points_raw = np.fromfile(temp_pc_file, dtype=np.float32).reshape(-1, 5)
                    if points_raw.shape[0] > 0 and points_raw.shape[1] >= 5:
                        max_inner_ts_us = points_raw[:, 4].max()
                        delta_time_us = max_inner_ts_us * 2
                        end_ts = pc_ts + delta_time_us * 1e-6
                        
                        # start, end, target éƒ½éœ€è¦åœ¨poseèŒƒå›´å†…
                        img_ts = self.image_metadata[img_idx].timestamp
                        if (pc_ts >= pose_ts_min and pc_ts <= pose_ts_max and
                            end_ts >= pose_ts_min and end_ts <= pose_ts_max and
                            img_ts >= pose_ts_min and img_ts <= pose_ts_max):
                            synced_pairs_filtered.append((img_idx, pc_idx))
            
            if len(synced_pairs_filtered) < len(synced_pairs):
                print(f"\n  âš ï¸  è¿‡æ»¤æ—¶é—´æˆ³è¶…å‡ºposeèŒƒå›´çš„å¸§: {len(synced_pairs)} â†’ {len(synced_pairs_filtered)}")
            synced_pairs = synced_pairs_filtered
        
        # âœ… å¯é€‰ï¼šåŸºäºtarget_fpsè¿›è¡Œé™é‡‡æ ·ï¼ˆå¦‚æœåŒæ­¥å¸§æ•°è¿‡å¤šï¼‰
        if len(synced_pairs) > 0 and self.target_fps is not None:
            # è®¡ç®—åŸå§‹å¸§ç‡
            if len(synced_pairs) >= 2:
                first_img_idx, first_pc_idx = synced_pairs[0]
                last_img_idx, last_pc_idx = synced_pairs[-1]
                # æ—¶é—´è·¨åº¦ï¼ˆlast_idx >= first_idx æ€»æ˜¯æˆç«‹ï¼Œæ‰€ä»¥ä¸éœ€è¦absï¼‰
                time_span = (self.image_metadata[last_img_idx].timestamp - 
                            self.image_metadata[first_img_idx].timestamp)
                if time_span > 0:  # é˜²æ­¢é™¤é›¶ï¼ˆæç«¯æƒ…å†µï¼šæ‰€æœ‰å¸§æ—¶é—´æˆ³ç›¸åŒï¼‰
                    original_fps = (len(synced_pairs) - 1) / time_span
                    
                    # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°é™é‡‡æ ·åˆ¤æ–­çš„è¯¦ç»†ä¿¡æ¯
                    print(f"\n  é™é‡‡æ ·åˆ¤æ–­:")
                    print(f"    åŒæ­¥å¸§æ•°: {len(synced_pairs)}")
                    print(f"    æ—¶é—´è·¨åº¦: {time_span:.3f}s")
                    print(f"    åŸå§‹å¸§ç‡: {original_fps:.2f} fps")
                    print(f"    ç›®æ ‡å¸§ç‡: {self.target_fps:.1f} fps")
                    
                    # å¦‚æœåŸå§‹å¸§ç‡ > target_fpsï¼Œè¿›è¡Œé™é‡‡æ ·
                    if original_fps > self.target_fps:
                        target_interval = 1.0 / self.target_fps
                        downsampled_pairs = []
                        last_selected_time = -float('inf')
                        
                        for img_idx, pc_idx in synced_pairs:
                            current_time = self.image_metadata[img_idx].timestamp
                            if current_time - last_selected_time >= target_interval:
                                downsampled_pairs.append((img_idx, pc_idx))
                                last_selected_time = current_time
                        
                        if len(downsampled_pairs) < len(synced_pairs):
                            print(f"\n  ğŸ“‰ é™é‡‡æ ·: {len(synced_pairs)} â†’ {len(downsampled_pairs)} å¸§ (ç›®æ ‡: {self.target_fps:.1f} fps)")
                            synced_pairs = downsampled_pairs
                    else:
                        print(f"    âœ“ æ— éœ€é™é‡‡æ ·ï¼ˆåŸå§‹å¸§ç‡ <= ç›®æ ‡å¸§ç‡ï¼‰")
        
        # æ‰“å°åŒæ­¥ç»Ÿè®¡ï¼ˆå‚è€ƒC++ kMaxLidarCameraDeltaï¼‰
        print(f"\nåŒæ­¥ç»Ÿè®¡:")
        print(f"  æˆåŠŸé…å¯¹: {len(synced_pairs)} å¸§")
        if rejected_pairs > 0:
            print(f"  æ‹’ç»é…å¯¹: {rejected_pairs} å¯¹ï¼ˆlidar-cameraæ—¶é—´å·® > {self.max_time_diff*1000:.0f}msï¼‰")
            # æ‰“å°æ¯ä¸ªè¢«æ‹’ç»é…å¯¹çš„è¯¦ç»†ä¿¡æ¯
            for img_idx, pc_idx, delta_ms, exceed_ms in rejected_details[:10]:  # æœ€å¤šæ˜¾ç¤ºå‰10ä¸ª
                print(f"    - å›¾åƒ#{img_idx:04d} & ç‚¹äº‘#{pc_idx:04d}: Î”t={delta_ms:.1f}ms (è¶…å‡º{exceed_ms:.1f}ms)")
            if len(rejected_details) > 10:
                print(f"    ... è¿˜æœ‰ {len(rejected_details)-10} ä¸ªè¢«æ‹’ç»çš„é…å¯¹")
        
        # é™åˆ¶å¤„ç†å¸§æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        if self.max_frames is not None and len(synced_pairs) > self.max_frames:
            print(f"  âš ï¸  é™åˆ¶å¤„ç†å¸§æ•°: {len(synced_pairs)} â†’ {self.max_frames}")
            synced_pairs = synced_pairs[:self.max_frames]
        
        sync_time = time.time() - sync_start_time
        
        print(f"\nâœ“ åŒæ­¥å®Œæˆ:")
        print(f"  åŒæ­¥å¯¹æ•°: {len(synced_pairs)}")
        print(f"  è€—æ—¶: {timedelta(seconds=int(sync_time))}")
        print(f"  é€Ÿåº¦: {len(synced_pairs) / sync_time:.2f} å¯¹/ç§’")
        
        # ä¿å­˜æœ€ç»ˆæ•°æ®é›†ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
        print(f"\n{'='*80}")
        print(f"é˜¶æ®µ 3/3: å»ç•¸å˜å¹¶ä¿å­˜ (ä½¿ç”¨ {self.num_workers} ä¸ªçº¿ç¨‹)")
        print(f"{'='*80}")
        
        save_start_time = time.time()
        
        # å‡†å¤‡å¹¶è¡Œä»»åŠ¡å‚æ•°
        tasks = [
            (idx, img_idx, pc_idx, image_dir, velodyne_dir)
            for idx, (img_idx, pc_idx) in enumerate(synced_pairs)
        ]
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼ˆI/Oå¯†é›†å‹ä»»åŠ¡ï¼Œçº¿ç¨‹æ± æ›´åˆé€‚ï¼‰
        results = []
        with ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            futures = [executor.submit(self._process_single_frame, task) for task in tasks]
            for future in tqdm(futures, desc="  å¤„ç†è¿›åº¦", total=len(tasks)):
                results.append(future.result())
        
        save_time = time.time() - save_start_time
        
        failed_count = sum(1 for r in results if not r)
        
        print(f"\nâœ“ å»ç•¸å˜å’Œä¿å­˜å®Œæˆ:")
        print(f"  æˆåŠŸ: {len(results) - failed_count} å¸§")
        if failed_count > 0:
            print(f"  å¤±è´¥: {failed_count} å¸§")
        print(f"  è€—æ—¶: {timedelta(seconds=int(save_time))}")
        print(f"  é€Ÿåº¦: {len(results) / save_time:.2f} å¸§/ç§’")
        print(f"  å¹³å‡: {save_time / len(results):.2f} ç§’/å¸§")
        
        # ä¿å­˜æ ‡å®šæ–‡ä»¶
        self._save_calib_file(seq_dir)
        
        # ä¿å­˜ä½å§¿æ–‡ä»¶
        if self.pose_metadata:
            self._save_poses_file(synced_pairs, sequence_id)
        else:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ä½å§¿æ•°æ®ï¼Œè·³è¿‡ poses æ–‡ä»¶ç”Ÿæˆ")
        
        # ä¿å­˜æ—¶é—´æˆ³æ–‡ä»¶
        self._save_times_file(synced_pairs, seq_dir)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        # æ³¨æ„ï¼šå¦‚æœéœ€è¦éªŒè¯å»ç•¸å˜æ•ˆæœï¼Œè¯·ä¿ç•™tempç›®å½•
        # temp/pointclouds/ ä¸­å­˜å‚¨çš„æ˜¯å»ç•¸å˜å‰çš„åŸå§‹ç‚¹äº‘
        print(f"\nğŸ’¡ æç¤º: tempç›®å½•åŒ…å«å»ç•¸å˜å‰çš„åŸå§‹ç‚¹äº‘")
        print(f"   ä½ç½®: {self.temp_dir}")
        print(f"   å¦‚æœéœ€è¦éªŒè¯å»ç•¸å˜æ•ˆæœï¼Œè¯·ä¿ç•™æ­¤ç›®å½•")
        print(f"   å¦‚æœä¸éœ€è¦ï¼Œå¯ä»¥æ‰‹åŠ¨åˆ é™¤ä»¥èŠ‚çœç©ºé—´")
        # import shutil
        # shutil.rmtree(self.temp_dir)  # æ³¨é‡Šæ‰è‡ªåŠ¨åˆ é™¤
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = getattr(self, '_extract_time', 0) + sync_time + save_time
        
        print(f"\n{'='*80}")
        print(f"æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
        print(f"{'='*80}")
        print(f"\nğŸ“ è¾“å‡ºä½ç½®:")
        print(f"  æ•°æ®é›†: {seq_dir}")
        print(f"  ä¸´æ—¶æ–‡ä»¶: {self.temp_dir} (å·²ä¿ç•™)")
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  å›¾åƒ: {len(synced_pairs)} å¼ ")
        print(f"  ç‚¹äº‘: {len(synced_pairs)} å¸§")
        if self.pose_metadata:
            print(f"  ä½å§¿: {len(self.pose_metadata)} ä¸ª")
        
        print(f"\nâ±ï¸  è€—æ—¶ç»Ÿè®¡:")
        if hasattr(self, '_extract_time'):
            print(f"  1. æ•°æ®æå–: {timedelta(seconds=int(self._extract_time))} ({self._extract_time/total_time*100:.1f}%)")
        print(f"  2. æ•°æ®åŒæ­¥: {timedelta(seconds=int(sync_time))} ({sync_time/total_time*100:.1f}%)")
        print(f"  3. å»ç•¸å˜ä¿å­˜: {timedelta(seconds=int(save_time))} ({save_time/total_time*100:.1f}%)")
        print(f"  {'â”€'*40}")
        print(f"  æ€»è®¡: {timedelta(seconds=int(total_time))}")
        print(f"  å¹³å‡é€Ÿåº¦: {len(synced_pairs) / total_time:.2f} å¸§/ç§’")
        
        print(f"\nğŸš€ æ€§èƒ½æŒ‡æ ‡:")
        print(f"  çº¿ç¨‹æ•°: {self.num_workers}")
        print(f"  æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        if hasattr(self, '_extract_time') and len(synced_pairs) > 0:
            print(f"  æå–æ•ˆç‡: {len(self.image_metadata) / self._extract_time:.2f} å¸§/ç§’")
        print(f"  ä¿å­˜æ•ˆç‡: {len(synced_pairs) / save_time:.2f} å¸§/ç§’")
    
    def _save_calib_file(self, seq_dir: Path):
        """ä¿å­˜æ ‡å®šæ–‡ä»¶ï¼ˆKITTI-Odometryæ ‡å‡†æ ¼å¼ï¼‰
        
        å‚è€ƒï¼š
        - manual_sensor_calib.cpp:1585-1626
        - åæ ‡ç³»æ–‡æ¡£ï¼šP_A = T^A_B * P_B
        
        **KITTIæ ‡å‡†**ï¼š
        - Velodyneç³»ï¼šx=forward, y=left, z=upï¼ˆå‰å·¦ä¸Šï¼Œä¸æˆ‘ä»¬çš„LiDARç³»ä¸€è‡´ï¼‰
        - Cameraç³»ï¼šx=right, y=down, z=forwardï¼ˆå³ä¸‹å‰ï¼Œé€šç”¨å®šä¹‰ï¼‰
        - TrçŸ©é˜µï¼š**LiDAR â†’ Camera**ï¼ˆå°†Velodyneç‚¹äº‘å˜æ¢åˆ°Cameraåæ ‡ç³»ï¼‰
        
        **åæ ‡å˜æ¢é“¾**ï¼š
        - ç‚¹äº‘åœ¨LiDARç³»ï¼šP_lidarï¼ˆå»ç•¸å˜åå·²è½¬æ¢åˆ°LiDARç³»ï¼‰
        - å˜æ¢åˆ°Cameraç³»ï¼šP_camera = T_lidar_to_camera * P_lidar
        - æŠ•å½±åˆ°å›¾åƒï¼šp = K * P_cameraï¼ˆP_camera.z > 0æ—¶å¯è§ï¼‰
        
        **å…³é”®ä¿®å¤**ï¼š
        - å»ç•¸å˜åçš„ç‚¹äº‘å·²ä»Sensingç³»è½¬æ¢åˆ°LiDARç³»
        - ç¬¦åˆKITTIæ ‡å‡†ï¼ŒæŠ•å½±æ—¶ç›´æ¥ä½¿ç”¨Trï¼ˆLiDARâ†’Cameraï¼‰
        - ä¸éœ€è¦é¢å¤–çš„æ‰©å±•å­—æ®µ
        """
        calib_path = seq_dir / 'calib.txt'
        
        # P2: å·¦ä¾§å½©è‰²ç›¸æœºçš„æŠ•å½±çŸ©é˜µ (3x4)
        P2 = np.zeros((3, 4))
        P2[:3, :3] = self.K
        
        # Tr: Velodyneåˆ°cam0çš„å˜æ¢çŸ©é˜µï¼ˆLiDAR â†’ Cameraï¼‰
        # C++å‘½åçº¦å®šï¼šT_camera_to_lidarï¼ˆä»å³å¾€å·¦è¯»ï¼šLiDAR â†’ Cameraï¼‰
        T_velo_to_cam0 = self.T_camera_to_lidar  # LiDAR â†’ Cameraï¼ˆKITTIæ ‡å‡†ï¼‰
        T_velo_to_cam0_3x4 = T_velo_to_cam0[:3, :]  # åªå–å‰3è¡Œï¼ˆKITTIæ ‡å‡†ï¼š3x4çŸ©é˜µï¼‰
        
        # D: ç•¸å˜ç³»æ•°ï¼ˆå‚è€ƒC++å®ç°ï¼ŒæŠ•å½±æ—¶éœ€è¦ï¼‰
        # æ”¯æŒä¸¤ç§æ¨¡å‹ï¼š
        # 1. pinhole: k1, k2, p1, p2, k3 (OpenCVæ ‡å‡†ï¼Œ5ä¸ªå‚æ•°)
        # 2. fisheye: k1, k2, k3, k4 (KANNALA_BRANDTé±¼çœ¼æ¨¡å‹ï¼Œ4ä¸ªå‚æ•°)
        distortion = self.camera_config.get('distortion', {})
        model_type = distortion.get('model_type', 'pinhole')
        
        if model_type == 'fisheye':
            # é±¼çœ¼æ¨¡å‹ï¼šk1, k2, k3, k4ï¼ˆæ— åˆ‡å‘ç•¸å˜ï¼‰
            D = np.array([
                distortion.get('k1', 0.0),
                distortion.get('k2', 0.0),
                distortion.get('k3', 0.0),
                distortion.get('k4', 0.0)
            ])
        else:
            # Pinholeæ¨¡å‹ï¼šk1, k2, p1, p2, k3
            D = np.array([
                distortion.get('k1', 0.0),
                distortion.get('k2', 0.0),
                distortion.get('p1', 0.0),
                distortion.get('p2', 0.0),
                distortion.get('k3', 0.0)
            ])
        
        with open(calib_path, 'w') as f:
            # å®Œæ•´çš„KITTIæ ¼å¼åŒ…å«P0-P3ï¼Œä½†BEVCalibåªéœ€è¦P2
            # ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬ä¹Ÿå†™å…¥P0, P1, P3ï¼ˆä½¿ç”¨ç›¸åŒçš„P2ï¼‰
            for i in range(4):
                f.write(f"P{i}: ")
                f.write(" ".join([f"{val:.12e}" for val in P2.flatten()]))
                f.write("\n")
            
            # Tr: 3x4çŸ©é˜µï¼ˆ12ä¸ªæ•°ï¼‰
            f.write("Tr: ")
            f.write(" ".join([f"{val:.12e}" for val in T_velo_to_cam0_3x4.flatten()]))
            f.write("\n")
            
            # D: ç•¸å˜ç³»æ•°
            # pinholeæ¨¡å‹ï¼šk1, k2, p1, p2, k3 (5ä¸ªå‚æ•°)
            # fisheyeæ¨¡å‹ï¼šk1, k2, k3, k4 (4ä¸ªå‚æ•°)
            # C++å‚è€ƒï¼šlidar_cam_fusion_manualéœ€è¦ç•¸å˜ç³»æ•°è¿›è¡Œå»ç•¸å˜
            f.write("D: ")
            f.write(" ".join([f"{val:.12e}" for val in D]))
            f.write("\n")
            
            # ä¿å­˜ç›¸æœºæ¨¡å‹ç±»å‹ï¼ˆç”¨äºæŠ•å½±æ—¶é€‰æ‹©æ­£ç¡®çš„å»ç•¸å˜æ–¹æ³•ï¼‰
            f.write(f"camera_model: {model_type}\n")
        
        print(f"æ ‡å®šæ–‡ä»¶å·²ä¿å­˜: {calib_path} (KITTI-Odometryæ ¼å¼ + ç•¸å˜ç³»æ•°)")
        print(f"  âœ“ ç‚¹äº‘åæ ‡ç³»: LiDARç³»ï¼ˆå·²ä»Sensingç³»è½¬æ¢ï¼‰")
        print(f"  âœ“ æŠ•å½±å˜æ¢: Tr (LiDARâ†’Camera)")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹æ‰“å°ç•¸å˜ç³»æ•°
        if model_type == 'fisheye':
            print(f"  âœ“ ç•¸å˜æ¨¡å‹: {model_type} (KANNALA_BRANDT)")
            print(f"  âœ“ ç•¸å˜ç³»æ•°: D (k1={D[0]:.6f}, k2={D[1]:.6f}, k3={D[2]:.6f}, k4={D[3]:.6f})")
        else:
            print(f"  âœ“ ç•¸å˜æ¨¡å‹: {model_type}")
            print(f"  âœ“ ç•¸å˜ç³»æ•°: D (k1={D[0]:.6f}, k2={D[1]:.6f}, p1={D[2]:.6f}, p2={D[3]:.6f}, k3={D[4]:.6f})")
    
    def _save_poses_file(self, synced_pairs: List[Tuple[int, int]], sequence_id: str):
        """ä¿å­˜ä½å§¿æ–‡ä»¶ï¼ˆKITTI-Odometry æ ¼å¼ï¼‰
        
        KITTIæ ¼å¼è¦æ±‚ï¼š
        1. æ¯è¡Œæ˜¯ä»ç¬¬iå¸§åˆ°ç¬¬0å¸§çš„å˜æ¢çŸ©é˜µ T_0_to_i
        2. P_0 = T_0_to_i @ P_i ï¼ˆå°†ç¬¬iå¸§çš„ç‚¹æŠ•å½±åˆ°ç¬¬0å¸§ï¼‰
        3. ä½¿ç”¨çº¿æ€§æ’å€¼è·å¾—å›¾åƒæ—¶åˆ»çš„ç²¾ç¡®ä½å§¿
        """
        poses_dir = self.output_dir / 'poses'
        poses_dir.mkdir(exist_ok=True)
        poses_file = poses_dir / f'{sequence_id}.txt'
        
        print(f"ç”Ÿæˆä½å§¿æ–‡ä»¶...")
        
        # âœ… å¤ç”¨å·²æœ‰çš„æ’å€¼/å¤–æ¨å®ç°
        # 1. ä¼˜å…ˆä½¿ç”¨ motion_interpolateï¼ˆæä»£æ•°æ’å€¼ï¼‰
        # 2. æ’å€¼å¤±è´¥æ—¶ä½¿ç”¨ motion_extrapolateï¼ˆå¤–æ¨ï¼‰
        # 3. éƒ½å¤±è´¥æ—¶ä½¿ç”¨æœ€è¿‘é‚»ï¼ˆæç«¯æƒ…å†µï¼‰
        poses_world = []
        interpolated_count = 0
        extrapolated_count = 0
        nearest_count = 0
        
        for idx, (img_idx, _) in enumerate(synced_pairs):
            img_ts = self.image_metadata[img_idx].timestamp
            
            # ä½¿ç”¨å·²æœ‰çš„motion_interpolateæ–¹æ³•ï¼ˆä¸¥æ ¼å‚è€ƒC++å®ç°ï¼‰
            result = UndistortionUtils.motion_interpolate(self.pose_metadata, img_ts)
            
            if result is not None:
                # æ’å€¼æˆåŠŸ
                R_mat, t_vec = result
                T_world = np.eye(4)
                T_world[:3, :3] = R_mat
                T_world[:3, 3] = t_vec
                poses_world.append(T_world)
                interpolated_count += 1
            else:
                # æ’å€¼å¤±è´¥ï¼ˆæ—¶é—´æˆ³è¶…å‡ºèŒƒå›´ï¼‰ï¼Œå°è¯•å¤–æ¨
                result_extrap = UndistortionUtils.motion_extrapolate(self.pose_metadata, img_ts)
                
                if result_extrap is not None:
                    # å¤–æ¨æˆåŠŸ
                    R_mat, t_vec = result_extrap
                    T_world = np.eye(4)
                    T_world[:3, :3] = R_mat
                    T_world[:3, 3] = t_vec
                    poses_world.append(T_world)
                    extrapolated_count += 1
                else:
                    # å¤–æ¨ä¹Ÿå¤±è´¥ï¼ˆæç«¯æƒ…å†µï¼šposeæ•°é‡<2ï¼‰ï¼Œä½¿ç”¨æœ€è¿‘é‚»
                    best_pose = None
                    best_diff = float('inf')
                    for pose in self.pose_metadata:
                        diff = abs(pose.timestamp - img_ts)
                        if diff < best_diff:
                            best_diff = diff
                            best_pose = pose
                    
                    if best_pose is not None:
                        T_world = np.eye(4)
                        T_world[:3, :3] = R.from_quat(best_pose.orientation).as_matrix()
                        T_world[:3, 3] = best_pose.position
                        poses_world.append(T_world)
                        nearest_count += 1
                    else:
                        # æ²¡æœ‰ä»»ä½•poseï¼Œä½¿ç”¨å•ä½çŸ©é˜µæˆ–ä¸Šä¸€å¸§
                        if poses_world:
                            poses_world.append(poses_world[-1].copy())
                        else:
                            poses_world.append(np.eye(4))
        
        # âœ… ä¿®å¤2ï¼šè½¬æ¢ä¸ºç›¸å¯¹äºç¬¬0å¸§çš„ä½å§¿
        # KITTIæ ¼å¼ï¼šT_0_to_i = inv(T_0_to_world) @ T_i_to_world
        # 
        # C++å‘½åçº¦å®šï¼ˆä»å³å¾€å·¦è¯»ï¼‰ï¼š
        #   T_0_to_world = ç¬¬0å¸§â†’Worldï¼ˆç¬¬0å¸§åœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
        #   T_i_to_world = ç¬¬iå¸§â†’Worldï¼ˆç¬¬iå¸§åœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
        #   T_world_to_0 = inv(T_0_to_world) = Worldâ†’ç¬¬0å¸§
        #   T_0_to_i = Worldâ†’ç¬¬0å¸§ @ ç¬¬iå¸§â†’World = ç¬¬iå¸§â†’ç¬¬0å¸§
        if len(poses_world) == 0:
            print("è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„ä½å§¿æ•°æ®")
            return
        
        T_0_to_world = poses_world[0]  # ç¬¬0å¸§â†’Worldï¼ˆC++å‘½åçº¦å®šï¼‰
        T_world_to_0 = np.linalg.inv(T_0_to_world)  # Worldâ†’ç¬¬0å¸§
        
        poses_relative = []
        for T_i_to_world in poses_world:  # ç¬¬iå¸§â†’World
            # ä»ç¬¬iå¸§åˆ°ç¬¬0å¸§çš„å˜æ¢
            T_0_to_i = T_world_to_0 @ T_i_to_world  # ç¬¬iå¸§â†’ç¬¬0å¸§
            poses_relative.append(T_0_to_i)
        
        # å†™å…¥æ–‡ä»¶ï¼ˆKITTI æ ¼å¼ï¼šæ¯è¡Œ12ä¸ªæ•°ï¼Œä»£è¡¨ 3x4 å˜æ¢çŸ©é˜µï¼‰
        with open(poses_file, 'w') as f:
            for T in poses_relative:
                # åªä¿å­˜å‰3è¡Œï¼ˆ3x4 çŸ©é˜µï¼‰
                pose_line = T[:3, :].flatten()
                f.write(' '.join([f"{val:.12e}" for val in pose_line]))
                f.write('\n')
        
        print(f"ä½å§¿æ–‡ä»¶å·²ä¿å­˜: {poses_file}")
        print(f"  æ€»å¸§æ•°: {len(poses_relative)}")
        print(f"  æ’å€¼å¸§æ•°: {interpolated_count} (æä»£æ•°æ’å€¼)")
        if extrapolated_count > 0:
            print(f"  å¤–æ¨å¸§æ•°: {extrapolated_count} (æä»£æ•°å¤–æ¨)")
        if nearest_count > 0:
            print(f"  æœ€è¿‘é‚»: {nearest_count}")
        
        # éªŒè¯ç¬¬0å¸§åº”è¯¥æ˜¯å•ä½çŸ©é˜µ
        if not np.allclose(poses_relative[0], np.eye(4), atol=1e-6):
            print(f"  âš ï¸  è­¦å‘Š: ç¬¬0å¸§ä½å§¿ä¸æ˜¯å•ä½çŸ©é˜µï¼ˆé¢„æœŸè¡Œä¸ºï¼‰")
        else:
            print(f"  âœ“ ç¬¬0å¸§ä½å§¿ä¸ºå•ä½çŸ©é˜µï¼ˆå‚è€ƒåæ ‡ç³»ï¼‰")
    
    def _save_times_file(self, synced_pairs: List[Tuple[int, int]], seq_dir: Path):
        """ä¿å­˜æ—¶é—´æˆ³æ–‡ä»¶ï¼ˆKITTI-Odometry æ ¼å¼ï¼‰
        
        KITTIæ ¼å¼è¦æ±‚ï¼š
        1. æ¯è¡Œä¸€ä¸ªæµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºè¯¥å¸§çš„æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
        2. æ—¶é—´æˆ³ç›¸å¯¹äºç¬¬ä¸€å¸§ï¼ˆç¬¬0å¸§æ—¶é—´æˆ³ä¸º0ï¼‰
        3. é«˜ç²¾åº¦æµ®ç‚¹æ•°æ ¼å¼ï¼ˆä¿ç•™è¶³å¤Ÿç²¾åº¦ï¼‰
        
        times.txt æŠ€æœ¯ç‰¹ç‚¹ï¼š
        - ç¡®ä¿ä¸åŒä¼ æ„Ÿå™¨æ•°æ®ä¹‹é—´çš„æ—¶é—´åŒæ­¥
        - ç”¨äºè½¨è¿¹æ’å€¼å’Œè¿åŠ¨è¡¥å¿
        - æ”¯æŒæ—¶åºæ•°æ®çš„ç²¾ç¡®å¯¹é½
        """
        times_file = seq_dir / 'times.txt'
        
        print(f"\nç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶...")
        
        if not synced_pairs:
            print("  âš ï¸  è­¦å‘Š: æ²¡æœ‰åŒæ­¥çš„å¸§ï¼Œè·³è¿‡ times.txt ç”Ÿæˆ")
            return
        
        # æå–æ‰€æœ‰å›¾åƒçš„æ—¶é—´æˆ³
        timestamps = []
        for img_idx, _ in synced_pairs:
            img_ts = self.image_metadata[img_idx].timestamp
            timestamps.append(img_ts)
        
        # è½¬æ¢ä¸ºç›¸å¯¹ç¬¬ä¸€å¸§çš„æ—¶é—´ï¼ˆKITTIæ ¼å¼ï¼‰
        first_timestamp = timestamps[0]
        relative_timestamps = [ts - first_timestamp for ts in timestamps]
        
        # å†™å…¥æ–‡ä»¶
        with open(times_file, 'w') as f:
            for ts in relative_timestamps:
                # ä½¿ç”¨è¶³å¤Ÿçš„ç²¾åº¦ï¼ˆ6ä½å°æ•°ï¼Œè¶³ä»¥è¡¨ç¤ºæ¯«ç§’çº§ç²¾åº¦ï¼‰
                f.write(f"{ts:.6f}\n")
        
        print(f"æ—¶é—´æˆ³æ–‡ä»¶å·²ä¿å­˜: {times_file}")
        print(f"  æ€»å¸§æ•°: {len(relative_timestamps)}")
        print(f"  æ—¶é—´èŒƒå›´: {relative_timestamps[0]:.3f}s ~ {relative_timestamps[-1]:.3f}s")
        print(f"  æ€»æ—¶é•¿: {relative_timestamps[-1]:.3f}s")
        
        # è®¡ç®—å¹³å‡å¸§ç‡
        if len(relative_timestamps) > 1:
            total_duration = relative_timestamps[-1] - relative_timestamps[0]
            if total_duration > 0:
                avg_fps = (len(relative_timestamps) - 1) / total_duration
                print(f"  å¹³å‡å¸§ç‡: {avg_fps:.2f} fps")
        
        # éªŒè¯ç¬¬0å¸§æ—¶é—´æˆ³åº”è¯¥æ˜¯0
        if abs(relative_timestamps[0]) > 1e-9:
            print(f"  âš ï¸  è­¦å‘Š: ç¬¬0å¸§æ—¶é—´æˆ³ä¸æ˜¯0 ({relative_timestamps[0]:.9f})")
        else:
            print(f"  âœ“ ç¬¬0å¸§æ—¶é—´æˆ³ä¸º0ï¼ˆå‚è€ƒæ—¶åˆ»ï¼‰")


def main():
    parser = argparse.ArgumentParser(description='å‡†å¤‡ BEVCalib æ•°æ®é›†ï¼ˆæµå¼å¤„ç†ï¼‰')
    parser.add_argument('--bag_dir', type=str, required=True)
    parser.add_argument('--config_dir', type=str, required=True)
    parser.add_argument('--output_dir', type=str, required=True)
    parser.add_argument('--camera_name', type=str, default='traffic_2')
    parser.add_argument('--target_fps', type=float, default=10.0)
    parser.add_argument('--max_time_diff', type=float, default=0.055,
                       help='æœ€å¤§æ—¶é—´å·®é˜ˆå€¼ï¼ˆç§’ï¼‰ã€‚å‚è€ƒC++: kMaxLidarCameraDelta=55msã€‚'
                            'è¶…è¿‡æ­¤é˜ˆå€¼çš„lidar-å›¾åƒå¯¹å°†è¢«ä¸¢å¼ƒã€‚')
    parser.add_argument('--lidar_topic', type=str,
                       default='/sensors/lidar/combined_point_cloud_proto')
    parser.add_argument('--pose_topic', type=str,
                       default="/localization/pose",
                       help='ä½å§¿ topicï¼ˆé»˜è®¤: /localization/poseï¼‰')
    parser.add_argument('--sequence_id', type=str, default='00')
    parser.add_argument('--batch_size', type=int, default=500,
                       help='æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤: 500ï¼Œå¢å¤§å¯æå‡é€Ÿåº¦ï¼‰')
    parser.add_argument('--num_workers', type=int, default=4,
                       help='å¹¶è¡Œå¤„ç†çš„çº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 4ï¼‰')
    parser.add_argument('--max_frames', type=int, default=None,
                       help='æœ€å¤§å¤„ç†å¸§æ•°ï¼Œç”¨äºæµ‹è¯•ï¼ˆé»˜è®¤: Noneï¼Œå¤„ç†æ‰€æœ‰å¸§ï¼‰')
    args = parser.parse_args()
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print(f"\n{'='*80}")
    print(f"BEVCalib æ•°æ®é›†ç”Ÿæˆå·¥å…·")
    print(f"{'='*80}")
    print(f"\nâš™ï¸  é…ç½®:")
    print(f"  Bagç›®å½•: {args.bag_dir}")
    print(f"  é…ç½®ç›®å½•: {args.config_dir}")
    print(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"  ç›¸æœº: {args.camera_name}")
    print(f"  ç›®æ ‡å¸§ç‡: {args.target_fps} fps")
    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"  çº¿ç¨‹æ•°: {args.num_workers}")
    
    total_start_time = time.time()
    
    preparer = BEVCalibDatasetPreparer(
        bag_path=args.bag_dir,
        config_dir=args.config_dir,
        output_dir=args.output_dir,
        camera_name=args.camera_name,
        target_fps=args.target_fps,
        max_time_diff=args.max_time_diff,
        lidar_topic=args.lidar_topic,
        pose_topic=args.pose_topic,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        max_frames=args.max_frames,
    )
    
    preparer.extract_data_from_bag()
    preparer.sync_and_save(sequence_id=args.sequence_id)
    
    total_time = time.time() - total_start_time
    
    print(f"\n{'='*80}")
    print(f"âœ“ å…¨éƒ¨å®Œæˆï¼")
    print(f"{'='*80}")
    print(f"\næ€»ç”¨æ—¶: {timedelta(seconds=int(total_time))}")
    print(f"\nğŸ“š ä¸‹ä¸€æ­¥:")
    print(f"  1. éªŒè¯æ•°æ®é›†:")
    print(f"     python validate_kitti_odometry.py --dataset_root {args.output_dir}")
    print(f"\n  2. å¯è§†åŒ–å»ç•¸å˜æ•ˆæœ:")
    print(f"     python visualize_undistortion.py {args.output_dir} --frame 0")
    print(f"\n  3. æŠ•å½±ç‚¹äº‘åˆ°å›¾åƒ:")
    print(f"     python project_points_to_image.py --dataset_root {args.output_dir} --frame 0")
    print(f"\n  4. å¼€å§‹è®­ç»ƒ:")
    print(f"     python kitti-bev-calib/train_kitti.py --dataset_root {args.output_dir}")
    print(f"\n{'='*80}\n")


if __name__ == '__main__':
    main()
