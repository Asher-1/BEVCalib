#!/usr/bin/env python3
"""
BEVCalib è‡ªå®šä¹‰æ•°æ®é›†å‡†å¤‡è„šæœ¬ï¼ˆæµå¼å¤„ç†ç‰ˆæœ¬ï¼‰

ä» rosbag å’Œé…ç½®æ–‡ä»¶æå–æ•°æ®ï¼Œè½¬æ¢ä¸º BEVCalib è®­ç»ƒæ ¼å¼ã€‚
é‡‡ç”¨æµå¼å¤„ç†ï¼Œå‡å°‘å†…å­˜å ç”¨ã€‚

ä½¿ç”¨æ–¹æ³•:
    python prepare_custom_dataset.py \\
        --bag_dir /path/to/bags \\
        --config_dir /path/to/config \\
        --output_dir /path/to/output \\
        --camera_name traffic_2 \\
        --target_fps 10.0
"""

import os
import re
import argparse
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from PIL import Image
import cv2
from tqdm import tqdm
from scipy.spatial.transform import Rotation as R, Slerp
import struct
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp
import time
from datetime import timedelta


@dataclass
class ImageMetadata:
    """å›¾åƒå…ƒæ•°æ®ï¼ˆä¸åŒ…å«å›¾åƒæ•°æ®ï¼‰"""
    timestamp: float
    file_path: str


@dataclass
class PointCloudMetadata:
    """ç‚¹äº‘å…ƒæ•°æ®ï¼ˆä¸åŒ…å«ç‚¹äº‘æ•°æ®ï¼‰"""
    timestamp: float
    file_path: str


@dataclass
class PoseMetadata:
    """ä½å§¿å…ƒæ•°æ®ï¼ˆSensingç³»åœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
    
    æ³¨æ„ï¼šä¸C++å¯¹é½ï¼Œå­˜å‚¨çš„æ˜¯ Sensingâ†’World å˜æ¢
    - å«ä¹‰ï¼šSensingç³»åœ¨Worldç³»ä¸­çš„ä½å§¿
    - ä½œç”¨ï¼šå°†Sensingç³»çš„ç‚¹å˜æ¢åˆ°Worldç³»
    
    C++å‚è€ƒï¼šlidar_online_calibrator.cpp:849-852
        sensing_pose.second = vehicle_pose * iso_vehicle_sensing_;
        å…¶ä¸­ï¼švehicle_pose = Vehicleâ†’World
              iso_vehicle_sensing_ = Sensingâ†’Vehicle
              ç»“æœï¼šsensing_pose = Sensingâ†’World
    """
    timestamp: float
    position: np.ndarray  # (3,) xyz - Sensingåœ¨Worldç³»ä¸­çš„ä½ç½®
    orientation: np.ndarray  # (4,) quaternion (x, y, z, w) - Sensingåœ¨Worldç³»ä¸­çš„å§¿æ€


class UndistortionUtils:
    """ç‚¹äº‘å»ç•¸å˜å·¥å…·ç±»"""
    
    @staticmethod
    def quat_to_matrix(q):
        """å››å…ƒæ•°è½¬æ—‹è½¬çŸ©é˜µ (x, y, z, w)"""
        x, y, z, w = q
        return np.array([
            [1 - 2*(y**2 + z**2), 2*(x*y - w*z), 2*(x*z + w*y)],
            [2*(x*y + w*z), 1 - 2*(x**2 + z**2), 2*(y*z - w*x)],
            [2*(x*z - w*y), 2*(y*z + w*x), 1 - 2*(x**2 + y**2)]
        ])
    
    @staticmethod
    def isometry_to_vec6(R_mat, t):
        """å°†æ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡è½¬æ¢ä¸º6Då‘é‡ [rx, ry, rz, tx, ty, tz]"""
        # ä½¿ç”¨Rodrigueså…¬å¼ï¼šR -> angle-axis
        r = R.from_matrix(R_mat).as_rotvec()
        return np.concatenate([r, t])
    
    @staticmethod
    def vec6_to_isometry(v):
        """å°†6Då‘é‡è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡"""
        r_vec = v[:3]
        t = v[3:6]
        R_mat = R.from_rotvec(r_vec).as_matrix()
        return R_mat, t
    
    @staticmethod
    def motion_interpolate(poses: List[PoseMetadata], timestamp: float, max_gap: float = 1.0):
        """ä½å§¿æ’å€¼ï¼ˆä¸¥æ ¼å‚è€ƒC++çš„motion_interpolateå®ç°ï¼‰
        
        Args:
            poses: ä½å§¿åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰
            timestamp: ç›®æ ‡æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            max_gap: å…è®¸çš„æœ€å¤§poseé—´éš”ï¼ˆç§’ï¼‰ï¼Œè¶…è¿‡æ­¤é—´éš”è®¤ä¸ºæ•°æ®ä¸è¿ç»­
            
        Returns:
            (R, t): æ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡ï¼Œå¦‚æœå¤±è´¥è¿”å›None
            
        Note:
            å‚è€ƒ math_utils.cpp:313-346
            C++ç‰ˆæœ¬åªæ”¯æŒæ’å€¼ï¼Œä¸æ”¯æŒå¤–æ¨ã€‚æ—¶é—´æˆ³è¶…å‡ºèŒƒå›´ç›´æ¥è¿”å›falseã€‚
            
            ğŸ”§ æ”¹è¿›ï¼šæ”¯æŒä¸è¿ç»­çš„bagæ•°æ®
            - å½“poseé—´éš”è¶…è¿‡max_gapæ—¶ï¼Œè®¤ä¸ºæ•°æ®ä¸è¿ç»­ï¼Œä¸è¿›è¡Œæ’å€¼
            - è¿™æ ·å¯ä»¥æ­£ç¡®å¤„ç†çº¿ä¸Šè¿‡æ»¤åçš„éè¿ç»­bagæ•°æ®
        """
        if not poses or len(poses) < 2:
            return None
        
        # æŸ¥æ‰¾timestampå‰åçš„ä¸¤ä¸ªä½å§¿è¿›è¡Œæ’å€¼ï¼ˆä¸¥æ ¼æŒ‰ç…§C++é€»è¾‘ï¼‰
        for i in range(len(poses) - 1):
            t1 = poses[i].timestamp
            t2 = poses[i + 1].timestamp
            
            # åªåœ¨èŒƒå›´å†…æ’å€¼ï¼ˆå¯¹åº”C++çš„ if (t1 <= t && t2 >= t)ï¼‰
            if t1 <= timestamp <= t2:
                # ğŸ”§ æ”¹è¿›ï¼šæ£€æŸ¥poseé—´éš”æ˜¯å¦è¿‡å¤§ï¼ˆæ•°æ®ä¸è¿ç»­ï¼‰
                if (t2 - t1) > max_gap:
                    # poseé—´éš”è¿‡å¤§ï¼Œè¯´æ˜è¿™æ®µæ—¶é—´æ²¡æœ‰è¿ç»­çš„poseæ•°æ®
                    # ä¸è¿›è¡Œæ’å€¼ï¼Œè¿”å›None
                    return None
                
                # è®¡ç®—æ’å€¼ç³»æ•°
                alpha = (timestamp - t1) / (t2 - t1)
                break
        else:
            # æ—¶é—´æˆ³ä¸åœ¨ä»»ä½•åŒºé—´å†…ï¼Œè¿”å›Noneï¼ˆå¯¹åº”C++çš„return falseï¼‰
            return None
        
        # ä½å§¿1
        R1 = UndistortionUtils.quat_to_matrix(poses[i].orientation)
        t1_vec = poses[i].position
        
        # ä½å§¿2
        R2 = UndistortionUtils.quat_to_matrix(poses[i + 1].orientation)
        t2_vec = poses[i + 1].position
        
        # è®¡ç®—ç›¸å¯¹è¿åŠ¨
        R_delta = R1.T @ R2
        t_delta = R1.T @ (t2_vec - t1_vec)
        
        # è½¬æ¢ä¸º6Då‘é‡å¹¶æ’å€¼/å¤–æ¨
        v_delta = UndistortionUtils.isometry_to_vec6(R_delta, t_delta)
        v_interp = v_delta * alpha
        
        # è½¬æ¢å›çŸ©é˜µ
        R_interp, t_interp = UndistortionUtils.vec6_to_isometry(v_interp)
        
        # åº”ç”¨åˆ°pose1
        R_result = R1 @ R_interp
        t_result = t1_vec + R1 @ t_interp
        
        return R_result, t_result
    
    @staticmethod
    def can_interpolate(poses: List[PoseMetadata], timestamp: float, max_gap: float = 1.0) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¯¹ç»™å®šæ—¶é—´æˆ³è¿›è¡Œä½å§¿æ’å€¼
        
        Args:
            poses: ä½å§¿åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰
            timestamp: ç›®æ ‡æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            max_gap: å…è®¸çš„æœ€å¤§poseé—´éš”ï¼ˆç§’ï¼‰
            
        Returns:
            True å¦‚æœå¯ä»¥æ’å€¼ï¼ŒFalse å¦åˆ™
            
        Note:
            ç”¨äºå¿«é€Ÿæ£€æŸ¥ï¼Œé¿å…é‡å¤è®¡ç®—æ’å€¼ç»“æœ
        """
        if not poses or len(poses) < 2:
            return False
        
        for i in range(len(poses) - 1):
            t1 = poses[i].timestamp
            t2 = poses[i + 1].timestamp
            
            if t1 <= timestamp <= t2:
                # æ£€æŸ¥poseé—´éš”æ˜¯å¦åœ¨å…è®¸èŒƒå›´å†…
                return (t2 - t1) <= max_gap
        
        return False
    
    @staticmethod
    def find_nearest_pose(poses: List[PoseMetadata], timestamp: float) -> Tuple[Optional[int], float]:
        """æ‰¾åˆ°æœ€è¿‘çš„poseï¼ˆå‚è€ƒC++ manual_sensor_calib.cppçš„min_deltaé€»è¾‘ï¼‰
        
        Args:
            poses: ä½å§¿åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰
            timestamp: ç›®æ ‡æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            
        Returns:
            (index, delta): æœ€è¿‘poseçš„ç´¢å¼•å’Œæ—¶é—´å·®ï¼ˆç§’ï¼‰ï¼Œå¦‚æœæ²¡æœ‰poseè¿”å›(None, inf)
        """
        if not poses:
            return None, float('inf')
        
        min_delta = float('inf')
        best_idx = None
        
        for i, pose in enumerate(poses):
            delta = abs(pose.timestamp - timestamp)
            if delta < min_delta:
                min_delta = delta
                best_idx = i
        
        return best_idx, min_delta
    
    @staticmethod
    def can_interpolate_nearest(poses: List[PoseMetadata], timestamp: float, 
                                max_delta: float = 0.1) -> bool:
        """ä½¿ç”¨æœ€è¿‘é‚»æ–¹å¼æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›è¡Œä½å§¿æ’å€¼
        
        å‚è€ƒ C++ manual_sensor_calib.cpp çš„ min_delta é€»è¾‘ï¼š
        - æ‰¾åˆ°æœ€è¿‘çš„pose
        - å¦‚æœæ—¶é—´å·® < max_deltaï¼Œåˆ™è®¤ä¸ºå¯ä»¥æ’å€¼
        
        è¿™ç§æ–¹å¼æ›´é€‚åˆå¤„ç†ä¸è¿ç»­çš„bagæ•°æ®ï¼Œå› ä¸ºï¼š
        1. ä¸è¦æ±‚poseä¸¥æ ¼åŒ…å›´ç›®æ ‡æ—¶é—´æˆ³
        2. åªè¦æœ‰è¶³å¤Ÿè¿‘çš„poseå°±å¯ä»¥ä½¿ç”¨
        
        Args:
            poses: ä½å§¿åˆ—è¡¨
            timestamp: ç›®æ ‡æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            max_delta: æœ€å¤§å…è®¸çš„æ—¶é—´å·®ï¼ˆç§’ï¼‰ï¼Œå‚è€ƒC++çš„0.1e9 ns = 100ms
            
        Returns:
            True å¦‚æœå¯ä»¥æ’å€¼
        """
        _, min_delta = UndistortionUtils.find_nearest_pose(poses, timestamp)
        return min_delta <= max_delta
    
    @staticmethod
    def motion_extrapolate(poses: List[PoseMetadata], timestamp: float):
        """ä½å§¿å¤–æ¨ï¼ˆç”¨äºæ—¶é—´æˆ³è¶…å‡ºèŒƒå›´çš„æƒ…å†µï¼‰
        
        Args:
            poses: ä½å§¿åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼‰
            timestamp: ç›®æ ‡æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
            
        Returns:
            (R, t): æ—‹è½¬çŸ©é˜µå’Œå¹³ç§»å‘é‡ï¼Œå¦‚æœå¤±è´¥è¿”å›None
            
        Note:
            å½“timestampåœ¨poseèŒƒå›´å¤–æ—¶ï¼Œä½¿ç”¨æœ€è¿‘çš„ä¸¤ä¸ªposeè¿›è¡Œå¤–æ¨
            å¤–æ¨ä½¿ç”¨ä¸æ’å€¼ç›¸åŒçš„æ•°å­¦å…¬å¼ï¼Œä½†alphaä¼šè¶…å‡º[0,1]èŒƒå›´
        """
        if not poses or len(poses) < 2:
            return None
        
        # ç¡®å®šå¤–æ¨æ–¹å‘å’Œä½¿ç”¨çš„poseå¯¹
        if timestamp < poses[0].timestamp:
            # å‘å‰å¤–æ¨ï¼šä½¿ç”¨å‰ä¸¤ä¸ªpose
            i = 0
            t1 = poses[0].timestamp
            t2 = poses[1].timestamp
        elif timestamp > poses[-1].timestamp:
            # å‘åå¤–æ¨ï¼šä½¿ç”¨åä¸¤ä¸ªpose
            i = len(poses) - 2
            t1 = poses[i].timestamp
            t2 = poses[i + 1].timestamp
        else:
            # åœ¨èŒƒå›´å†…ï¼Œåº”è¯¥ä½¿ç”¨æ’å€¼
            return None
        
        # è®¡ç®—å¤–æ¨ç³»æ•°ï¼ˆä¼šè¶…å‡º[0,1]èŒƒå›´ï¼‰
        if t2 == t1:
            return None
        alpha = (timestamp - t1) / (t2 - t1)
        
        # ä½å§¿1
        R1 = UndistortionUtils.quat_to_matrix(poses[i].orientation)
        t1_vec = poses[i].position
        
        # ä½å§¿2
        R2 = UndistortionUtils.quat_to_matrix(poses[i + 1].orientation)
        t2_vec = poses[i + 1].position
        
        # è®¡ç®—ç›¸å¯¹è¿åŠ¨
        R_delta = R1.T @ R2
        t_delta = R1.T @ (t2_vec - t1_vec)
        
        # è½¬æ¢ä¸º6Då‘é‡å¹¶å¤–æ¨
        v_delta = UndistortionUtils.isometry_to_vec6(R_delta, t_delta)
        v_extrap = v_delta * alpha  # alphaå¯ä»¥<0æˆ–>1
        
        # è½¬æ¢å›çŸ©é˜µ
        R_extrap, t_extrap = UndistortionUtils.vec6_to_isometry(v_extrap)
        
        # åº”ç”¨åˆ°pose1
        R_result = R1 @ R_extrap
        t_result = t1_vec + R1 @ t_extrap
        
        return R_result, t_result
    
    @staticmethod
    def undistort_pointcloud(points_raw: np.ndarray,
                            cloud_timestamp: float,
                            target_timestamp: float,
                            poses: List[PoseMetadata],
                            debug: bool = False,
                            frame_idx: int = -1) -> np.ndarray:
        """ç‚¹äº‘å»ç•¸å˜ï¼ˆå®Œå…¨å¯¹é½C++å®ç°ï¼‰
        
        å‚è€ƒ: ~/codetree/repo/calibration/modules/calib_utils/src/math_utils.cpp:169-252
        
        âœ… å…³é”®å‡è®¾ï¼ˆä¸C++ä¸€è‡´ï¼‰ï¼š
            1. è¾“å…¥posesæ˜¯ Sensingâ†’World å˜æ¢ï¼ˆSensingåœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
            2. LiDARç³» = Sensingç³»ï¼ˆiso_vehicle_lidar = Identityï¼‰
        
        ğŸ¯ å»ç•¸å˜åŸç†ï¼š
            - å°†ç‚¹äº‘ä»æ¿€å…‰é›·è¾¾æ‰«ææ—¶åˆ»(cloud_timestamp)è½¬æ¢åˆ°ç›®æ ‡æ—¶åˆ»(target_timestamp)
            - ç›®çš„ï¼šæ¶ˆé™¤è½¦è¾†è¿åŠ¨é€ æˆçš„ç‚¹äº‘ç•¸å˜ï¼Œä½¿ç‚¹äº‘ä¸å›¾åƒåœ¨ç©ºé—´ä¸Šå¯¹é½
            - è¾“å‡ºçš„ç‚¹äº‘åœ¨é€»è¾‘ä¸Šå¯¹åº”äºtarget_timestampæ—¶åˆ»çš„LiDARåæ ‡ç³»
        
        Args:
            points_raw: åŸå§‹ç‚¹äº‘ (N, 5): x, y, z, intensity, timestamp (LiDARåæ ‡ç³»)
                       å…¶ä¸­timestampå•ä½æ˜¯2å¾®ç§’
            cloud_timestamp: ç‚¹äº‘æ‰«æå¼€å§‹æ—¶åˆ»ï¼ˆç§’ï¼‰
            target_timestamp: ç›®æ ‡æ—¶åˆ»ï¼ˆé€šå¸¸æ˜¯å›¾åƒæ›å…‰æ—¶åˆ»ï¼Œç§’ï¼‰
            poses: GNSSä½å§¿åˆ—è¡¨ï¼ˆSensingâ†’Worldï¼Œå·²è½¬æ¢ï¼ï¼‰
            debug: æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
            frame_idx: å¸§ç´¢å¼•ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            å»ç•¸å˜åçš„ç‚¹äº‘ (N, 4): x, y, z, intensity
            âœ… ç©ºé—´ä½ç½®å¯¹åº”äºtarget_timestampæ—¶åˆ»çš„LiDARåæ ‡ç³»
            âœ… ä¸è¯¥æ—¶åˆ»çš„å›¾åƒå®Œå…¨å¯¹é½ï¼ˆæ—¶é—´å’Œç©ºé—´åŒé‡å¯¹é½ï¼‰
            âœ… ä¸åŒ…å«timestampï¼ˆæ‰€æœ‰ç‚¹å·²ç»Ÿä¸€åˆ°target_timestampï¼ŒåŸå§‹æ—¶é—´æˆ³å·²æ— æ„ä¹‰ï¼‰
            âœ… ç¬¦åˆKITTIæ ‡å‡†æ ¼å¼
        
        C++å‚è€ƒï¼š
            - math_utils.cpp:184-188: lidar_pose_data = vehicle_poses * iso_vehicle_lidar
            - math_utils.cpp:200: delta_stamp = max_inner_stamp * 2 (å•ä½:2us)
            - math_utils.cpp:215: dt = timestamp * 2.0e-6 (å•ä½:2us)
            
        âš ï¸ ä¸C++æ—¶é—´æˆ³å•ä½å¯¹æ¯”ï¼š
            - C++: cloud_stamp/target_stamp æ˜¯å¾®ç§’(int64_t)ï¼Œposeæ—¶é—´æˆ³ä¹Ÿæ˜¯å¾®ç§’
            - C++: æ’å€¼æ—¶ pose_data[i].first * 1e-6 è½¬æ¢ä¸ºç§’
            - Python: æ‰€æœ‰æ—¶é—´æˆ³å·²ç»æ˜¯ç§’ï¼Œæ— éœ€è½¬æ¢
        """
        if points_raw.shape[1] < 5:
            # æ²¡æœ‰timestampï¼Œæ— æ³•å»ç•¸å˜ï¼Œç›´æ¥è¿”å›å‰4åˆ—
            return points_raw[:, :4]
        
        if not poses or len(poses) == 0:
            # æ²¡æœ‰ä½å§¿æ•°æ®ï¼Œæ— æ³•å»ç•¸å˜
            return points_raw[:, :4]
        
        # âœ… æ£€æµ‹ç‚¹äº‘æ˜¯å¦å·²ç»åœ¨ä¸–ç•Œåæ ‡ç³»
        # ä¼ æ„Ÿå™¨åæ ‡ç³»çš„ç‚¹äº‘èŒƒå›´é€šå¸¸åœ¨ Â±200m ä»¥å†…
        # ä¸–ç•Œåæ ‡ç³»çš„ç‚¹äº‘åæ ‡å¯èƒ½éå¸¸å¤§ï¼ˆå–å†³äºè½¦è¾†ä½ç½®ï¼‰
        xyz = points_raw[:, :3]
        xyz_range = np.abs(xyz).max()
        
        if xyz_range > 250.0:  # å¦‚æœåæ ‡è¶…è¿‡250mï¼Œè®¤ä¸ºå·²ç»åœ¨ä¸–ç•Œåæ ‡ç³»
            if debug:
                print(f"âš ï¸  æ£€æµ‹åˆ°ç‚¹äº‘å·²åœ¨ä¸–ç•Œåæ ‡ç³»ï¼ˆèŒƒå›´: {xyz_range:.1f}mï¼‰ï¼Œå°†è½¬æ¢å›ä¼ æ„Ÿå™¨åæ ‡ç³»")
            
            # è·å–ç‚¹äº‘æ—¶åˆ»çš„ä½å§¿ï¼ˆSensingâ†’Worldï¼‰
            cloud_pose = UndistortionUtils.motion_interpolate(poses, cloud_timestamp)
            if cloud_pose is None:
                return None
            
            R_world_sensing, t_world_sensing = cloud_pose
            # ä¸–ç•Œåæ ‡ç³» â†’ ä¼ æ„Ÿå™¨åæ ‡ç³»
            R_sensing_world = R_world_sensing.T
            t_sensing_world = -R_world_sensing.T @ t_world_sensing
            
            # è½¬æ¢ç‚¹äº‘åˆ°ä¼ æ„Ÿå™¨åæ ‡ç³»
            xyz_sensing = (R_sensing_world @ xyz.T).T + t_sensing_world
            
            # æ›´æ–°ç‚¹äº‘æ•°æ®
            points_raw = np.hstack([xyz_sensing, points_raw[:, 3:]])
            
            if debug:
                print(f"  è½¬æ¢åèŒƒå›´: X=[{xyz_sensing[:, 0].min():.1f}, {xyz_sensing[:, 0].max():.1f}]")
        
        # æ‰¾åˆ°ç‚¹äº‘æ‰«æçš„æœ€å¤§å†…éƒ¨æ—¶é—´æˆ³ï¼ˆå•ä½ï¼š2å¾®ç§’ï¼‰
        # C++å‚è€ƒï¼šmath_utils.cpp:190-200
        max_inner_timestamp_2us = points_raw[:, 4].max()
        delta_time_us = max_inner_timestamp_2us * 2  # è½¬æ¢ä¸ºå¾®ç§’
        end_timestamp = cloud_timestamp + delta_time_us * 1e-6  # è½¬æ¢ä¸ºç§’
        
        # æ’å€¼è·å–ä¸‰ä¸ªå…³é”®æ—¶åˆ»çš„ä½å§¿ï¼ˆSensingâ†’Worldå˜æ¢ï¼‰
        # C++å‚è€ƒï¼šmath_utils.cpp:198-205
        start_pose = UndistortionUtils.motion_interpolate(poses, cloud_timestamp)
        end_pose = UndistortionUtils.motion_interpolate(poses, end_timestamp)
        target_pose = UndistortionUtils.motion_interpolate(poses, target_timestamp)
        
        if start_pose is None or end_pose is None or target_pose is None:
            # æ’å€¼å¤±è´¥ï¼Œè¿”å› None è¡¨ç¤ºè¯¥å¸§åº”è¯¥è¢«è·³è¿‡
            # C++å‚è€ƒï¼šmath_utils.cpp:247-250 - å¤±è´¥æ—¶è·³è¿‡è¯¥å¸§
            # æ³¨æ„ï¼šä¸åº”è¯¥è¿”å›åŸå§‹ç‚¹äº‘ï¼Œå› ä¸ºæ²¡æœ‰æ­£ç¡®çš„ä½å§¿æ’å€¼ä¼šå¯¼è‡´åæ ‡é”™è¯¯
            return None
        
        R_start, t_start = start_pose  # Sensingâ†’Worldï¼ˆå·²è½¬æ¢ï¼ï¼‰
        R_end, t_end = end_pose
        R_target, t_target = target_pose
        
        # âœ… ä½å§¿åˆç†æ€§æ£€æŸ¥ï¼šæ£€æµ‹ä½å§¿çªå˜
        # æ­£å¸¸æƒ…å†µä¸‹ï¼Œstart/end/targetä¸‰ä¸ªä½å§¿åº”è¯¥éå¸¸æ¥è¿‘ï¼ˆæ—¶é—´è·¨åº¦é€šå¸¸<100msï¼‰
        # å¦‚æœä½å§¿å·®å¼‚è¿‡å¤§ï¼Œè¯´æ˜æ•°æ®æœ‰é—®é¢˜ï¼ˆå¦‚ä½å§¿è·³å˜ã€æ—¶é—´æˆ³é”™è¯¯ç­‰ï¼‰
        MAX_POSE_DISPLACEMENT = 5.0  # æœ€å¤§å…è®¸ä½ç§»ï¼ˆç±³ï¼‰- å¯¹åº”50m/sè½¦é€Ÿä¸‹çš„100ms
        MAX_POSE_ROTATION = 0.5  # æœ€å¤§å…è®¸æ—‹è½¬ï¼ˆå¼§åº¦ï¼‰- çº¦30åº¦
        
        # æ£€æŸ¥startåˆ°endçš„ä½ç§»
        displacement_se = np.linalg.norm(t_end - t_start)
        # æ£€æŸ¥startåˆ°targetçš„ä½ç§»
        displacement_st = np.linalg.norm(t_target - t_start)
        
        # æ£€æŸ¥æ—‹è½¬å˜åŒ–ï¼ˆä½¿ç”¨æ—‹è½¬å‘é‡çš„æ¨¡ï¼‰
        R_delta_se = R_start.T @ R_end
        rotation_se = np.linalg.norm(R.from_matrix(R_delta_se).as_rotvec())
        R_delta_st = R_start.T @ R_target
        rotation_st = np.linalg.norm(R.from_matrix(R_delta_st).as_rotvec())
        
        if displacement_se > MAX_POSE_DISPLACEMENT or displacement_st > MAX_POSE_DISPLACEMENT:
            if debug:
                print(f"âš ï¸  ä½å§¿ä½ç§»å¼‚å¸¸ï¼start-end: {displacement_se:.2f}m, start-target: {displacement_st:.2f}m")
            return None
        
        if rotation_se > MAX_POSE_ROTATION or rotation_st > MAX_POSE_ROTATION:
            if debug:
                print(f"âš ï¸  ä½å§¿æ—‹è½¬å¼‚å¸¸ï¼start-end: {np.degrees(rotation_se):.1f}Â°, start-target: {np.degrees(rotation_st):.1f}Â°")
            return None
        
        # ğŸ” DEBUG: æ‰“å°poseä¿¡æ¯ï¼ˆå¯¹é½C++æ—¥å¿—æ ¼å¼ï¼Œä¾¿äºå¯¹æ¯”ï¼‰
        if debug:
            print(f"\n{'='*60}")
            print(f"ğŸ” å»ç•¸å˜è°ƒè¯•ä¿¡æ¯ [frame_idx={frame_idx}]")
            print(f"{'='*60}")
            print(f"  === æ—¶é—´æˆ³ä¿¡æ¯ (Pythonç”¨ç§’ï¼ŒC++ç”¨å¾®ç§’) ===")
            print(f"  cloud_stamp(s): {cloud_timestamp:.6f}")
            print(f"  cloud_stamp(us): {int(cloud_timestamp * 1e6)}")  # ä¾¿äºä¸C++å¯¹æ¯”
            print(f"  target_stamp(s): {target_timestamp:.6f}")
            print(f"  target_stamp(us): {int(target_timestamp * 1e6)}")
            print(f"  lidar_camera_delta(ms): {(target_timestamp - cloud_timestamp)*1000:.2f}")
            print(f"  ")
            print(f"  === ç‚¹äº‘å†…éƒ¨æ—¶é—´æˆ³ ===")
            print(f"  max_inner_stamp(2us): {max_inner_timestamp_2us:.0f}")
            print(f"  delta_stamp(us): {delta_time_us:.0f}")
            print(f"  end_stamp(s): {end_timestamp:.6f}")
            print(f"  scan_duration(ms): {delta_time_us * 1e-3:.2f}")
            print(f"  ")
            print(f"  === ä½å§¿èŒƒå›´ ===")
            print(f"  poses.size(): {len(poses)}")
            print(f"  pose_range(s): [{poses[0].timestamp:.6f}, {poses[-1].timestamp:.6f}]")
            print(f"  ")
            print(f"  === æ’å€¼ä½å§¿ (Sensingâ†’World) ===")
            print(f"  start_pose.t: [{t_start[0]:.4f}, {t_start[1]:.4f}, {t_start[2]:.4f}]")
            print(f"  end_pose.t: [{t_end[0]:.4f}, {t_end[1]:.4f}, {t_end[2]:.4f}]")
            print(f"  target_pose.t: [{t_target[0]:.4f}, {t_target[1]:.4f}, {t_target[2]:.4f}]")
        
        R_lidar_start = R_start
        t_lidar_start = t_start
        R_lidar_end = R_end
        t_lidar_end = t_end
        R_lidar_target = R_target
        t_lidar_target = t_target
        
        # è®¡ç®—è¿åŠ¨å¢é‡ï¼ˆLiDARåæ ‡ç³»ï¼‰
        # âœ… æœ€ç»ˆä¿®å¤ï¼šå»ç•¸å˜å˜æ¢ï¼ˆå¯¹é½C++é€»è¾‘ï¼‰
        # 
        # C++ä¸­poseçš„å«ä¹‰ï¼š
        # - lidar_pose = (Vehicleâ†’World) @ (LiDARâ†’Vehicle) = LiDARâ†’World
        # 
        # å»ç•¸å˜æµç¨‹ï¼š
        # 1. ç‚¹påœ¨(start+dt)æ—¶åˆ»çš„LiDARç³»
        # 2. å˜æ¢åˆ°Worldç³»ï¼šP_world = LiDARâ†’World(start+dt) * p
        # 3. å˜æ¢åˆ°targetæ—¶åˆ»çš„LiDARç³»ï¼špu = Worldâ†’LiDAR(target) * P_world
        #                              = Worldâ†’LiDAR(target) * LiDARâ†’World(start+dt) * p
        # 
        # å…¶ä¸­ï¼šLiDARâ†’World(start+dt) â‰ˆ LiDARâ†’World(start) * exp(v*dt)
        # 
        # C++å®ç°ï¼š
        # - delta = inv(start) * end  ï¼ˆä»startåˆ°endçš„è¿åŠ¨ï¼‰
        # - iso_target_start = inv(target) * start  ï¼ˆä»startçš„LiDARåˆ°targetçš„LiDARï¼‰
        # - delta2 = iso_target_start * delta2  ï¼ˆç»„åˆå˜æ¢ï¼‰
        # - pu = delta2 * p  ï¼ˆåº”ç”¨åˆ°ç‚¹ï¼‰
        
        # delta = inv(start) * end ï¼ˆä»startåˆ°endçš„è¿åŠ¨ï¼‰
        R_delta = R_lidar_start.T @ R_lidar_end
        t_delta = R_lidar_start.T @ (t_lidar_end - t_lidar_start)
        v_full = UndistortionUtils.isometry_to_vec6(R_delta, t_delta)
        v_per_second = v_full / (delta_time_us * 1e-6)
        
        # iso_target_start = inv(target) * start ï¼ˆä»startçš„LiDARåˆ°targetçš„LiDARï¼‰
        R_target_start = R_lidar_target.T @ R_lidar_start  # âœ… æ¢å¤ï¼štarget^{-1} * start
        t_target_start = R_lidar_target.T @ (t_lidar_start - t_lidar_target)  # âœ… æ¢å¤
        
        # å‘é‡åŒ–å¤„ç†æ‰€æœ‰ç‚¹
        xyz = points_raw[:, :3]  # (N, 3) LiDARåæ ‡ç³»
        intensity = points_raw[:, 3:4]  # (N, 1)
        ts_us = points_raw[:, 4]  # (N,)
        
        # è®¡ç®—æ¯ä¸ªç‚¹çš„æ—¶é—´åç§»ï¼ˆç§’ï¼‰
        dt = ts_us * 2.0e-6  # (N,) uint: 2us
        
        # è®¡ç®—æ¯ä¸ªç‚¹çš„è¿åŠ¨å¢é‡ v2 = v * dt
        v_points = v_per_second[np.newaxis, :] * dt[:, np.newaxis]  # (N, 6)
        r_vecs = v_points[:, :3]  # (N, 3)
        t_vecs = v_points[:, 3:6]  # (N, 3)
        
        # æ‰¹é‡è®¡ç®—delta2 (å¯¹åº”C++çš„Vec2Isometry)
        R_delta2 = R.from_rotvec(r_vecs).as_matrix()  # (N, 3, 3)
        
        # âœ… æœ€ç»ˆä¿®å¤ï¼šdelta2 = iso_target_start * delta2ï¼ˆå®Œå…¨å¯¹é½C++ï¼‰
        # 
        # å…³é”®ç†è§£ï¼šdelta2ä¸æ˜¯LiDARç³»ä¸­çš„å¢é‡ï¼Œè€Œæ˜¯poseçš„å³ä¹˜å¢é‡
        # å³ï¼špose(start+dt) = pose(start) * delta2
        # å…¶ä¸­poseè¡¨ç¤ºLiDARâ†’Worldçš„å˜æ¢
        # 
        # æ‰€ä»¥æœ€ç»ˆå˜æ¢ï¼š
        # delta2_final = iso_target_start * delta2
        #              = [inv(target) * start] * delta2
        #              = inv(target) * [start * delta2]
        #              = inv(target) * (start+dt)
        #              = Worldâ†’LiDAR(target) * LiDARâ†’World(start+dt)
        # 
        # åº”ç”¨åˆ°ç‚¹ï¼š
        # pu = delta2_final * p
        #    = Worldâ†’LiDAR(target) * LiDARâ†’World(start+dt) * p
        # 
        # ç‰©ç†å«ä¹‰ï¼šç‚¹pä»(start+dt)æ—¶åˆ»çš„LiDARç³»å˜æ¢åˆ°targetæ—¶åˆ»çš„LiDARç³»
        
        # é½æ¬¡å˜æ¢çŸ©é˜µä¹˜æ³•ï¼šiso_target_start * delta2
        R_combined = np.einsum('ij,njk->nik', R_target_start, R_delta2)  # (N, 3, 3)
        t_combined = np.einsum('ij,nj->ni', R_target_start, t_vecs) + t_target_start  # (N, 3)
        
        # åº”ç”¨åˆ°ç‚¹ï¼špu = delta2 * p ï¼ˆå¯¹åº”C++ç¬¬225è¡Œï¼‰
        xyz_undistorted = np.einsum('nij,nj->ni', R_combined, xyz) + t_combined  # (N, 3)
        
        # æ‹¼æ¥å¼ºåº¦ï¼ˆä¸ä¿ç•™timestampï¼‰
        # æ³¨æ„ï¼šå»ç•¸å˜åæ‰€æœ‰ç‚¹éƒ½åœ¨target_timestampæ—¶åˆ»ï¼ŒåŸå§‹timestampå·²æ— æ„ä¹‰
        # è¾“å‡ºæ ¼å¼ï¼š(N, 4) = [x, y, z, intensity]ï¼ˆç¬¦åˆKITTIæ ‡å‡†ï¼‰
        points_undistorted = np.hstack([xyz_undistorted, intensity])  # (N, 4)
        
        # âœ… ç»“æœèŒƒå›´éªŒè¯ï¼šæ£€æµ‹å»ç•¸å˜å¼‚å¸¸
        # åˆç†çš„ä¼ æ„Ÿå™¨æ•°æ®èŒƒå›´ï¼š
        # - æ¿€å…‰é›·è¾¾é€šå¸¸æœ‰æ•ˆèŒƒå›´ 200m
        # - å»ç•¸å˜ä¸åº”è¯¥æ˜¾è‘—æ”¹å˜ç‚¹äº‘çš„ä½ç½®ï¼Œåªåšå¾®å°è°ƒæ•´
        # - å¼‚å¸¸æƒ…å†µï¼šä½å§¿æ’å€¼å¤–æ¨æ—¶å¯èƒ½äº§ç”Ÿæç«¯å˜æ¢
        MAX_REASONABLE_RANGE = 250.0  # æœ€å¤§åˆç†è·ç¦» (ç±³)
        MAX_REASONABLE_HEIGHT = 50.0  # æœ€å¤§åˆç†é«˜åº¦ (ç±³)
        
        x_min, x_max = xyz_undistorted[:, 0].min(), xyz_undistorted[:, 0].max()
        y_min, y_max = xyz_undistorted[:, 1].min(), xyz_undistorted[:, 1].max()
        z_min, z_max = xyz_undistorted[:, 2].min(), xyz_undistorted[:, 2].max()
        
        is_abnormal = (
            x_min < -MAX_REASONABLE_RANGE or x_max > MAX_REASONABLE_RANGE or
            y_min < -MAX_REASONABLE_RANGE or y_max > MAX_REASONABLE_RANGE or
            z_min < -MAX_REASONABLE_HEIGHT or z_max > MAX_REASONABLE_HEIGHT
        )
        
        if is_abnormal:
            print(f"âš ï¸  å»ç•¸å˜ç»“æœå¼‚å¸¸ï¼ŒèŒƒå›´è¶…é™ï¼")
            print(f"    X: [{x_min:.2f}, {x_max:.2f}], Y: [{y_min:.2f}, {y_max:.2f}], Z: [{z_min:.2f}, {z_max:.2f}]")
            print(f"    åˆç†èŒƒå›´: XY Â±{MAX_REASONABLE_RANGE}m, Z Â±{MAX_REASONABLE_HEIGHT}m")
            # è¿”å› None è¡¨ç¤ºè¯¥å¸§åº”è¯¥è¢«è·³è¿‡
            return None
        
        # ğŸ” DEBUG: æ‰“å°ç»“æœç»Ÿè®¡ï¼ˆæ ¼å¼å¯¹é½C++ MLOGè¾“å‡ºï¼Œä¾¿äºé€è¡Œå¯¹æ¯”ï¼‰
        if debug:
            print(f"  ")
            print(f"  === è¿åŠ¨å¢é‡ (å¯¹é½C++: delta = inv(start) * end) ===")
            print(f"  delta.translation: [{t_delta[0]:.6f}, {t_delta[1]:.6f}, {t_delta[2]:.6f}]")
            print(f"  v(6d): {v_full}")
            print(f"  v_per_sec(trans): [{v_per_second[3]:.6f}, {v_per_second[4]:.6f}, {v_per_second[5]:.6f}] m/s")
            print(f"  v_per_sec(rot): [{v_per_second[0]:.6f}, {v_per_second[1]:.6f}, {v_per_second[2]:.6f}] rad/s")
            print(f"  ")
            print(f"  === iso_target_start (å¯¹é½C++: inv(target) * start) ===")
            print(f"  iso_target_start.translation: [{t_target_start[0]:.6f}, {t_target_start[1]:.6f}, {t_target_start[2]:.6f}]")
            iso_ts_rotvec = R.from_matrix(R_target_start).as_rotvec()
            print(f"  iso_target_start.axis*angle: [{iso_ts_rotvec[0]:.6f}, {iso_ts_rotvec[1]:.6f}, {iso_ts_rotvec[2]:.6f}]")
            print(f"  ")
            
            # âœ… å…³é”®å¯¹æ¯”ï¼šå‰10ä¸ªç‚¹çš„é€ç‚¹å»ç•¸å˜è¿‡ç¨‹ï¼ˆä¸C++å®Œå…¨å¯¹é½ï¼‰
            print(f"  === First 10 points undistortion detail ===")
            for i in range(min(10, len(xyz))):
                dt_i = ts_us[i] * 2.0e-6  # ç§’
                v2_i = v_per_second * dt_i
                R_delta2_i = R.from_rotvec(v2_i[:3]).as_matrix()
                t_delta2_i = v2_i[3:6]
                
                # delta2 = iso_target_start * delta2
                R_comb_i = R_target_start @ R_delta2_i
                t_comb_i = R_target_start @ t_delta2_i + t_target_start
                
                p_raw = xyz[i]
                p_undist = R_comb_i @ p_raw + t_comb_i
                
                print(f"  Point[{i}] ts_2us={ts_us[i]:.0f}"
                      f" dt_sec={dt_i:.6f}"
                      f" raw=[{p_raw[0]:.4f}, {p_raw[1]:.4f}, {p_raw[2]:.4f}]"
                      f" undist=[{p_undist[0]:.4f}, {p_undist[1]:.4f}, {p_undist[2]:.4f}]")
            
            print(f"  ")
            print(f"  === ç‚¹äº‘èŒƒå›´ ===")
            print(f"  cloud_raw range: X=[{xyz[:, 0].min():.2f}, {xyz[:, 0].max():.2f}]"
                  f" Y=[{xyz[:, 1].min():.2f}, {xyz[:, 1].max():.2f}]"
                  f" Z=[{xyz[:, 2].min():.2f}, {xyz[:, 2].max():.2f}]")
            print(f"  cloud_undistorted range: X=[{xyz_undistorted[:, 0].min():.2f}, {xyz_undistorted[:, 0].max():.2f}]"
                  f" Y=[{xyz_undistorted[:, 1].min():.2f}, {xyz_undistorted[:, 1].max():.2f}]"
                  f" Z=[{xyz_undistorted[:, 2].min():.2f}, {xyz_undistorted[:, 2].max():.2f}]")
            
            diff = xyz_undistorted - xyz
            print(f"  ")
            print(f"  === å»ç•¸å˜ä½ç§»ç»Ÿè®¡ ===")
            print(f"  Difference (mean Â± std):")
            print(f"    X: {diff[:, 0].mean():.6f} Â± {diff[:, 0].std():.6f}m, max={np.abs(diff[:, 0]).max():.6f}m")
            print(f"    Y: {diff[:, 1].mean():.6f} Â± {diff[:, 1].std():.6f}m, max={np.abs(diff[:, 1]).max():.6f}m")
            print(f"    Z: {diff[:, 2].mean():.6f} Â± {diff[:, 2].std():.6f}m, max={np.abs(diff[:, 2]).max():.6f}m")
            max_displacement = np.sqrt((diff**2).sum(axis=1)).max()
            mean_displacement = np.sqrt((diff**2).sum(axis=1)).mean()
            print(f"  æœ€å¤§ä½ç§»: {max_displacement:.6f}m, å¹³å‡ä½ç§»: {mean_displacement:.6f}m")
            if max_displacement > 1.0:
                print(f"  âš ï¸ è­¦å‘Š: æœ€å¤§ä½ç§»è¶…è¿‡1ç±³ï¼Œæ£€æŸ¥æ˜¯å¦æ­£å¸¸ï¼")
            print(f"{'='*60}\n")
        
        return points_undistorted.astype(np.float32)


class ConfigParser:
    """é…ç½®æ–‡ä»¶è§£æå™¨"""
    
    @staticmethod
    def parse_cameras_cfg(filepath: str) -> Dict:
        """è§£æ cameras.cfg æ–‡ä»¶"""
        with open(filepath, 'r') as f:
            content = f.read()
        
        cameras = {}
        config_pattern = r'config\s*\{(.*?)\n\}'
        config_blocks = re.findall(config_pattern, content, re.DOTALL)
        
        for block in config_blocks:
            camera = ConfigParser._parse_camera_block(block)
            if camera:
                cameras[camera['camera_dev']] = camera
        
        return cameras
    
    @staticmethod
    def _parse_camera_block(block: str) -> Optional[Dict]:
        """è§£æå•ä¸ªç›¸æœºé…ç½®å—"""
        
        def get_value(pattern, text, default=None):
            match = re.search(pattern, text)
            return match.group(1).strip().strip('"') if match else default
        
        def get_float(pattern, text, default=0.0):
            val = get_value(pattern, text)
            return float(val) if val is not None else default
        
        def get_int(pattern, text, default=0):
            val = get_value(pattern, text)
            return int(val) if val is not None else default
        
        camera_dev = get_value(r'camera_dev:\s*"([^"]+)"', block)
        if not camera_dev:
            return None
        
        pos_x = get_float(r'position\s*\{[^}]*x:\s*([-\d.e]+)', block)
        pos_y = get_float(r'position\s*\{[^}]*y:\s*([-\d.e]+)', block)
        pos_z = get_float(r'position\s*\{[^}]*z:\s*([-\d.e]+)', block)
        
        ori_qx = get_float(r'orientation\s*\{[^}]*qx:\s*([-\d.e]+)', block)
        ori_qy = get_float(r'orientation\s*\{[^}]*qy:\s*([-\d.e]+)', block)
        ori_qz = get_float(r'orientation\s*\{[^}]*qz:\s*([-\d.e]+)', block)
        ori_qw = get_float(r'orientation\s*\{[^}]*qw:\s*([-\d.e]+)', block)
        
        intrinsic = {
            'img_width': get_int(r'img_width:\s*(\d+)', block, 1920),
            'img_height': get_int(r'img_height:\s*(\d+)', block, 1080),
            'f_x': get_float(r'f_x:\s*([-\d.e]+)', block),
            'f_y': get_float(r'f_y:\s*([-\d.e]+)', block),
            'o_x': get_float(r'o_x:\s*([-\d.e]+)', block),
            'o_y': get_float(r'o_y:\s*([-\d.e]+)', block),
        }
        
        # è§£æç•¸å˜ç³»æ•°ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        # å®é™…é…ç½®æ ¼å¼éƒ½æ˜¯å¸¦ä¸‹åˆ’çº¿çš„ï¼šk_1, k_2, p_1, p_2
        # æ ¹æ®model_typeåŒºåˆ†ï¼š
        # - PINHOLE: k_1, k_2, p_1, p_2 (é’ˆå­”ç›¸æœºï¼Œæœ‰å¾„å‘å’Œåˆ‡å‘ç•¸å˜)
        # - KANNALA_BRANDT: k_1, k_2, k_3, k_4 (é±¼çœ¼ç›¸æœºï¼Œåªæœ‰å¾„å‘ç•¸å˜)
        
        # æå–æ¨¡å‹ç±»å‹
        model_type_raw = get_value(r'model_type:\s*(\w+)', block, 'PINHOLE')
        
        # æå–ç•¸å˜ç³»æ•°ï¼ˆå¸¦ä¸‹åˆ’çº¿ï¼‰
        k_1 = get_float(r'k_1:\s*([-\d.e]+)', block, None)
        k_2 = get_float(r'k_2:\s*([-\d.e]+)', block, None)
        p_1 = get_float(r'p_1:\s*([-\d.e]+)', block, None)
        p_2 = get_float(r'p_2:\s*([-\d.e]+)', block, None)
        k_3 = get_float(r'k_3:\s*([-\d.e]+)', block, None)
        k_4 = get_float(r'k_4:\s*([-\d.e]+)', block, None)
        
        if model_type_raw == 'KANNALA_BRANDT':
            # é±¼çœ¼æ¨¡å‹ï¼šåªæœ‰å¾„å‘ç•¸å˜ k_1, k_2, k_3, k_4
            distortion = {
                'k1': k_1 if k_1 is not None else 0.0,
                'k2': k_2 if k_2 is not None else 0.0,
                'k3': k_3 if k_3 is not None else 0.0,
                'k4': k_4 if k_4 is not None else 0.0,
                'model_type': 'fisheye',
            }
        else:
            # PINHOLEé’ˆå­”æ¨¡å‹ï¼šå¾„å‘ç•¸å˜ k_1, k_2 + åˆ‡å‘ç•¸å˜ p_1, p_2
            distortion = {
                'k1': k_1 if k_1 is not None else 0.0,
                'k2': k_2 if k_2 is not None else 0.0,
                'p1': p_1 if p_1 is not None else 0.0,
                'p2': p_2 if p_2 is not None else 0.0,
                'k3': 0.0,  # PINHOLEé€šå¸¸åªç”¨k1, k2
                'model_type': 'pinhole',
            }
        
        return {
            'camera_dev': camera_dev,
            'position': np.array([pos_x, pos_y, pos_z]),
            'orientation': np.array([ori_qx, ori_qy, ori_qz, ori_qw]),
            'intrinsic': intrinsic,
            'distortion': distortion
        }
    
    @staticmethod
    def parse_lidars_cfg(filepath: str) -> Dict:
        """è§£æ lidars.cfg æ–‡ä»¶ï¼ˆåŒ…å«vehicle_to_sensingå’Œsensor_to_lidarï¼‰"""
        with open(filepath, 'r') as f:
            content = f.read()
        
        def find_block(text, name):
            m = re.search(rf'{name}\s*\{{', text)
            if not m:
                return None
            start = m.end() - 1
            depth, i = 0, start
            while i < len(text):
                if text[i] == '{':
                    depth += 1
                elif text[i] == '}':
                    depth -= 1
                    if depth == 0:
                        return text[start + 1 : i]
                i += 1
            return None
        
        result = {}
        
        # 1. è§£ævehicle_to_sensingï¼ˆåœ¨æ ¹çº§åˆ«ï¼‰
        v2s_blk = find_block(content, 'vehicle_to_sensing')
        if v2s_blk:
            pos = find_block(v2s_blk, 'position')
            v2s_position = None
            if pos:
                x = re.search(r'x:\s*([-\d.e]+)', pos)
                y = re.search(r'y:\s*([-\d.e]+)', pos)
                z = re.search(r'z:\s*([-\d.e]+)', pos)
                if x and y and z:
                    v2s_position = np.array([float(x.group(1)), float(y.group(1)), float(z.group(1))])
            
            ori = find_block(v2s_blk, 'orientation')
            v2s_orientation = None
            if ori:
                qx = re.search(r'qx:\s*([-\d.e]+)', ori)
                qy = re.search(r'qy:\s*([-\d.e]+)', ori)
                qz = re.search(r'qz:\s*([-\d.e]+)', ori)
                qw = re.search(r'qw:\s*([-\d.e]+)', ori)
                if qx and qy and qz and qw:
                    v2s_orientation = [float(qx.group(1)), float(qy.group(1)), float(qz.group(1)), float(qw.group(1))]
            
            if v2s_position is not None and v2s_orientation is not None:
                result['vehicle_to_sensing'] = {
                    'position': v2s_position,
                    'orientation': v2s_orientation  # [qx, qy, qz, qw]
                }
        
        # 2. è§£æsensor_to_lidar
        blk = find_block(content, 'sensor_to_lidar')
        if not blk:
            config_blk = find_block(content, 'config')
            if config_blk:
                blk = find_block(config_blk, 'sensor_to_lidar')
            if not blk:
                raise ValueError(f'åœ¨ {filepath} ä¸­æœªæ‰¾åˆ° sensor_to_lidar')
        
        pos = find_block(blk, 'position')
        position = None
        if pos:
            x = re.search(r'x:\s*([-\d.e]+)', pos)
            y = re.search(r'y:\s*([-\d.e]+)', pos)
            z = re.search(r'z:\s*([-\d.e]+)', pos)
            if x and y and z:
                position = np.array([float(x.group(1)), float(y.group(1)), float(z.group(1))])
        
        ori = find_block(blk, 'orientation')
        orientation = None
        if ori:
            qx = re.search(r'qx:\s*([-\d.e]+)', ori)
            qy = re.search(r'qy:\s*([-\d.e]+)', ori)
            qz = re.search(r'qz:\s*([-\d.e]+)', ori)
            qw = re.search(r'qw:\s*([-\d.e]+)', ori)
            if qx and qy and qz and qw:
                orientation = np.array([
                    float(qx.group(1)), float(qy.group(1)),
                    float(qz.group(1)), float(qw.group(1))
                ])
        
        if position is None or orientation is None:
            raise ValueError(f'sensor_to_lidar çš„ position æˆ– orientation ä¸å®Œæ•´: {filepath}')
        
        # å°†sensor_to_lidarçš„positionå’Œorientationæ·»åŠ åˆ°resultä¸­
        result['position'] = position
        result['orientation'] = orientation
        
        return result


class PointCloudIO:
    """ç‚¹äº‘æ–‡ä»¶ I/O å·¥å…·"""
    
    @staticmethod
    def save_ply(points: np.ndarray, filepath: str):
        """ä¿å­˜ç‚¹äº‘ä¸º PLY æ ¼å¼ï¼ˆASCIIï¼Œæ–¹ä¾¿æŸ¥çœ‹å’Œå¯è§†åŒ–ï¼‰
        
        Args:
            points: (N, 3) æˆ– (N, 4) çš„ç‚¹äº‘æ•°æ®
            filepath: ä¿å­˜è·¯å¾„
        """
        if points.shape[1] == 3:
            # æ·»åŠ å¼ºåº¦é€šé“
            intensity = np.zeros((points.shape[0], 1), dtype=np.float32)
            points = np.hstack([points, intensity])
        
        with open(filepath, 'w') as f:
            # PLY header
            f.write("ply\n")
            f.write("format ascii 1.0\n")
            f.write(f"element vertex {points.shape[0]}\n")
            f.write("property float x\n")
            f.write("property float y\n")
            f.write("property float z\n")
            f.write("property float intensity\n")
            f.write("end_header\n")
            
            # ç‚¹äº‘æ•°æ®
            for point in points:
                f.write(f"{point[0]:.6f} {point[1]:.6f} {point[2]:.6f} {point[3]:.6f}\n")
    
    @staticmethod
    def load_ply(filepath: str) -> np.ndarray:
        """ä» PLY æ–‡ä»¶åŠ è½½ç‚¹äº‘
        
        Returns:
            (N, 4) çš„ç‚¹äº‘æ•°æ® [x, y, z, intensity]
        """
        with open(filepath, 'r') as f:
            # è¯»å– header
            line = f.readline()
            if not line.startswith('ply'):
                raise ValueError(f"ä¸æ˜¯æœ‰æ•ˆçš„ PLY æ–‡ä»¶: {filepath}")
            
            # è·³è¿‡ headerï¼Œæ‰¾åˆ° vertex æ•°é‡
            num_vertices = 0
            while True:
                line = f.readline()
                if line.startswith('element vertex'):
                    num_vertices = int(line.split()[-1])
                elif line.startswith('end_header'):
                    break
            
            # è¯»å–ç‚¹äº‘æ•°æ®
            points = []
            for _ in range(num_vertices):
                line = f.readline().strip()
                if line:
                    values = [float(v) for v in line.split()]
                    points.append(values[:4])  # x, y, z, intensity
            
            return np.array(points, dtype=np.float32)
    
    @staticmethod
    def ply_to_bin(ply_path: str, bin_path: str):
        """å°† PLY è½¬æ¢ä¸º BIN æ ¼å¼"""
        points = PointCloudIO.load_ply(ply_path)
        points.astype(np.float32).tofile(bin_path)


class ProtobufUtils:
    """Protobufæ¶ˆæ¯å¤„ç†å·¥å…·"""
    
    @staticmethod
    def extract_header_timestamp(data: bytes) -> Optional[float]:
        """ä»protobufæ¶ˆæ¯ä¸­æå–header.timestamp_sec()
        
        å‚è€ƒC++:
          image_msg.header().timestamp_sec()
          cloud_msg->header().timestamp_sec()
        
        Protobuf wire format:
          - field 1 (header): nested message
            - field 1 (timestamp_sec): double (64-bit)
        
        Args:
            data: protobufæ¶ˆæ¯çš„bytesæ•°æ®
            
        Returns:
            timestamp_sec (float)ï¼Œå¦‚æœè§£æå¤±è´¥è¿”å›None
        """
        # è·³è¿‡è‡ªå®šä¹‰header ($$$$å¼€å¤´)
        pos = 0
        if data.startswith(b'$$$$'):
            if len(data) < 8:
                return None
            # è¯»å–headeré•¿åº¦ï¼ˆ4å­—èŠ‚ï¼Œå°ç«¯ï¼‰
            header_len = struct.unpack('<I', data[4:8])[0]
            # è·³è¿‡ "$$$$" + é•¿åº¦å­—æ®µ + headerå†…å®¹
            pos = 8 + header_len
            if pos >= len(data):
                return None
        while pos < len(data):
            # è§£ætag
            if pos >= len(data):
                break
            tag = data[pos]
            pos += 1
            
            field_num = tag >> 3
            wire_type = tag & 7
            
            # field 1 æ˜¯ header (wire_type=2: length-delimited)
            if field_num == 1 and wire_type == 2:
                # è¯»å–é•¿åº¦
                length, pos_new = ProtobufUtils._decode_varint(data, pos)
                if pos_new >= len(data):
                    break
                pos = pos_new
                
                # è¯»å–headerå†…å®¹
                header_data = data[pos:pos+length]
                pos += length
                
                # åœ¨headerä¸­æŸ¥æ‰¾field 1 (timestamp_sec, wire_type=1: 64-bit)
                h_pos = 0
                while h_pos < len(header_data):
                    if h_pos >= len(header_data):
                        break
                    h_tag = header_data[h_pos]
                    h_pos += 1
                    
                    h_field_num = h_tag >> 3
                    h_wire_type = h_tag & 7
                    
                    if h_field_num == 1 and h_wire_type == 1:  # timestamp_sec (double)
                        if h_pos + 8 <= len(header_data):
                            timestamp_sec = struct.unpack('<d', header_data[h_pos:h_pos+8])[0]
                            return timestamp_sec
                        break
                    elif h_wire_type == 0:  # varint
                        _, h_pos = ProtobufUtils._decode_varint(header_data, h_pos)
                    elif h_wire_type == 1:  # 64-bit
                        h_pos += 8
                    elif h_wire_type == 2:  # length-delimited
                        l, h_pos = ProtobufUtils._decode_varint(header_data, h_pos)
                        h_pos += l
                    elif h_wire_type == 5:  # 32-bit
                        h_pos += 4
                    else:
                        break
                break
            elif wire_type == 0:  # varint
                _, pos = ProtobufUtils._decode_varint(data, pos)
            elif wire_type == 1:  # 64-bit
                pos += 8
            elif wire_type == 2:  # length-delimited
                length, pos = ProtobufUtils._decode_varint(data, pos)
                pos += length
            elif wire_type == 5:  # 32-bit
                pos += 4
            else:
                break
        
        return None
    
    @staticmethod
    def _decode_varint(buf: bytes, pos: int):
        """è§£æprotobuf varint"""
        n, sh = 0, 0
        while pos < len(buf):
            b = buf[pos]
            pos += 1
            n |= (b & 0x7F) << sh
            if not (b & 0x80):
                return n, pos
            sh += 7
            if sh >= 35:
                break
        return n, pos


class PointCloudParser:
    """ç‚¹äº‘è§£æå™¨ï¼ˆproto æ ¼å¼ï¼‰- å®Œå…¨å¯¹é½Self-Cali-GSå®ç°
    
    âœ… æ–°å¢ï¼šæ”¯æŒlidar_configsè§£æå’Œdecombineå¤„ç†ï¼ˆå¯¹é½C++ DecombineProtoPointCloudï¼‰
    """
    
    # DataType å¸¸é‡ï¼ˆä¸ PointCloud2.proto ä¸€è‡´ï¼‰
    _DT_INT8 = 1
    _DT_UINT8 = 2
    _DT_INT16 = 3
    _DT_UINT16 = 4
    _DT_INT32 = 5
    _DT_UINT32 = 6
    _DT_FLOAT32 = 7
    _DT_FLOAT64 = 8
    
    # é™æ€ç¼“å­˜ï¼šé¿å…é‡å¤æ‰“å°lidar_configsæ—¥å¿—
    _lidar_configs_logged = False
    
    @staticmethod
    def _decode_varint(buf: bytes, pos: int):
        """è§£æ protobuf varint"""
        n, sh = 0, 0
        while pos < len(buf):
            b = buf[pos]
            pos += 1
            n |= (b & 0x7F) << sh
            if not (b & 0x80):
                return n, pos
            sh += 7
            if sh >= 35:
                break
        return n, pos
    
    @staticmethod
    def _parse_header(data: bytes) -> dict:
        """è§£æ Header æ¶ˆæ¯
        
        Protoå®šä¹‰ (header.proto):
          - timestamp_sec: field 1 (double)
          - frame_id: field 9 (string)
        """
        result = {'timestamp_sec': None, 'frame_id': None}
        pos = 0
        
        while pos < len(data):
            tag, pos = PointCloudParser._decode_varint(data, pos)
            if pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 1:  # Fixed64 (double)
                if pos + 8 > len(data):
                    break
                if field_num == 1:  # timestamp_sec
                    result['timestamp_sec'] = struct.unpack_from('<d', data, pos)[0]
                pos += 8
            elif wire == 2:  # Length-delimited
                L, pos = PointCloudParser._decode_varint(data, pos)
                if pos + L > len(data):
                    break
                if field_num == 9:  # frame_id
                    result['frame_id'] = data[pos:pos + L].decode('utf-8', errors='ignore')
                pos += L
            elif wire == 0:  # Varint
                _, pos = PointCloudParser._decode_varint(data, pos)
            elif wire == 5:  # Fixed32
                pos += 4
            else:
                break
        
        return result
    
    @staticmethod
    def _parse_vector3(data: bytes) -> Optional[np.ndarray]:
        """è§£æ Vector3 æ¶ˆæ¯ (floatç‰ˆæœ¬)
        
        Protoå®šä¹‰ (geometry.proto):
          - x: field 1 (float)
          - y: field 2 (float)
          - z: field 3 (float)
        """
        x, y, z = 0.0, 0.0, 0.0
        pos = 0
        
        while pos < len(data):
            tag, pos = PointCloudParser._decode_varint(data, pos)
            if pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 5:  # Fixed32 (float)
                if pos + 4 > len(data):
                    break
                val = struct.unpack_from('<f', data, pos)[0]
                if field_num == 1:
                    x = val
                elif field_num == 2:
                    y = val
                elif field_num == 3:
                    z = val
                pos += 4
            elif wire == 0:  # Varint
                _, pos = PointCloudParser._decode_varint(data, pos)
            elif wire == 2:  # Length-delimited
                L, pos = PointCloudParser._decode_varint(data, pos)
                pos += L
            else:
                break
        
        return np.array([x, y, z], dtype=np.float32)
    
    @staticmethod
    def _parse_quaternion_f(data: bytes) -> Optional[np.ndarray]:
        """è§£æ Quaternion_f æ¶ˆæ¯ (floatç‰ˆæœ¬)
        
        Protoå®šä¹‰ (geometry.proto):
          - qx: field 1 (float)
          - qy: field 2 (float)
          - qz: field 3 (float)
          - qw: field 4 (float)
        """
        qx, qy, qz, qw = 0.0, 0.0, 0.0, 1.0
        pos = 0
        
        while pos < len(data):
            tag, pos = PointCloudParser._decode_varint(data, pos)
            if pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 5:  # Fixed32 (float)
                if pos + 4 > len(data):
                    break
                val = struct.unpack_from('<f', data, pos)[0]
                if field_num == 1:
                    qx = val
                elif field_num == 2:
                    qy = val
                elif field_num == 3:
                    qz = val
                elif field_num == 4:
                    qw = val
                pos += 4
            elif wire == 0:  # Varint
                _, pos = PointCloudParser._decode_varint(data, pos)
            elif wire == 2:  # Length-delimited
                L, pos = PointCloudParser._decode_varint(data, pos)
                pos += L
            else:
                break
        
        return np.array([qx, qy, qz, qw], dtype=np.float32)
    
    @staticmethod
    def _parse_transformation3(data: bytes) -> Optional[np.ndarray]:
        """è§£æ Transformation3 æ¶ˆæ¯ï¼Œè¿”å› 4x4 å˜æ¢çŸ©é˜µ
        
        Protoå®šä¹‰ (geometry.proto):
          - position: field 1 (Vector3)
          - orientation: field 2 (Quaternion_f)
        """
        position = np.zeros(3, dtype=np.float32)
        orientation = np.array([0, 0, 0, 1], dtype=np.float32)  # [qx, qy, qz, qw]
        pos = 0
        
        while pos < len(data):
            tag, pos = PointCloudParser._decode_varint(data, pos)
            if pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 2:  # Length-delimited
                L, pos = PointCloudParser._decode_varint(data, pos)
                if pos + L > len(data):
                    break
                chunk = data[pos:pos + L]
                pos += L
                
                if field_num == 1:  # position
                    position = PointCloudParser._parse_vector3(chunk)
                elif field_num == 2:  # orientation
                    orientation = PointCloudParser._parse_quaternion_f(chunk)
            elif wire == 0:  # Varint
                _, pos = PointCloudParser._decode_varint(data, pos)
            elif wire == 5:  # Fixed32
                pos += 4
            elif wire == 1:  # Fixed64
                pos += 8
            else:
                break
        
        # æ„å»º 4x4 å˜æ¢çŸ©é˜µ
        T = np.eye(4, dtype=np.float64)
        r = R.from_quat(orientation)  # [qx, qy, qz, qw]
        T[:3, :3] = r.as_matrix()
        T[:3, 3] = position
        
        return T
    
    @staticmethod
    def _parse_lidar_config_single(data: bytes) -> dict:
        """è§£æå•ä¸ª LidarConfig.Config æ¶ˆæ¯
        
        Protoå®šä¹‰ (config.proto):
          - frame_id: field 1 (string)
          - ring_id_start: field 27 (int32)
          - ring_id_end: field 28 (int32)
          - sensor_to_lidar: field 26 (repeated Transformation3)
        """
        result = {
            'frame_id': None,
            'ring_id_start': 0,
            'ring_id_end': 255,
            'sensor_to_lidar': None  # Transformation3
        }
        pos = 0
        
        while pos < len(data):
            tag, pos = PointCloudParser._decode_varint(data, pos)
            if pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 0:  # Varint
                val, pos = PointCloudParser._decode_varint(data, pos)
                if field_num == 27:
                    result['ring_id_start'] = val
                elif field_num == 28:
                    result['ring_id_end'] = val
            elif wire == 2:  # Length-delimited
                L, pos = PointCloudParser._decode_varint(data, pos)
                if pos + L > len(data):
                    break
                chunk = data[pos:pos + L]
                pos += L
                
                if field_num == 1:  # frame_id (string)
                    try:
                        result['frame_id'] = chunk.decode('utf-8', errors='ignore')
                    except:
                        pass
                elif field_num == 26:  # sensor_to_lidar (repeated)
                    # åªå–ç¬¬ä¸€ä¸ªsensor_to_lidar
                    if result['sensor_to_lidar'] is None:
                        result['sensor_to_lidar'] = PointCloudParser._parse_transformation3(chunk)
            elif wire == 5:  # Fixed32
                pos += 4
            elif wire == 1:  # Fixed64
                pos += 8
            else:
                break
        
        return result
    
    @staticmethod
    def _parse_lidar_configs(data: bytes, main_lidar_frame_id: str = "atx_202") -> dict:
        """è§£æ LidarConfig æ¶ˆæ¯
        
        Protoå®šä¹‰ (config.proto):
          - vehicle_to_sensing: field 1 (Transformation3)
          - config: field 2 (repeated Config)
        
        Args:
            data: protobufæ¶ˆæ¯bytesæ•°æ®
            main_lidar_frame_id: ä¸»lidarçš„frame_idï¼Œåªä¿ç•™è¯¥lidarçš„é…ç½®ï¼ˆé»˜è®¤"atx_202"ï¼‰
        
        è¿”å›:
          {
            'vehicle_to_sensing': 4x4 ndarray (Sensingâ†’Vehicle),
            'configs': [
              {'frame_id': str, 'ring_id_start': int, 'ring_id_end': int, 'sensor_to_lidar': 4x4 ndarray},
              ...
            ]
          }
        
        æ³¨æ„ï¼š
          å¦‚æœå­˜åœ¨å¤šä¸ªlidarï¼Œåªä¿ç•™frame_idä¸ºmain_lidar_frame_idçš„é…ç½®
        """
        result = {
            'vehicle_to_sensing': None,
            'configs': []
        }
        pos = 0
        
        while pos < len(data):
            tag, pos = PointCloudParser._decode_varint(data, pos)
            if pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 2:  # Length-delimited
                L, pos = PointCloudParser._decode_varint(data, pos)
                if pos + L > len(data):
                    break
                chunk = data[pos:pos + L]
                pos += L
                
                if field_num == 1:  # vehicle_to_sensing
                    result['vehicle_to_sensing'] = PointCloudParser._parse_transformation3(chunk)
                elif field_num == 2:  # config (repeated)
                    config = PointCloudParser._parse_lidar_config_single(chunk)
                    # âœ… è¿‡æ»¤ï¼šåªä¿ç•™ä¸»lidarçš„é…ç½®
                    if main_lidar_frame_id is None or config.get('frame_id') == main_lidar_frame_id:
                        result['configs'].append(config)
            elif wire == 0:  # Varint
                _, pos = PointCloudParser._decode_varint(data, pos)
            elif wire == 5:  # Fixed32
                pos += 4
            elif wire == 1:  # Fixed64
                pos += 8
            else:
                break
        
        return result
    
    @staticmethod
    def _extract_frame_id_and_lidar_configs(data: bytes, main_lidar_frame_id: str = "atx_202") -> Tuple[Optional[str], Optional[dict]]:
        """ä» PointCloud2 æ¶ˆæ¯ä¸­æå– frame_id å’Œ lidar_configs
        
        Protoå®šä¹‰ (pointcloud2.proto):
          - header: field 1 (Header)
          - lidar_configs: field 12 (LidarConfig)
        
        Args:
            data: protobufæ¶ˆæ¯bytesæ•°æ®
            main_lidar_frame_id: ä¸»lidarçš„frame_idï¼Œåªä¿ç•™è¯¥lidarçš„é…ç½®ï¼ˆé»˜è®¤"atx_202"ï¼‰
        
        âš ï¸ é‡è¦ï¼šlidar_configs (field 12) é€šå¸¸åœ¨æ¶ˆæ¯æœ«å°¾ï¼ˆåœ¨data blobä¹‹åï¼‰
        
        è¿”å›: (frame_id, lidar_configs)
        
        æ³¨æ„ï¼šå¦‚æœå­˜åœ¨å¤šä¸ªlidarï¼Œåªä¿ç•™frame_idä¸ºmain_lidar_frame_idçš„é…ç½®
        """
        frame_id = None
        lidar_configs = None
        
        # ç­–ç•¥1ï¼šä»å¼€å¤´è§£ææ‰¾ frame_idï¼ˆåœ¨headerä¸­ï¼Œé€šå¸¸åœ¨å‰100å­—èŠ‚ï¼‰
        pos = 0
        max_header_search = min(len(data), 500)  # åªæœç´¢å‰500å­—èŠ‚æ‰¾header
        
        while pos < max_header_search:
            try:
                tag, new_pos = PointCloudParser._decode_varint(data, pos)
            except:
                pos += 1
                continue
            if new_pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 2:  # Length-delimited
                L, new_pos = PointCloudParser._decode_varint(data, new_pos)
                if new_pos + L > len(data):
                    break
                chunk = data[new_pos:new_pos + L]
                
                if field_num == 1:  # header
                    header = PointCloudParser._parse_header(chunk)
                    frame_id = header.get('frame_id')
                    if frame_id:
                        break  # æ‰¾åˆ°frame_idååœæ­¢
                pos = new_pos + L
            elif wire == 0:  # Varint
                _, pos = PointCloudParser._decode_varint(data, new_pos)
            elif wire == 5:  # Fixed32
                pos = new_pos + 4
            elif wire == 1:  # Fixed64
                pos = new_pos + 8
            else:
                pos += 1  # è·³è¿‡æ— æ•ˆå­—èŠ‚ç»§ç»­æœç´¢
        
        # ç­–ç•¥2ï¼šä»æœ«å°¾æœç´¢æ‰¾ lidar_configs
        # field 12, wire type 2 çš„ tag æ˜¯ (12 << 3) | 2 = 98 = 0x62
        # lidar_configs é€šå¸¸åœ¨æ¶ˆæ¯æœ€å 200 å­—èŠ‚å†…
        search_start = max(0, len(data) - 500)  # ä»æœ«å°¾500å­—èŠ‚å¼€å§‹æœç´¢
        
        for i in range(search_start, len(data) - 10):
            if data[i] == 0x62:  # å¯èƒ½æ˜¯ field 12 tag
                try:
                    # éªŒè¯è¿™æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ field 12
                    length, next_pos = PointCloudParser._decode_varint(data, i + 1)
                    # lidar_configs é•¿åº¦é€šå¸¸åœ¨ 50-500 å­—èŠ‚
                    if 20 < length < 1000 and next_pos + length <= len(data):
                        chunk = data[next_pos:next_pos + length]
                        # å°è¯•è§£æä¸º lidar_configsï¼ˆåªä¿ç•™ä¸»lidaré…ç½®ï¼‰
                        parsed = PointCloudParser._parse_lidar_configs(chunk, main_lidar_frame_id)
                        # éªŒè¯è§£æç»“æœæ˜¯å¦æœ‰æ•ˆ
                        if parsed and (parsed.get('vehicle_to_sensing') is not None or parsed.get('configs')):
                            lidar_configs = parsed
                            break
                except:
                    continue
        
        return frame_id, lidar_configs
    
    @staticmethod
    def _parse_pointcloud2_wire(data: bytes):
        """æ‰‹åŠ¨è§£æ PointCloud2 protobuf wire format
        
        è¿”å›: (point_step, data_blob, fields_list)
          - point_step: æ¯ä¸ªç‚¹çš„å­—èŠ‚æ•°
          - data_blob: ç‚¹äº‘æ•°æ®
          - fields_list: [(name, offset, datatype), ...]
        """
        point_step = None
        data_blob = None
        fields_list = []
        pos = 0
        
        while pos < len(data):
            tag, pos = PointCloudParser._decode_varint(data, pos)
            if pos >= len(data):
                break
            field_num, wire = tag >> 3, tag & 7
            
            if wire == 0:  # Varint
                v, pos = PointCloudParser._decode_varint(data, pos)
                if field_num == 6:  # point_step
                    point_step = v
            elif wire == 2:  # Length-delimited
                L, pos = PointCloudParser._decode_varint(data, pos)
                if pos + L > len(data):
                    break
                chunk = data[pos:pos + L]
                pos += L
                
                if field_num == 4:  # fields (repeated PointField)
                    # è§£æ PointField æ¶ˆæ¯
                    i = 0
                    while i < len(chunk):
                        start_i = i
                        name, offset, datatype = None, 0, PointCloudParser._DT_FLOAT32
                        
                        # è§£æå•ä¸ª PointField
                        while i < len(chunk):
                            t, i = PointCloudParser._decode_varint(chunk, i)
                            if i >= len(chunk):
                                break
                            fn, w = t >> 3, t & 7
                            if w == 0:  # Varint
                                v, i = PointCloudParser._decode_varint(chunk, i)
                                if fn == 2:  # offset
                                    offset = v
                                elif fn == 3:  # datatype
                                    datatype = v
                            elif w == 2:  # Length-delimited (string)
                                ln, i = PointCloudParser._decode_varint(chunk, i)
                                if fn == 1 and i + ln <= len(chunk):  # name
                                    name = chunk[i:i + ln].decode('utf-8', errors='ignore').strip().lower()
                                i += ln
                            elif w == 5:  # Fixed32
                                if i + 4 > len(chunk):
                                    break
                                i += 4
                            elif w == 1:  # Fixed64
                                if i + 8 > len(chunk):
                                    break
                                i += 8
                            else:
                                break
                        
                        # ä¿å­˜æˆåŠŸè§£æçš„ PointField
                        if name and name in ('x', 'y', 'z'):
                            fields_list.append((name, offset, datatype))
                        
                        # é¿å…æ­»å¾ªç¯
                        if i == start_i:
                            i += 1
                elif field_num == 8:  # data (bytes)
                    data_blob = chunk
        
        # éªŒè¯è§£æç»“æœ
        if point_step and point_step > 0 and data_blob is not None and len(data_blob) >= point_step:
            return (point_step, data_blob, fields_list)
        return None
    
    @staticmethod
    def _datatype_to_fmt_scale(dt: int):
        """å°† DataType è½¬æ¢ä¸º struct format å’Œ scale"""
        if dt in (PointCloudParser._DT_INT16, PointCloudParser._DT_UINT16):
            return ('h' if dt == PointCloudParser._DT_INT16 else 'H', 0.01)
        if dt in (PointCloudParser._DT_INT32, PointCloudParser._DT_UINT32):
            return ('i' if dt == PointCloudParser._DT_INT32 else 'I', 1.0)
        if dt == PointCloudParser._DT_FLOAT32:
            return ('f', 1.0)
        if dt == PointCloudParser._DT_FLOAT64:
            return ('d', 1.0)
        return ('f', 1.0)
    
    @staticmethod
    def _read_xyz_from_fields(buf: bytes, offset: int, step: int, fields_map: dict):
        """ä» buffer ä¸­è¯»å– x, y, zï¼ˆå•ç‚¹ç‰ˆæœ¬ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰"""
        try:
            x_info = fields_map['x']
            y_info = fields_map['y']
            z_info = fields_map['z']
        except KeyError:
            return None
        
        need = max(x_info[0], y_info[0], z_info[0]) + 8
        if offset + need > len(buf):
            return None
        
        def _read_value(info):
            off, fmt, scale = info
            if fmt == 'h':
                return struct.unpack_from('<h', buf, offset + off)[0] * scale
            elif fmt == 'H':
                return struct.unpack_from('<H', buf, offset + off)[0] * scale
            elif fmt == 'i':
                return struct.unpack_from('<i', buf, offset + off)[0] * scale
            elif fmt == 'I':
                return struct.unpack_from('<I', buf, offset + off)[0] * scale
            elif fmt == 'f':
                return struct.unpack_from('<f', buf, offset + off)[0] * scale
            elif fmt == 'd':
                return struct.unpack_from('<d', buf, offset + off)[0] * scale
            return struct.unpack_from('<f', buf, offset + off)[0] * scale
        
        return (_read_value(x_info), _read_value(y_info), _read_value(z_info))
    
    @staticmethod
    def _parse_points_fast_numpy(raw: bytes, step: int, fields_map: dict, max_points: int = 500000) -> Optional[np.ndarray]:
        """ä½¿ç”¨NumPyå‘é‡åŒ–æ“ä½œå¿«é€Ÿè§£æç‚¹äº‘æ•°æ®
        
        âœ… æ€§èƒ½å…³é”®å‡½æ•°ï¼šä½¿ç”¨numpy structured arrayå’Œå‘é‡åŒ–æ“ä½œ
        æ¯”Pythonå¾ªç¯å¿«10-100å€
        """
        n = len(raw) // step
        if n < 50:
            return None
        
        n = min(n, max_points)
        data_len = n * step
        
        # è·å–å­—æ®µä¿¡æ¯
        try:
            x_off, x_fmt, x_scale = fields_map['x']
            y_off, y_fmt, y_scale = fields_map['y']
            z_off, z_fmt, z_scale = fields_map['z']
        except KeyError:
            return None
        
        # æ ¼å¼åˆ°numpy dtypeçš„æ˜ å°„
        fmt_to_dtype = {
            'h': np.int16,   # signed short (2 bytes)
            'H': np.uint16,  # unsigned short (2 bytes)
            'i': np.int32,   # signed int (4 bytes)
            'I': np.uint32,  # unsigned int (4 bytes)
            'f': np.float32, # float (4 bytes)
            'd': np.float64, # double (8 bytes)
        }
        
        dtype_sizes = {'h': 2, 'H': 2, 'i': 4, 'I': 4, 'f': 4, 'd': 8}
        
        try:
            # å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
            raw_array = np.frombuffer(raw[:data_len], dtype=np.uint8)
            
            # é‡å¡‘ä¸º (n, step) çš„2Dæ•°ç»„ï¼Œæ¯è¡Œä¸€ä¸ªç‚¹
            if len(raw_array) < n * step:
                return None
            points_raw = raw_array[:n * step].reshape(n, step)
            
            # æå–x, y, zï¼ˆä½¿ç”¨è§†å›¾é¿å…å¤åˆ¶ï¼‰
            x_dtype = fmt_to_dtype.get(x_fmt, np.float32)
            y_dtype = fmt_to_dtype.get(y_fmt, np.float32)
            z_dtype = fmt_to_dtype.get(z_fmt, np.float32)
            x_size = dtype_sizes.get(x_fmt, 4)
            y_size = dtype_sizes.get(y_fmt, 4)
            z_size = dtype_sizes.get(z_fmt, 4)
            
            # ä½¿ç”¨contiguous arrayæ¥æå–æ•°æ®ï¼ˆå…³é”®æ€§èƒ½ä¼˜åŒ–ï¼‰
            x_bytes = np.ascontiguousarray(points_raw[:, x_off:x_off+x_size])
            y_bytes = np.ascontiguousarray(points_raw[:, y_off:y_off+y_size])
            z_bytes = np.ascontiguousarray(points_raw[:, z_off:z_off+z_size])
            
            x_data = x_bytes.view(x_dtype).flatten().astype(np.float32) * x_scale
            y_data = y_bytes.view(y_dtype).flatten().astype(np.float32) * y_scale
            z_data = z_bytes.view(z_dtype).flatten().astype(np.float32) * z_scale
            
            # âœ… å…³é”®ä¿®å¤ï¼šå¯¹é½C++ PointXYZIBT/PointXYZIRT ç»“æ„ä½“
            # å‚è€ƒ /home/ludahai/codetree/repo/common/common/point.h:
            # struct PointXYZIBT {
            #   float x, y, z;           // 12 bytes (offset 0, 4, 8)
            #   uint8_t intensity;       // 1 byte (offset 12)
            #   uint8_t ring;            // 1 byte (offset 13)
            #   uint16_t timestamp;      // 2 bytes (offset 14) - å•ä½: 2us
            # };
            # typedef PointXYZIBT PointXYZIRT;
            # æ€»å…± 16 bytes
            
            # æå–intensity (offset 12, uint8)
            intensity_data = np.zeros(n, dtype=np.float32)
            if step >= 13:  # ç¡®ä¿æœ‰intensityå­—æ®µ
                intensity_data = points_raw[:, 12].astype(np.float32)
            elif step > 6:  # å…¼å®¹æ—§æ ¼å¼
                intensity_data = points_raw[:, 6].astype(np.float32)
            
            # æå–timestamp (offset 14-15, uint16, å•ä½: 2us)
            timestamp_data = np.zeros(n, dtype=np.float32)
            if step >= 16:  # PointXYZIBT/PointXYZIRTæ ¼å¼ (16 bytes)
                ts_bytes = np.ascontiguousarray(points_raw[:, 14:16])
                timestamp_data = ts_bytes.view(np.uint16).flatten().astype(np.float32)
            elif step >= 10:  # å…¼å®¹æ—§æ ¼å¼
                ts_bytes = np.ascontiguousarray(points_raw[:, 8:10])
                timestamp_data = ts_bytes.view(np.uint16).flatten().astype(np.float32)
            
            # è¿‡æ»¤æ— æ•ˆç‚¹ï¼ˆå‘é‡åŒ–æ“ä½œï¼‰
            valid_mask = (
                np.isfinite(x_data) & np.isfinite(y_data) & np.isfinite(z_data) &
                (np.abs(x_data) <= 500) & (np.abs(y_data) <= 500) & (np.abs(z_data) <= 100)
            )
            
            valid_count = valid_mask.sum()
            if valid_count < 50:
                return None
            
            # ç»„åˆç»“æœï¼ˆå‘é‡åŒ–ï¼‰
            points = np.column_stack([
                x_data[valid_mask],
                y_data[valid_mask],
                z_data[valid_mask],
                intensity_data[valid_mask],
                timestamp_data[valid_mask]
            ])
            
            return points.astype(np.float32)
            
        except Exception as e:
            return None
    
    @staticmethod
    def _decombine_pointcloud(points: np.ndarray, lidar_configs: dict, step: int, frame_id: str) -> np.ndarray:
        """Decombineç‚¹äº‘ï¼šå°†ç‚¹äº‘ä»Sensingç³»è½¬å›LiDARç³»ï¼ˆå¯¹é½C++ DecombineProtoPointCloudï¼‰
        
        å‚è€ƒ: modules/calib_utils/src/proto_instance.cpp:45-82
        
        C++é€»è¾‘ï¼ˆå¯¹é½å®ç°ï¼‰:
        1. å¦‚æœframe_id != "lidar_uncalibrated"ï¼Œè¯´æ˜ç‚¹äº‘å·²ç»è¢«combinedåˆ°Sensingç³»
        2. ä»lidar_configsæå–æ¯ä¸ªlidarçš„sensor_to_lidarå¤–å‚
           - sensor_to_lidarè¡¨ç¤º: LiDARåæ ‡ç³»åˆ°Sensingåæ ‡ç³»çš„å˜æ¢
           - C++: Eigen::Isometry3d (4x4å˜æ¢çŸ©é˜µ)
        3. è®¡ç®—é€†å˜æ¢: transform = sensor_to_lidar.inverse()
           - ä½œç”¨: å°†ç‚¹ä»Sensingç³»è½¬å›åŸå§‹LiDARç³»
        4. æŒ‰ringèŒƒå›´åˆ†å‰²ç‚¹äº‘ï¼ˆsplite_pointcloud_rawï¼‰ï¼Œå¯¹æ¯ä¸ªå­ç‚¹äº‘åˆ†åˆ«åº”ç”¨é€†å˜æ¢
        
        å…³é”®å¯¹é½ç‚¹:
        - C++: transform = extrinsics[j].inverse().matrix()
        - Python: T_sensing_to_lidar = np.linalg.inv(sensor_to_lidar)
        
        Args:
            points: (N, 5) ç‚¹äº‘ [x, y, z, intensity, timestamp] æˆ– (N, 6) [x, y, z, intensity, ring, timestamp]
            lidar_configs: è§£æåçš„lidar_configså­—å…¸ (åŒ…å«configsåˆ—è¡¨)
            step: æ¯ç‚¹çš„å­—èŠ‚æ•° (16è¡¨ç¤ºåŒ…å«ringå­—æ®µ)
            frame_id: åŸå§‹frame_id
        
        Returns:
            å˜æ¢åçš„ç‚¹äº‘ï¼ˆå·²è½¬æ¢åˆ°LiDARç³»ï¼Œframe_idå°†è®¾ä¸º"lidar_uncalibrated"ï¼‰
        """
        configs = lidar_configs.get('configs', [])
        
        if not configs:
            # æ²¡æœ‰configsï¼Œæ— æ³•decombine
            # æŒ‰C++é€»è¾‘: å¦‚æœæ²¡æœ‰lidar_configsï¼Œåº”è¯¥è¿”å›é”™è¯¯
            print(f"  âš ï¸  æ²¡æœ‰æ‰¾åˆ°lidar configsï¼Œæ— æ³•decombine")
            return points
        
        # åˆ¤æ–­ç‚¹äº‘æ˜¯å¦åŒ…å«ringä¿¡æ¯ï¼ˆstep=16è¡¨ç¤ºPointXYZIRTæ ¼å¼ï¼Œæœ‰ringå­—æ®µï¼‰
        has_ring = (step == 16 and points.shape[1] >= 6)
        
        if not has_ring:
            # æ²¡æœ‰ringä¿¡æ¯ï¼Œæ— æ³•æŒ‰lidaråˆ†å‰²ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªconfigçš„å˜æ¢åº”ç”¨åˆ°æ‰€æœ‰ç‚¹
            # æ³¨æ„ï¼šè¿™ä¸C++è¡Œä¸ºä¸å®Œå…¨ä¸€è‡´ï¼ŒC++è¦æ±‚æœ‰ringä¿¡æ¯
            if configs[0].get('sensor_to_lidar') is not None:
                # æŒ‰C++å‘½åçº¦å®šï¼ˆä»å³å¾€å·¦è¯»ï¼‰
                T_sensing_to_lidar = configs[0]['sensor_to_lidar']  # LiDARâ†’Sensing (ä»configè¯»å–ï¼Œä»å³å¾€å·¦è¯»)
                T_lidar_to_sensing = np.linalg.inv(T_sensing_to_lidar)  # Sensingâ†’LiDAR (é€†å˜æ¢ï¼Œä»å³å¾€å·¦è¯»)
                
                # åº”ç”¨å˜æ¢ï¼šå°†ç‚¹ä»Sensingç³»è½¬å›LiDARç³»
                # C++å¯¹é½: transformPointCloudXYZIRT(*source_cloud_raw, *source_cloud, transform)
                #          å…¶ä¸­ transform = extrinsics[j].inverse()
                xyz = points[:, :3]
                xyz_homo = np.hstack([xyz, np.ones((xyz.shape[0], 1))])
                xyz_transformed = (T_lidar_to_sensing @ xyz_homo.T).T[:, :3]
                
                points_out = points.copy()
                points_out[:, :3] = xyz_transformed
                
                # æ‰“å°decombineç»“æœ
                if not hasattr(PointCloudParser, '_decombine_logged'):
                    PointCloudParser._decombine_logged = True
                    print(f"  âœ“ å·²åº”ç”¨decombineå˜æ¢ (âš ï¸ æ— ringä¿¡æ¯ï¼Œåº”ç”¨config[0]åˆ°æ‰€æœ‰ç‚¹)")
                    print(f"    T_sensing_to_lidar (LiDARâ†’Sensing, ä»å³å¾€å·¦è¯») translation: [{T_sensing_to_lidar[0, 3]:.4f}, {T_sensing_to_lidar[1, 3]:.4f}, {T_sensing_to_lidar[2, 3]:.4f}]")
                    print(f"    T_lidar_to_sensing (Sensingâ†’LiDAR, ä»å³å¾€å·¦è¯») translation: [{T_lidar_to_sensing[0, 3]:.4f}, {T_lidar_to_sensing[1, 3]:.4f}, {T_lidar_to_sensing[2, 3]:.4f}]")
                    print(f"    å˜æ¢å‰ç‚¹äº‘èŒƒå›´: x=[{xyz[:, 0].min():.2f}, {xyz[:, 0].max():.2f}], y=[{xyz[:, 1].min():.2f}, {xyz[:, 1].max():.2f}]")
                    print(f"    å˜æ¢åç‚¹äº‘èŒƒå›´: x=[{xyz_transformed[:, 0].min():.2f}, {xyz_transformed[:, 0].max():.2f}], y=[{xyz_transformed[:, 1].min():.2f}, {xyz_transformed[:, 1].max():.2f}]")
                
                return points_out
            else:
                print(f"  âš ï¸  config[0]æ²¡æœ‰sensor_to_lidarï¼Œè·³è¿‡decombine")
                return points
        
        # æœ‰ringä¿¡æ¯ï¼ŒæŒ‰ringèŒƒå›´åˆ†å‰²ç‚¹äº‘ï¼ˆå¯¹é½C++ splite_pointcloud_rawé€»è¾‘ï¼‰
        ring_col = 4 if points.shape[1] == 6 else -1  # ringåœ¨ç¬¬5åˆ—ï¼ˆç´¢å¼•4ï¼‰
        
        if ring_col < 0 or points.shape[1] < 6:
            print(f"  âš ï¸  ç‚¹äº‘æ ¼å¼ä¸æ”¯æŒringåˆ†å‰² (shape={points.shape})ï¼Œè·³è¿‡decombine")
            return points
        
        rings = points[:, ring_col].astype(np.int32)
        points_out = points.copy()
        decombined_count = 0
        
        # æ‰“å°decombineè¯¦æƒ…ï¼ˆé¦–æ¬¡ï¼‰
        if not hasattr(PointCloudParser, '_decombine_logged'):
            PointCloudParser._decombine_logged = True
            print(f"  âœ“ æŒ‰ringèŒƒå›´åˆ†å‰²å¹¶åº”ç”¨decombineå˜æ¢")
            print(f"    ç‚¹äº‘åŒ…å«ringä¿¡æ¯ï¼Œå…±{len(configs)}ä¸ªlidar configs")
        
        for i, cfg in enumerate(configs):
            ring_start = cfg['ring_id_start']
            ring_end = cfg['ring_id_end']
            sensor_to_lidar = cfg.get('sensor_to_lidar')
            
            if sensor_to_lidar is None:
                print(f"    âš ï¸  config[{i}] æ²¡æœ‰sensor_to_lidarï¼Œè·³è¿‡")
                continue
            
            # æ‰¾åˆ°å±äºè¿™ä¸ªlidarçš„ç‚¹ï¼ˆC++: splite_pointcloud_rawï¼‰
            # C++: if (ring >= ring_start && ring < ring_end)  // å·¦é—­å³å¼€åŒºé—´ [ring_start, ring_end)
            mask = (rings >= ring_start) & (rings < ring_end)
            num_points_in_range = np.sum(mask)
            
            if num_points_in_range == 0:
                continue
            
            # è®¡ç®—é€†å˜æ¢ï¼ˆC++å¯¹é½: transform = extrinsics[j].inverse()ï¼‰
            # æŒ‰C++å‘½åçº¦å®šï¼ˆä»å³å¾€å·¦è¯»ï¼‰ï¼š
            T_sensing_to_lidar = sensor_to_lidar  # LiDARâ†’Sensingï¼ˆä»å³å¾€å·¦è¯»ï¼‰
            T_lidar_to_sensing = np.linalg.inv(T_sensing_to_lidar)  # Sensingâ†’LiDARï¼ˆä»å³å¾€å·¦è¯»ï¼‰
            
            # åº”ç”¨å˜æ¢ï¼ˆC++å¯¹é½: transformPointCloudXYZIRTï¼‰
            # å°†ç‚¹ä»Sensingç³»è½¬å›LiDARç³»
            xyz = points[mask, :3]
            xyz_homo = np.hstack([xyz, np.ones((xyz.shape[0], 1))])
            xyz_transformed = (T_lidar_to_sensing @ xyz_homo.T).T[:, :3]
            
            points_out[mask, :3] = xyz_transformed
            decombined_count += num_points_in_range
            
            # æ‰“å°æ¯ä¸ªlidarçš„å˜æ¢è¯¦æƒ…ï¼ˆé¦–æ¬¡ï¼‰
            if not PointCloudParser._lidar_configs_logged:
                cfg_frame_id = cfg.get('frame_id', 'unknown')
                print(f"    config[{i}]: frame_id='{cfg_frame_id}', ring=[{ring_start}, {ring_end}) (å·¦é—­å³å¼€), points={num_points_in_range}")
                print(f"      T_sensing_to_lidar (LiDARâ†’Sensing, ä»å³å¾€å·¦è¯») translation: [{T_sensing_to_lidar[0, 3]:.4f}, {T_sensing_to_lidar[1, 3]:.4f}, {T_sensing_to_lidar[2, 3]:.4f}]")
                print(f"      T_lidar_to_sensing (Sensingâ†’LiDAR, ä»å³å¾€å·¦è¯») translation: [{T_lidar_to_sensing[0, 3]:.4f}, {T_lidar_to_sensing[1, 3]:.4f}, {T_lidar_to_sensing[2, 3]:.4f}]")
        
        if not PointCloudParser._lidar_configs_logged:
            print(f"    æ€»è®¡å˜æ¢ç‚¹æ•°: {decombined_count}/{len(points)} ({100*decombined_count/len(points):.1f}%)")
        
        return points_out
    
    @staticmethod
    def parse_proto_pointcloud2(data: bytes, apply_decombine: bool = False, main_lidar_frame_id: str = "atx_202",
                                config_for_comparison: Optional[dict] = None) -> Optional[np.ndarray]:
        """è§£æ PointCloud2 proto æ•°æ®
        
        å‚è€ƒ: ~/develop/code/github/Self-Cali-GS/surround_calibration/data/lidar_utils.py
        
        âœ… æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨NumPyå‘é‡åŒ–æ“ä½œæ›¿ä»£Pythonå¾ªç¯ï¼Œå¤§å¹…æå‡è§£æé€Ÿåº¦
        âœ… æ–°å¢ï¼šæ”¯æŒlidar_configsè§£æï¼ˆå¯¹é½C++ DecombineProtoPointCloudï¼‰
        
        Args:
            data: protobufæ¶ˆæ¯bytesæ•°æ®
            apply_decombine: æ˜¯å¦åº”ç”¨decombineå¤„ç†ï¼ˆå¦‚æœç‚¹äº‘åœ¨Sensingç³»ï¼Œè½¬å›LiDARç³»ï¼‰
                           âš ï¸ é»˜è®¤Falseï¼šæœ¬è„šæœ¬ä¸­ç‚¹äº‘éœ€è¦ä¿æŒåœ¨Sensingç³»ç”¨äºåç»­å»ç•¸å˜
                           âœ… ä»…åœ¨éœ€è¦åŸå§‹LiDARç³»ç‚¹äº‘æ—¶è®¾ç½®ä¸ºTrue
            main_lidar_frame_id: ä¸»lidarçš„frame_idï¼Œåªä¿ç•™è¯¥lidarçš„é…ç½®ï¼ˆé»˜è®¤"atx_202"ï¼‰
                               âš ï¸ å¦‚æœå­˜åœ¨å¤šä¸ªlidarï¼Œåªæå–å’Œä½¿ç”¨ä¸»lidarçš„å¤–å‚
                               âœ… è®¾ç½®ä¸ºNoneåˆ™ä¿ç•™æ‰€æœ‰lidaré…ç½®
            config_for_comparison: ä»lidars.cfgè¯»å–çš„é…ç½®ï¼Œç”¨äºä¸bagæå–çš„é…ç½®è¿›è¡Œå¯¹æ¯”
        
        æ³¨æ„ï¼š
            - æœ¬è„šæœ¬å·¥ä½œæµç¨‹ï¼šbagæå–(Sensingç³») â†’ å»ç•¸å˜(Sensingç³») â†’ ä¿å­˜(Sensingç³»)
            - å»ç•¸å˜å‡è®¾ç‚¹äº‘åœ¨Sensingç³»ï¼Œå› æ­¤æå–æ—¶ä¸åº”åšdecombineå˜æ¢
            - å‚è€ƒä»£ç 3222è¡Œæ³¨é‡Šï¼š"ç‚¹äº‘å»ç•¸å˜ååœ¨ Sensing åæ ‡ç³»"
        """
        if data is None or len(data) < 16:
            return None
        
        # âœ… æ–°å¢ï¼šæå–frame_idå’Œlidar_configsï¼ˆå¯¹é½C++ï¼‰
        frame_id = None
        lidar_configs = None
        
        # å°è¯•å¤šä¸ªå€™é€‰ä½ç½®ï¼ˆå¯èƒ½æœ‰ä¸åŒçš„å‰ç¼€ï¼‰
        candidates = [data]
        if len(data) > 4:
            candidates.append(data[4:])
        if len(data) > 8:
            candidates.append(data[8:])
        
        # ä½¿ç”¨ wire format è§£æ
        for to_parse in candidates:
            result = PointCloudParser._parse_pointcloud2_wire(to_parse)
            if result is None:
                continue
            
            step, raw, flist = result
            if not step or step <= 0:
                continue
            
            n = len(raw) // step
            if n < 50:
                continue
            
            # âœ… æ–°å¢ï¼šåœ¨æ‰¾åˆ°æœ‰æ•ˆç‚¹äº‘æ•°æ®åï¼Œæå–frame_idå’Œlidar_configsï¼ˆåªä¿ç•™ä¸»lidaré…ç½®ï¼‰
            if frame_id is None:
                frame_id, lidar_configs = PointCloudParser._extract_frame_id_and_lidar_configs(to_parse, main_lidar_frame_id)
            
            # æ„å»º fields_map
            fields_map = {}
            for name, off, dt in flist:
                fmt, scale = PointCloudParser._datatype_to_fmt_scale(dt)
                fields_map[name] = (off, fmt, scale)
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„ x, y, zï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„ï¼ˆINT16ï¼‰
            if len(fields_map) != 3:
                fields_map = {'x': (0, 'h', 0.01), 'y': (2, 'h', 0.01), 'z': (4, 'h', 0.01)}
            
            # âœ… ä½¿ç”¨å‘é‡åŒ–å¿«é€Ÿè§£æï¼ˆæ€§èƒ½å…³é”®ä¼˜åŒ–ï¼‰
            points = PointCloudParser._parse_points_fast_numpy(raw, step, fields_map)
            if points is not None and len(points) >= 50:
                # é¦–æ¬¡è§£ææ—¶æ‰“å°ç‚¹äº‘æ ¼å¼è¯Šæ–­ä¿¡æ¯
                if not hasattr(PointCloudParser, '_format_logged'):
                    PointCloudParser._format_logged = True
                    print(f"\nğŸ“Š ç‚¹äº‘æ ¼å¼è¯Šæ–­:")
                    print(f"  point_step: {step} bytes")
                    print(f"  fields_map: {fields_map}")
                    print(f"  point_count: {len(points)}")
                    if step == 16:
                        print(f"  âœ… åŒ¹é… C++ PointXYZIBT/PointXYZIRT æ ¼å¼ (16 bytes)")
                        print(f"     structure: x(0-3), y(4-7), z(8-11), intensity(12), ring(13), timestamp(14-15)")
                    elif step == 10:
                        print(f"  âš ï¸  æ—§æ ¼å¼ç‚¹äº‘ (10 bytes)ï¼Œtimestampä½ç½®å¯èƒ½ä¸åŒ")
                    else:
                        print(f"  âš ï¸  éæ ‡å‡†ç‚¹äº‘æ ¼å¼ ({step} bytes)")
                    
                    # æ‰“å°å‰å‡ ä¸ªç‚¹çš„timestampå€¼ç”¨äºéªŒè¯
                    if points.shape[1] >= 5:
                        ts_sample = points[:5, 4]
                        print(f"  timestampæ ·æœ¬(å‰5ç‚¹): {ts_sample}")
                        print(f"  timestampèŒƒå›´: [{points[:, 4].min():.0f}, {points[:, 4].max():.0f}] (å•ä½: 2us)")
                        print(f"  æ‰«ææ—¶é•¿çº¦: {points[:, 4].max() * 2 / 1000:.1f} ms")
                
                # âœ… æ–°å¢ï¼šæ‰“å°frame_idå’Œlidar_configsä¿¡æ¯ï¼ˆå¯¹é½C++æ—¥å¿—ï¼‰
                if not PointCloudParser._lidar_configs_logged:
                    PointCloudParser._lidar_configs_logged = True
                    print(f"\n=== PYTHON_CPP_COMPARE: PointCloud lidar_configs ===")
                    print(f"  frame_id: {frame_id}")
                    print(f"  has_lidar_configs: {'YES' if lidar_configs else 'NO'}")
                    
                    if lidar_configs:
                        # æ‰“å°ä»bagæå–çš„vehicle_to_sensing
                        v2s_bag = lidar_configs.get('vehicle_to_sensing')
                        if v2s_bag is not None:
                            print(f"\n  ã€ä»BAGæå–ã€‘vehicle_to_sensing (Sensing->Vehicle):")
                            print(f"    position: [{v2s_bag[0, 3]:.6f}, {v2s_bag[1, 3]:.6f}, {v2s_bag[2, 3]:.6f}]")
                            print(f"    rotation (3x3):")
                            for row_idx in range(3):
                                print(f"      [{v2s_bag[row_idx, 0]:9.6f}, {v2s_bag[row_idx, 1]:9.6f}, {v2s_bag[row_idx, 2]:9.6f}]")
                        
                        # æ‰“å°ä»bagæå–çš„sensor_to_lidar
                        configs = lidar_configs.get('configs', [])
                        print(f"\n  config_size: {len(configs)} (filtered: only main_lidar_frame_id='{main_lidar_frame_id}')")
                        for i, cfg in enumerate(configs):
                            s2l_bag = cfg.get('sensor_to_lidar')
                            cfg_frame_id = cfg.get('frame_id', 'unknown')
                            print(f"\n    ã€ä»BAGæå–ã€‘config[{i}]: frame_id='{cfg_frame_id}', ring=[{cfg['ring_id_start']}, {cfg['ring_id_end']})")
                            if s2l_bag is not None:
                                print(f"      sensor_to_lidar (LiDAR->Sensing) translation: [{s2l_bag[0, 3]:.6f}, {s2l_bag[1, 3]:.6f}, {s2l_bag[2, 3]:.6f}]")
                                print(f"      sensor_to_lidar rotation (3x3):")
                                for row_idx in range(3):
                                    print(f"        [{s2l_bag[row_idx, 0]:9.6f}, {s2l_bag[row_idx, 1]:9.6f}, {s2l_bag[row_idx, 2]:9.6f}]")
                        
                        # å¦‚æœæä¾›äº†lidars.cfgé…ç½®ï¼Œè¿›è¡Œå¯¹æ¯”
                        if config_for_comparison is not None:
                            print(f"\n=== å¯¹æ¯” lidars.cfg é…ç½® ===")
                            
                            # å¯¹æ¯”vehicle_to_sensing
                            if 'vehicle_to_sensing' in config_for_comparison:
                                v2s_cfg = config_for_comparison['vehicle_to_sensing']
                                if 'position' in v2s_cfg and 'orientation' in v2s_cfg:
                                    from scipy.spatial.transform import Rotation as R
                                    pos_cfg = np.array(v2s_cfg['position'])
                                    ori_cfg = np.array(v2s_cfg['orientation'])  # [qx, qy, qz, qw]
                                    T_cfg = np.eye(4)
                                    T_cfg[:3, :3] = R.from_quat(ori_cfg).as_matrix()
                                    T_cfg[:3, 3] = pos_cfg
                                    
                                    print(f"\n  ã€ä»LIDARS.CFGã€‘vehicle_to_sensing (Sensing->Vehicle):")
                                    print(f"    position: [{T_cfg[0, 3]:.6f}, {T_cfg[1, 3]:.6f}, {T_cfg[2, 3]:.6f}]")
                                    print(f"    rotation (3x3):")
                                    for row_idx in range(3):
                                        print(f"      [{T_cfg[row_idx, 0]:9.6f}, {T_cfg[row_idx, 1]:9.6f}, {T_cfg[row_idx, 2]:9.6f}]")
                                    
                                    # è®¡ç®—å·®å¼‚
                                    if v2s_bag is not None:
                                        pos_diff = np.linalg.norm(T_cfg[:3, 3] - v2s_bag[:3, 3])
                                        rot_diff = np.linalg.norm(T_cfg[:3, :3] - v2s_bag[:3, :3], 'fro')
                                        print(f"\n  ã€GAPã€‘vehicle_to_sensing:")
                                        print(f"    ä½ç½®å·®å¼‚ (L2 norm): {pos_diff:.6f} m")
                                        print(f"    æ—‹è½¬å·®å¼‚ (Frobenius norm): {rot_diff:.6f}")
                                        print(f"    ä½ç½®åˆ†é‡å·®å¼‚: [{T_cfg[0,3]-v2s_bag[0,3]:.6f}, {T_cfg[1,3]-v2s_bag[1,3]:.6f}, {T_cfg[2,3]-v2s_bag[2,3]:.6f}]")
                            
                            # å¯¹æ¯”sensor_to_lidar
                            if 'position' in config_for_comparison and 'orientation' in config_for_comparison:
                                from scipy.spatial.transform import Rotation as R
                                pos_cfg = np.array(config_for_comparison['position'])
                                ori_cfg = np.array(config_for_comparison['orientation'])  # [qx, qy, qz, qw]
                                T_s2l_cfg = np.eye(4)
                                T_s2l_cfg[:3, :3] = R.from_quat(ori_cfg).as_matrix()
                                T_s2l_cfg[:3, 3] = pos_cfg
                                
                                print(f"\n  ã€ä»LIDARS.CFGã€‘sensor_to_lidar (LiDAR->Sensing):")
                                print(f"    position: [{T_s2l_cfg[0, 3]:.6f}, {T_s2l_cfg[1, 3]:.6f}, {T_s2l_cfg[2, 3]:.6f}]")
                                print(f"    rotation (3x3):")
                                for row_idx in range(3):
                                    print(f"      [{T_s2l_cfg[row_idx, 0]:9.6f}, {T_s2l_cfg[row_idx, 1]:9.6f}, {T_s2l_cfg[row_idx, 2]:9.6f}]")
                                
                                # è®¡ç®—å·®å¼‚
                                if configs and s2l_bag is not None:
                                    pos_diff = np.linalg.norm(T_s2l_cfg[:3, 3] - s2l_bag[:3, 3])
                                    rot_diff = np.linalg.norm(T_s2l_cfg[:3, :3] - s2l_bag[:3, :3], 'fro')
                                    print(f"\n  ã€GAPã€‘sensor_to_lidar:")
                                    print(f"    ä½ç½®å·®å¼‚ (L2 norm): {pos_diff:.6f} m")
                                    print(f"    æ—‹è½¬å·®å¼‚ (Frobenius norm): {rot_diff:.6f}")
                                    print(f"    ä½ç½®åˆ†é‡å·®å¼‚: [{T_s2l_cfg[0,3]-s2l_bag[0,3]:.6f}, {T_s2l_cfg[1,3]-s2l_bag[1,3]:.6f}, {T_s2l_cfg[2,3]-s2l_bag[2,3]:.6f}]")
                
                # âœ… æ–°å¢ï¼šDecombineå¤„ç†ï¼ˆå¯¹é½C++ DecombineProtoPointCloudï¼‰
                if apply_decombine and frame_id and frame_id != 'lidar_uncalibrated' and lidar_configs:
                    points = PointCloudParser._decombine_pointcloud(points, lidar_configs, step, frame_id)
                
                return points
        
        # Fallback: å°è¯•ç›´æ¥æŒ‰floatæ ¼å¼è¯»å–ï¼ˆå¦‚æœwire formatå¤±è´¥ï¼‰
        # å‚è€ƒSelf-Cali-GS: å°è¯•ä¸åŒçš„èµ·å§‹åç§»é‡
        for offset_start in [0, 20, 40, 60, 80, 100, 150, 200, 300, 400, 500]:
            if len(data) < offset_start + 16:
                continue
            rem = len(data) - offset_start
            if rem < 16 or rem % 16 != 0:
                continue
            n = rem // 16
            pts, ok = [], 0
            for i in range(min(2000, n)):
                o = offset_start + i * 16
                try:
                    x, y, z, _ = struct.unpack_from('ffff', data, o)
                    if not (np.isnan(x) or np.isnan(y) or np.isnan(z)) and abs(x) < 5000 and abs(y) < 5000 and abs(z) < 500:
                        pts.append([x, y, z, 0.0, 0.0])  # æ·»åŠ dummy intensityå’Œtimestamp
                        ok += 1
                except Exception:
                    continue
            if ok > 50:
                # å¦‚æœæ‰¾åˆ°è¶³å¤Ÿçš„æœ‰æ•ˆç‚¹ï¼Œå¤„ç†å‰©ä½™çš„ç‚¹
                for i in range(min(2000, n), n):
                    o = offset_start + i * 16
                    try:
                        x, y, z, _ = struct.unpack_from('ffff', data, o)
                        if not (np.isnan(x) or np.isnan(y) or np.isnan(z)) and abs(x) < 5000 and abs(y) < 5000 and abs(z) < 500:
                            pts.append([x, y, z, 0.0, 0.0])
                    except Exception:
                        continue
                return np.array(pts, dtype=np.float32) if pts else None
        
        return None


class BEVCalibDatasetPreparer:
    """BEVCalib æ•°æ®é›†å‡†å¤‡å™¨ï¼ˆæµå¼å¤„ç†ç‰ˆæœ¬ï¼‰"""
    
    # å®šä½ topics (æŒ‰ç…§ç”¨æˆ·è¦æ±‚ï¼Œåªä½¿ç”¨/localization/pose)
    LOCALIZATION_TOPICS = [
        '/localization/pose',  # ä¼˜å…ˆä½¿ç”¨è¿™ä¸ªtopicï¼Œä¸C++å‚è€ƒä»£ç ä¸€è‡´
        # '/localiztaion/gnss/calibration_pose',  # æ³¨æ„æ‹¼å†™é”™è¯¯æ˜¯åŸå§‹æ•°æ®ä¸­çš„
        # '/sensors/gnss/pose'
    ]
    
    def __init__(
        self,
        bag_path: str,
        config_dir: str,
        output_dir: str,
        camera_name: str = "traffic_2",
        target_fps: float = 10.0,
        max_time_diff: float = 0.055,  # 55msï¼Œå‚è€ƒC++: kMaxLidarCameraDelta = 55000us
        lidar_topic: str = '/sensors/lidar/combined_point_cloud_proto',
        pose_topic: str = None,  # æ”¹ä¸ºå¯é€‰ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨æ£€æµ‹
        batch_size: int = 500,  # æ¯æ‰¹å¤„ç†çš„å¸§æ•°ï¼ˆå¢åŠ é»˜è®¤å€¼ä»¥æå‡é€Ÿåº¦ï¼‰
        num_workers: int = 4,  # å¹¶è¡Œå¤„ç†çš„å·¥ä½œçº¿ç¨‹æ•°
        max_frames: int = None,  # æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        save_debug_samples: int = 0,  # ä¿å­˜è°ƒè¯•æ ·æœ¬æ•°é‡ï¼ˆæœªå»ç•¸å˜ç‚¹äº‘ï¼‰
        max_pose_gap: float = 0.5,  # æœ€å¤§å…è®¸çš„poseé—´éš”ï¼ˆç§’ï¼‰ï¼Œç”¨äºå¤„ç†ä¸è¿ç»­bagæ•°æ®
    ):
        self.bag_path = Path(bag_path)
        self.config_dir = Path(config_dir)
        self.output_dir = Path(output_dir)
        self.camera_name = camera_name
        self.target_fps = target_fps
        self.max_time_diff = max_time_diff
        self.lidar_topic = lidar_topic
        self.pose_topic = pose_topic  # å¦‚æœä¸ºNoneï¼Œåˆ™è‡ªåŠ¨æ£€æµ‹
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.max_frames = max_frames  # æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        self.save_debug_samples = save_debug_samples  # ä¿å­˜è°ƒè¯•æ ·æœ¬æ•°é‡
        self.max_pose_gap = max_pose_gap  # æœ€å¤§å…è®¸çš„poseé—´éš”
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.temp_dir = self.output_dir / 'temp'
        self.temp_dir.mkdir(exist_ok=True)
        self.temp_image_dir = self.temp_dir / 'images'
        self.temp_pc_dir = self.temp_dir / 'pointclouds'
        self.temp_image_dir.mkdir(exist_ok=True)
        self.temp_pc_dir.mkdir(exist_ok=True)
        
        # å…ƒæ•°æ®åˆ—è¡¨ï¼ˆä¸å­˜å‚¨å®é™…æ•°æ®ï¼‰
        self.image_metadata: List[ImageMetadata] = []
        self.pc_metadata: List[PointCloudMetadata] = []
        self.pose_metadata: List[PoseMetadata] = []
        
        # ä»bagä¸­æå–çš„ Sensingâ†’Vehicle å˜æ¢ï¼ˆä¼˜å…ˆçº§é«˜äºæœ¬åœ°é…ç½®ï¼‰
        # C++å‘½åï¼šT_vehicle_to_sensingï¼ˆä»å³å¾€å·¦è¯»ï¼šSensingâ†’Vehicleï¼‰
        # æ³¨æ„ï¼šå¿…é¡»åœ¨_compute_transforms()ä¹‹å‰åˆå§‹åŒ–
        self.vehicle_to_sensing_from_bag: Optional[np.ndarray] = None
        
        # è®¡æ•°å™¨
        self.image_counter = 0
        self.pc_counter = 0
        
        # è°ƒè¯•é€‰é¡¹
        self.verbose = True
        
        # åŠ è½½é…ç½®å¹¶è®¡ç®—å˜æ¢çŸ©é˜µ
        self._load_configs()
        self._compute_transforms()
    
    def _load_configs(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        cameras_cfg = self.config_dir / 'cameras.cfg'
        lidars_cfg = self.config_dir / 'lidars.cfg'
        
        if not cameras_cfg.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ° cameras.cfg: {cameras_cfg}")
        if not lidars_cfg.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ° lidars.cfg: {lidars_cfg}")
        
        cameras = ConfigParser.parse_cameras_cfg(str(cameras_cfg))
        if self.camera_name not in cameras:
            raise ValueError(f"æœªæ‰¾åˆ°ç›¸æœº {self.camera_name}ï¼Œå¯ç”¨: {list(cameras.keys())}")
        
        self.camera_config = cameras[self.camera_name]
        self.lidar_config = ConfigParser.parse_lidars_cfg(str(lidars_cfg))
        
        print(f"å·²åŠ è½½é…ç½®:")
        print(f"  ç›¸æœº: {self.camera_name}")
        print(f"  å›¾åƒå°ºå¯¸: {self.camera_config['intrinsic']['img_width']}x{self.camera_config['intrinsic']['img_height']}")
        print(f"  å†…å‚ fx={self.camera_config['intrinsic']['f_x']:.2f}, fy={self.camera_config['intrinsic']['f_y']:.2f}")
    
    def _extract_vehicle_to_sensing_from_pc_msg(self, data: bytes) -> Optional[np.ndarray]:
        """ä»ç‚¹äº‘protobufæ¶ˆæ¯ä¸­æå– vehicle_to_sensing (Sensingâ†’Vehicle) å˜æ¢
        
        **å‘½åçº¦å®š**: vehicle_to_sensing = Sensingâ†’Vehicle
        
        å‚è€ƒï¼šlidar_online_calibrator.cpp:1038-1054 + proto_utils.cpp:569-588
        
        Returns:
            T_sensing_to_vehicle: Sensingâ†’Vehicleçš„4x4å˜æ¢çŸ©é˜µï¼Œå¦‚æœæå–å¤±è´¥è¿”å›None
        """
        try:
            # æ‰‹åŠ¨è§£æprotobuf wire formatä»¥æŸ¥æ‰¾lidar_configså­—æ®µ
            # å¯»æ‰¾vehicle_to_sensingçš„positionå’Œorientation
            
            # å°è¯•ä½¿ç”¨protobufååºåˆ—åŒ–ï¼ˆå¦‚æœæ¶ˆæ¯åŒ…å«lidar_configsï¼‰
            # æ³¨æ„ï¼šæˆ‘ä»¬ä¸éœ€è¦å®Œæ•´çš„protoå®šä¹‰ï¼Œåªéœ€è¦æå–ç‰¹å®šå­—æ®µ
            
            # ç®€åŒ–æ–¹æ¡ˆï¼šå°è¯•æœç´¢ç‰¹å®šçš„å­—èŠ‚æ¨¡å¼
            # vehicle_to_sensingåŒ…å«: position(x,y,z) + orientation(qw,qx,qy,qz)
            
            # æš‚æ—¶è¿”å›Noneï¼Œä½¿ç”¨fallbacké€»è¾‘
            return None
            
        except Exception as e:
            return None
    
    def _get_vehicle_to_sensing_transform(self) -> np.ndarray:
        """è·å– Sensingâ†’Vehicle çš„å˜æ¢
        
        å‚è€ƒï¼šproto_utils.cpp:569-588
        
        **C++å‘½åçº¦å®š**ï¼ˆä»å³å¾€å·¦è¯»ï¼‰ï¼š
        - vehicle_to_sensing = Sensingâ†’Vehicle (Sensingåœ¨Vehicleç³»ä¸­çš„ä½å§¿)
        - T_vehicle_to_sensingè¡¨ç¤ºå°†Vehicleç³»å˜æ¢åˆ°Sensingç³» = Sensingâ†’Vehicle
        
        ä¼˜å…ˆçº§ï¼š
        1. ä»bagä¸­çš„ç‚¹äº‘æ¶ˆæ¯æå–ï¼ˆself.vehicle_to_sensing_from_bagï¼‰
        2. ä»æœ¬åœ°lidars.cfgçš„vehicle_to_sensingå­—æ®µè¯»å–
        3. é»˜è®¤å•ä½çŸ©é˜µï¼ˆVehicle == Sensingï¼‰
        
        Returns:
            T_vehicle_to_sensing: Sensingâ†’Vehicleçš„4x4å˜æ¢çŸ©é˜µï¼ˆä»å³å¾€å·¦è¯»ï¼‰
        """
        # ä¼˜å…ˆä½¿ç”¨ä»bagä¸­æå–çš„é…ç½®
        if self.vehicle_to_sensing_from_bag is not None:
            return self.vehicle_to_sensing_from_bag
        
        # å°è¯•ä»æœ¬åœ°lidars.cfgè¯»å–vehicle_to_sensing = Sensingâ†’Vehicle
        # æŒ‰C++è§„èŒƒå‘½åï¼šT_vehicle_to_sensingï¼ˆä»å³å¾€å·¦è¯»ï¼šSensingâ†’Vehicleï¼‰
        T_vehicle_to_sensing = np.eye(4)
        
        # æ£€æŸ¥lidar_configæ˜¯å¦åŒ…å«vehicle_to_sensing
        if isinstance(self.lidar_config, dict) and 'vehicle_to_sensing' in self.lidar_config:
            v2s = self.lidar_config['vehicle_to_sensing']
            if 'position' in v2s and 'orientation' in v2s:
                pos = v2s['position']
                ori = v2s['orientation']  # [qx, qy, qz, qw]
                
                # æ„å»ºå˜æ¢çŸ©é˜µï¼šSensingâ†’Vehicle
                r = R.from_quat(ori)
                T_vehicle_to_sensing[:3, :3] = r.as_matrix()
                T_vehicle_to_sensing[:3, 3] = pos
                
                print(f"âœ“ ä»lidars.cfgè¯»å– vehicle_to_sensing")
                print(f"  (C++å‘½å: T_vehicle_to_sensing = Sensingâ†’Vehicle)")
                print(f"  position: {pos}")
                print(f"  orientation: {ori}")
                return T_vehicle_to_sensing
        
        # é»˜è®¤ï¼šVehicle == Sensingï¼ˆå•ä½çŸ©é˜µï¼‰
        print(f"â„¹ï¸  ä½¿ç”¨é»˜è®¤å‡è®¾: Vehicle == Sensing (å•ä½çŸ©é˜µ)")
        return T_vehicle_to_sensing
    
    def _convert_poses_to_sensing_frame(self):
        """å°†Vehicleç³»çš„poseè½¬æ¢ä¸ºSensingç³»ï¼ˆå¯¹é½C++å®ç°ï¼‰
        
        C++å‚è€ƒï¼šlidar_online_calibrator.cpp:849-852
            sensing_pose.second = vehicle_pose * iso_vehicle_sensing_;
            lidar_pose_data_.push_back(sensing_pose);
        
        å˜æ¢ç†è§£ï¼š
        - è¾“å…¥ï¼švehicle_pose = Vehicleâ†’Worldï¼ˆVehicleåœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
        - ä¸­é—´ï¼šT_vehicle_to_sensing = Sensingâ†’Vehicleï¼ˆä»configè¯»å–ï¼‰
        - è¾“å‡ºï¼šsensing_pose = (Vehicleâ†’World) @ (Sensingâ†’Vehicle) = Sensingâ†’World
        
        å«ä¹‰ï¼šSensingåœ¨Worldç³»ä¸­çš„ä½å§¿
        
        âš ï¸ C++ä¸­æ—¶é—´æˆ³å•ä½ï¼š
        - C++: poseæ—¶é—´æˆ³æ˜¯å¾®ç§’(int64_t)ï¼Œmeasurement_time()è¿”å›å¾®ç§’
        - Python: è¿™é‡Œå·²ç»è½¬æ¢ä¸ºç§’
        """
        print(f"\n  è½¬æ¢ä½å§¿åˆ°Sensingåæ ‡ç³»...")
        print(f"  === ä½å§¿åæ ‡ç³»è½¬æ¢ (å¯¹é½C++) ===")
        print(f"  T_vehicle_to_sensing (Sensingâ†’Vehicle):")
        print(f"    æ—‹è½¬:\n{self.T_vehicle_to_sensing[:3, :3]}")
        print(f"    å¹³ç§»: {self.T_vehicle_to_sensing[:3, 3]}")
        
        # æ‰“å°è½¬æ¢å‰çš„ç¬¬ä¸€ä¸ªposeï¼ˆä¾¿äºä¸C++å¯¹æ¯”ï¼‰
        if self.pose_metadata:
            pose0 = self.pose_metadata[0]
            print(f"  è½¬æ¢å‰(Vehicleç³»)ç¬¬ä¸€ä¸ªpose:")
            print(f"    timestamp(s): {pose0.timestamp:.6f}")
            print(f"    timestamp(us): {int(pose0.timestamp * 1e6)}")  # ä¾¿äºä¸C++å¯¹æ¯”
            print(f"    position: {pose0.position}")
            print(f"    orientation(quat): {pose0.orientation}")
        
        for i, pose in enumerate(self.pose_metadata):
            # æ„å»ºVehicleç³»çš„poseï¼ˆVehicleâ†’Worldï¼‰
            R_vehicle = UndistortionUtils.quat_to_matrix(pose.orientation)
            t_vehicle = pose.position
            
            iso_vehicle = np.eye(4)
            iso_vehicle[:3, :3] = R_vehicle
            iso_vehicle[:3, 3] = t_vehicle
            
            # è½¬æ¢åˆ°Sensingç³»ï¼šsensing_pose = vehicle_pose * T_vehicle_to_sensing
            # å…¶ä¸­T_vehicle_to_sensing = Sensingâ†’Vehicleï¼ˆC++å‘½åçº¦å®šï¼‰
            iso_sensing = iso_vehicle @ self.T_vehicle_to_sensing
            
            # æ›´æ–°poseï¼ˆç°åœ¨æ˜¯Sensingç³»ï¼‰
            R_sensing = iso_sensing[:3, :3]
            t_sensing = iso_sensing[:3, 3]
            
            # è½¬æ¢å›å››å…ƒæ•°
            r = R.from_matrix(R_sensing)
            pose.orientation = r.as_quat()  # [x, y, z, w]
            pose.position = t_sensing
        
        # æ‰“å°è½¬æ¢åçš„ç¬¬ä¸€ä¸ªpose
        if self.pose_metadata:
            pose0 = self.pose_metadata[0]
            print(f"  è½¬æ¢å(Sensingç³»)ç¬¬ä¸€ä¸ªpose:")
            print(f"    position: {pose0.position}")
            print(f"    orientation(quat): {pose0.orientation}")
        
        print(f"  âœ“ å·²è½¬æ¢ {len(self.pose_metadata)} ä¸ªä½å§¿åˆ°Sensingç³»")
    
    def _compute_transforms(self):
        """è®¡ç®—å˜æ¢çŸ©é˜µ
        
        å‚è€ƒï¼šproto_utils.cpp:193-201, 274-323 + åæ ‡ç³»æ–‡æ¡£
        
        **C++å‘½åçº¦å®š**ï¼ˆä»å³å¾€å·¦è¯»ï¼‰ï¼š
        - T_A_to_B è¡¨ç¤ºå°†Aç³»åæ ‡å˜æ¢åˆ°Bç³» = Bâ†’A çš„å˜æ¢ = Båœ¨Aç³»ä¸­çš„ä½å§¿
        - ä¾‹å¦‚ï¼šT_sensing_to_camera = Cameraâ†’Sensing (å°†Sensingç³»å˜æ¢åˆ°Cameraç³»)
        
        **configæ–‡ä»¶å«ä¹‰**ï¼š
        - cameras.cfg: sensor_to_cam = Cameraâ†’Sensing (Cameraåœ¨Sensingç³»ä¸­çš„ä½å§¿)
        - lidars.cfg: sensor_to_lidar = LiDARâ†’Sensing (LiDARåœ¨Sensingç³»ä¸­çš„ä½å§¿)
        - lidars.cfg: vehicle_to_sensing = Sensingâ†’Vehicle (Sensingåœ¨Vehicleç³»ä¸­çš„ä½å§¿)
        
        **åæ ‡ç³»å®šä¹‰**ï¼š
        - Vehicleç³»ï¼šåè½´ä¸­å¿ƒï¼Œå‰å·¦ä¸Š=XYZ
        - Sensingç³»ï¼šè™šæ‹Ÿç³»ï¼Œå‰å·¦ä¸Š=XYZ
        - LiDARç³»ï¼šå‰å·¦ä¸Š=XYZï¼ˆä¸KITTI Velodyneä¸€è‡´ï¼‰
        - Cameraç³»ï¼šå…‰è½´=Zï¼Œå³ä¸‹å‰=XYZï¼ˆOpenCVæ ‡å‡†ï¼‰
        """
        # 1. ä»configè¯»å– sensor_to_cam = Cameraâ†’Sensing
        # æŒ‰C++è§„èŒƒå‘½åï¼šT_sensing_to_cameraï¼ˆä»å³å¾€å·¦è¯»ï¼šCameraâ†’Sensingï¼‰
        T_sensing_to_camera = np.eye(4)
        r = R.from_quat(self.camera_config['orientation'])
        T_sensing_to_camera[:3, :3] = r.as_matrix()
        T_sensing_to_camera[:3, 3] = self.camera_config['position']
        
        # 2. å–é€†å¾—åˆ° Sensingâ†’Camera (ä»å³å¾€å·¦è¯»)
        T_camera_to_sensing = np.linalg.inv(T_sensing_to_camera)
        
        # 3. ä»configè¯»å– sensor_to_lidar = LiDARâ†’Sensing
        # æŒ‰C++è§„èŒƒå‘½åï¼šT_sensing_to_lidarï¼ˆä»å³å¾€å·¦è¯»ï¼šLiDARâ†’Sensingï¼‰
        T_sensing_to_lidar = np.eye(4)
        r = R.from_quat(self.lidar_config['orientation'])
        T_sensing_to_lidar[:3, :3] = r.as_matrix()
        T_sensing_to_lidar[:3, 3] = self.lidar_config['position']
        
        # 4. å–é€†å¾—åˆ° Sensingâ†’LiDAR (ä»å³å¾€å·¦è¯»)
        T_lidar_to_sensing = np.linalg.inv(T_sensing_to_lidar)
        
        # 5. è®¡ç®— LiDARâ†’Camera (KITTIæ ‡å‡†TrçŸ©é˜µ)
        # å˜æ¢é“¾ï¼šLiDAR â†’ Sensing â†’ Camera
        # T_camera_to_lidar = T_camera_to_sensing @ T_sensing_to_lidar
        #                   = (Sensingâ†’Camera) @ (LiDARâ†’Sensing)
        #                   = LiDAR â†’ Camera
        self.T_camera_to_lidar = T_camera_to_sensing @ T_sensing_to_lidar
        
        # 6. å–é€†å¾—åˆ° Cameraâ†’LiDAR (ä»å³å¾€å·¦è¯»)
        self.T_lidar_to_camera = np.linalg.inv(self.T_camera_to_lidar)
        
        # 7. ä¿å­˜ç”¨äºå»ç•¸å˜å’ŒæŠ•å½±çš„å˜æ¢
        self.T_sensing_to_lidar = T_sensing_to_lidar    # LiDAR â†’ Sensing (ä»å³å¾€å·¦è¯»)
        self.T_lidar_to_sensing = T_lidar_to_sensing    # Sensing â†’ LiDAR (ä»å³å¾€å·¦è¯»)
        self.T_sensing_to_camera = T_sensing_to_camera  # Camera â†’ Sensing (ä»å³å¾€å·¦è¯»)
        self.T_camera_to_sensing = T_camera_to_sensing  # Sensing â†’ Camera (ä»å³å¾€å·¦è¯»)
        
        # 8. è·å–å¹¶ç¼“å­˜ Vehicleâ†’Sensing å˜æ¢ï¼ˆé¢‘ç¹ä½¿ç”¨ï¼Œæå‰è®¡ç®—ï¼‰
        self.T_vehicle_to_sensing = self._get_vehicle_to_sensing_transform()
        
        # 9. å†…å‚çŸ©é˜µ
        intrinsic = self.camera_config['intrinsic']
        self.K = np.array([
            [intrinsic['f_x'], 0, intrinsic['o_x']],
            [0, intrinsic['f_y'], intrinsic['o_y']],
            [0, 0, 1]
        ])
        
        print(f"\nâœ“ å˜æ¢çŸ©é˜µå·²è®¡ç®— (C++å‘½åçº¦å®šï¼Œä»å³å¾€å·¦è¯»):")
        print(f"  === åæ ‡ç³»å˜æ¢çŸ©é˜µ ===")
        print(f"  T_sensing_to_camera (Cameraâ†’Sensing, ä»configè¯»å–):")
        print(f"    æ—‹è½¬:\n{T_sensing_to_camera[:3, :3]}")
        print(f"    å¹³ç§»: {T_sensing_to_camera[:3, 3]}")
        print(f"  T_camera_to_sensing (Sensingâ†’Camera, TrçŸ©é˜µ):")
        print(f"    æ—‹è½¬:\n{self.T_camera_to_sensing[:3, :3]}")
        print(f"    å¹³ç§»: {self.T_camera_to_sensing[:3, 3]}")
        print(f"  T_sensing_to_lidar (LiDARâ†’Sensing, ä»configè¯»å–):")
        print(f"    æ—‹è½¬:\n{T_sensing_to_lidar[:3, :3]}")
        print(f"    å¹³ç§»: {T_sensing_to_lidar[:3, 3]}")
        print(f"  T_vehicle_to_sensing (Sensingâ†’Vehicle):")
        print(f"    æ—‹è½¬:\n{self.T_vehicle_to_sensing[:3, :3]}")
        print(f"    å¹³ç§»: {self.T_vehicle_to_sensing[:3, 3]}")
        print(f"  ")
        print(f"  === å…³é”®è¯´æ˜ ===")
        print(f"  1. ç‚¹äº‘ä¿å­˜åœ¨Sensingç³»ï¼ˆå»ç•¸å˜åï¼‰")
        print(f"  2. æŠ•å½±æ—¶ä½¿ç”¨ Tr = T_camera_to_sensing (Sensingâ†’Camera)")
        print(f"  3. ä¸C++ lidar_cam_fusion_manual ä½¿ç”¨ç›¸åŒçš„å˜æ¢é“¾")
    
    def extract_data_from_bag(self):
        """ä» rosbag æå–æ•°æ®ï¼ˆæµå¼å¤„ç†+å¹¶è¡ŒåŠ é€Ÿï¼‰"""
        print(f"\n{'='*80}")
        print(f"é˜¶æ®µ 1/3: ä» rosbag æå–æ•°æ®")
        print(f"{'='*80}")
        
        start_time = time.time()
        
        bag_files = self._find_bag_files()
        if not bag_files:
            raise ValueError(f"æœªæ‰¾åˆ° bag æ–‡ä»¶: {self.bag_path}")
        
        print(f"æ‰¾åˆ° {len(bag_files)} ä¸ª bag æ–‡ä»¶")
        
        try:
            from rosbags.rosbag1 import Reader
            use_rosbags = True
        except ImportError:
            try:
                import rosbag
                use_rosbags = False
            except ImportError:
                raise ImportError("éœ€è¦å®‰è£… rosbag æˆ– rosbags: pip install rosbags")
        
        # ç¡®å®šå›¾åƒ topic
        possible_topics = [
            f'/sensors/camera/{self.camera_name}_raw_data/compressed_proto',
            f'/sensors/camera/{self.camera_name}/compressed_proto',
        ]
        
        image_topic = None
        detected_pose_topic = None
        
        # å…³é”®ä¿®å¤ï¼šæ‰«ææ‰€æœ‰bagæ–‡ä»¶ä»¥æ”¶é›†æ‰€æœ‰å¯ç”¨topics
        # ï¼ˆå› ä¸ºä¸åŒçš„Topic Groupæœ‰ä¸åŒçš„topicsï¼ï¼‰
        print(f"\næ‰«ææ‰€æœ‰bagæ–‡ä»¶ä»¥æ£€æµ‹topics...")
        all_available_topics = set()
        
        # ğŸ” ä¼˜åŒ–ï¼šæŒ‰æ–‡ä»¶ååˆ†ç»„ï¼Œç¡®ä¿æ¯ä¸ªTopic Groupéƒ½è¢«æ‰«æ
        from collections import defaultdict
        bags_by_group = defaultdict(list)
        for bf in bag_files:
            # æå–Topic Groupåç§°ï¼ˆå¦‚ Heavy_Topic_Group, Light_Topic_Groupç­‰ï¼‰
            parts = bf.parts
            group_name = 'default'
            for i, p in enumerate(parts):
                if 'Topic_Group' in p:
                    group_name = p
                    break
            bags_by_group[group_name].append(bf)
        
        # ä»æ¯ä¸ªGroupæ‰«æè‡³å°‘1ä¸ªbag
        bags_to_scan = []
        for group, blist in bags_by_group.items():
            bags_to_scan.append(blist[0])  # æ¯ç»„æ‰«æç¬¬ä¸€ä¸ª
        
        print(f"  å‘ç° {len(bags_by_group)} ä¸ªTopic Groups: {list(bags_by_group.keys())}")
        print(f"  æ‰«æ {len(bags_to_scan)} ä¸ªä»£è¡¨æ€§bagæ–‡ä»¶...")
        
        if use_rosbags:
            for bag_file in bags_to_scan:
                try:
                    with Reader(str(bag_file)) as reader:
                        all_available_topics.update(reader.topics.keys())
                except Exception as e:
                    print(f"  è­¦å‘Š: æ— æ³•è¯»å– {bag_file.name}: {e}")
        else:
            import rosbag as rb
            for bag_file in bags_to_scan:
                try:
                    with rb.Bag(str(bag_file), 'r') as bag:
                        info = bag.get_type_and_topic_info()
                        all_available_topics.update(info[1].keys())
                except Exception as e:
                    print(f"  è­¦å‘Š: æ— æ³•è¯»å– {bag_file.name}: {e}")
        
        print(f"  âœ“ æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(all_available_topics)} ä¸ªä¸åŒçš„topics")
        
        # æŸ¥æ‰¾å›¾åƒtopic
        for t in possible_topics:
            if t in all_available_topics:
                image_topic = t
                print(f"  âœ“ æ‰¾åˆ°å›¾åƒ topic: {t}")
                break
        
        # æŸ¥æ‰¾ä½å§¿topicï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šï¼‰
        if self.pose_topic is None:
            for t in self.LOCALIZATION_TOPICS:
                if t in all_available_topics:
                    detected_pose_topic = t
                    print(f"  âœ“ æ‰¾åˆ°ä½å§¿ topic: {t}")
                    break
            if detected_pose_topic is None:
                print(f"  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•ä½å§¿topicï¼Œå°†è·³è¿‡ç‚¹äº‘å»ç•¸å˜")
                print(f"     å°è¯•çš„topics: {self.LOCALIZATION_TOPICS}")
        else:
            if self.pose_topic in all_available_topics:
                detected_pose_topic = self.pose_topic
                print(f"  âœ“ ä½¿ç”¨æŒ‡å®šä½å§¿ topic: {self.pose_topic}")
        
        # ä½¿ç”¨æ£€æµ‹åˆ°çš„topicæˆ–æŒ‡å®šçš„topic
        self.active_pose_topic = detected_pose_topic or self.pose_topic
        
        # å¦‚æœè®¾ç½®äº†max_framesï¼Œå¼ºåˆ¶ä¸²è¡Œæå–ä»¥ä¾¿æå‰ç»ˆæ­¢
        if self.max_frames is not None:
            print(f"\nâš ï¸  è®¾ç½®äº†max_frames={self.max_frames}ï¼Œä½¿ç”¨ä¸²è¡Œæå–ä»¥ä¾¿æå‰ç»ˆæ­¢")
            force_serial = True
        else:
            force_serial = False
        
        # å¹¶è¡Œæå–ï¼ˆå¦‚æœæœ‰å¤šä¸ªbagæ–‡ä»¶ä¸”æœªè®¾ç½®max_framesï¼‰
        if len(bag_files) > 1 and self.num_workers > 1 and not force_serial:
            print(f"\nä½¿ç”¨ {self.num_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç† bag æ–‡ä»¶...")
            self._extract_parallel(bag_files, image_topic, possible_topics, use_rosbags)
        else:
            # ä¸²è¡Œæå–
            # å…³é”®ä¿®å¤ï¼šå¯¹äºmax_framesæ¨¡å¼ï¼Œä¼˜å…ˆå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰ï¼Œå¿«é€Ÿè¾¾åˆ°é˜ˆå€¼ï¼
            if self.max_frames is not None:
                # å¿«é€Ÿæ¨¡å¼ï¼šä¼˜å…ˆå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰ï¼Œç„¶åæ˜¯Light/Medium/Tinyï¼ˆç‚¹äº‘+ä½å§¿ï¼‰
                sorted_bags = sorted(bag_files, key=lambda x: (
                    1 if 'Heavy_Topic_Group' not in x.name else 0,
                    x.name
                ))
                print(f"  ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼ˆmax_frames={self.max_frames}ï¼‰ï¼šä¼˜å…ˆå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰ï¼Œå¿«é€Ÿæ”¶é›†æ•°æ®")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šä¼˜å…ˆå¤„ç†Light/Medium/Tiny bagsï¼ˆç‚¹äº‘+ä½å§¿ï¼‰ï¼Œæœ€åå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰
                sorted_bags = sorted(bag_files, key=lambda x: (
                    0 if 'Heavy_Topic_Group' not in x.name else 1,
                    x.name
                ))
                print(f"  ä¼˜åŒ–å¤„ç†é¡ºåºï¼šä¼˜å…ˆå¤„ç†Light/Medium/Tiny bagsï¼ˆç‚¹äº‘+ä½å§¿ï¼‰ï¼Œæœ€åå¤„ç†Heavy bagsï¼ˆå›¾åƒï¼‰")
            
            for bag_file in sorted_bags:
                # æå‰ç»ˆæ­¢æ£€æŸ¥ï¼ˆä»…é’ˆå¯¹å›¾åƒå’Œç‚¹äº‘ï¼Œä½å§¿éœ€è¦å®Œæ•´ï¼‰
                if self.max_frames is not None:
                    # ä¿®æ­£ï¼šä½¿ç”¨1.1å€ä½œä¸ºç¼“å†²ï¼Œè€Œä¸æ˜¯1.5å€
                    img_count = len(self.image_metadata)
                    pc_count = len(self.pc_metadata)
                    threshold = self.max_frames * 1.1
                    
                    # å…³é”®ä¿®å¤ï¼šå¦‚æœå›¾åƒå’Œç‚¹äº‘éƒ½è¾¾åˆ°é˜ˆå€¼ï¼Œåˆ™å®Œå…¨åœæ­¢æå–ï¼ˆåªæå–ä½å§¿ï¼‰
                    if img_count >= threshold and pc_count >= threshold:
                        # æ³¨æ„ï¼šä½å§¿ä¸é™åˆ¶ï¼Œç»§ç»­æå–ä»¥ç¡®ä¿æ—¶é—´è¦†ç›–
                        print(f"\nâœ“ å›¾åƒå’Œç‚¹äº‘å·²è¶³å¤Ÿï¼ˆå›¾åƒ:{img_count}, ç‚¹äº‘:{pc_count}ï¼‰")
                        print(f"   ç»§ç»­æå–ä½å§¿æ•°æ®ä»¥ç¡®ä¿æ—¶é—´èŒƒå›´å®Œæ•´...")
                        # åˆ‡æ¢åˆ°ä»…æå–ä½å§¿æ¨¡å¼
                        try:
                            if use_rosbags:
                                self._extract_poses_only(bag_file, use_rosbags=True)
                            else:
                                self._extract_poses_only(bag_file, use_rosbags=False)
                        except Exception as e:
                            print(f"  è­¦å‘Š: {e}")
                        continue
                    # å…³é”®ä¿®å¤ï¼šå¦‚æœä»»ä¸€æ•°æ®ç±»å‹å·²è¾¾åˆ°é˜ˆå€¼ï¼Œè·³è¿‡ä¸»è¦åŒ…å«è¯¥ç±»å‹çš„bags
                    elif img_count >= threshold and 'Heavy_Topic_Group' in bag_file.name:
                        print(f"\nâ­ï¸  è·³è¿‡ {bag_file.name}ï¼ˆå›¾åƒæ•°å·²è¶³å¤Ÿ:{img_count}ï¼‰")
                        continue
                    elif pc_count >= threshold and 'Heavy_Topic_Group' not in bag_file.name:
                        print(f"\nâ­ï¸  è·³è¿‡ {bag_file.name}ï¼ˆç‚¹äº‘æ•°å·²è¶³å¤Ÿ:{pc_count}ï¼‰")
                        # ä½†ä»éœ€è¦å¤„ç†ä½å§¿
                        try:
                            if use_rosbags:
                                self._extract_poses_only(bag_file, use_rosbags=True)
                            else:
                                self._extract_poses_only(bag_file, use_rosbags=False)
                        except Exception as e:
                            print(f"  è­¦å‘Š: {e}")
                        continue
                
                print(f"\nå¤„ç†: {bag_file.name}")
                try:
                    if use_rosbags:
                        self._extract_streaming_rosbags(bag_file, image_topic, possible_topics)
                    else:
                        self._extract_streaming_rosbag(bag_file, image_topic, possible_topics)
                except Exception as e:
                    print(f"  è­¦å‘Š: {e}")
        
        # æ’åºå…ƒæ•°æ®
        self.image_metadata.sort(key=lambda x: x.timestamp)
        self.pc_metadata.sort(key=lambda x: x.timestamp)
        self.pose_metadata.sort(key=lambda x: x.timestamp)
        
        # âœ… å…³é”®ä¿®å¤ï¼šå°†Vehicleç³»çš„poseè½¬æ¢ä¸ºSensingç³»ï¼ˆå¯¹é½C++å®ç°ï¼‰
        # C++å‚è€ƒï¼šlidar_online_calibrator.cpp:849-852
        #   sensing_pose.second = vehicle_pose * iso_vehicle_sensing_;
        if len(self.pose_metadata) > 0:
            self._convert_poses_to_sensing_frame()
        
        extract_time = time.time() - start_time
        
        print(f"\nâœ“ æ•°æ®æå–å®Œæˆ:")
        print(f"  å›¾åƒ: {len(self.image_metadata)} å¸§")
        print(f"  ç‚¹äº‘: {len(self.pc_metadata)} å¸§")
        print(f"  ä½å§¿: {len(self.pose_metadata)} ä¸ª")
        if len(self.pose_metadata) == 0:
            print(f"  âš ï¸  è­¦å‘Šï¼šæœªæå–åˆ°ä½å§¿æ•°æ®ï¼ç‚¹äº‘å»ç•¸å˜å°†è·³è¿‡ï¼")
            print(f"    æ£€æµ‹åˆ°çš„ä½å§¿topic: {self.active_pose_topic or 'æœªæ‰¾åˆ°'}")
            print(f"    å¯èƒ½çš„åŸå› ï¼š1) bagä¸­æ²¡æœ‰ä½å§¿æ•°æ®ï¼›2) topicåç§°ä¸åŒ¹é…")
        print(f"  è€—æ—¶: {timedelta(seconds=int(extract_time))}")
        print(f"  é€Ÿåº¦: {len(self.image_metadata) / extract_time:.2f} å¸§/ç§’")
        
        # ä¿å­˜æå–é˜¶æ®µçš„è€—æ—¶
        self._extract_time = extract_time
    
    def _extract_parallel(self, bag_files: List[Path], image_topic: Optional[str],
                         possible_topics: List[str], use_rosbags: bool):
        """å¹¶è¡Œå¤„ç†å¤šä¸ªbagæ–‡ä»¶"""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import threading
        
        # çº¿ç¨‹é”ä¿æŠ¤å…ƒæ•°æ®åˆ—è¡¨å’Œè®¡æ•°å™¨
        lock = threading.Lock()
        counter_lock = threading.Lock()  # ä¸“é—¨ç”¨äºè®¡æ•°å™¨çš„é”
        
        def process_single_bag(bag_file: Path):
            """å¤„ç†å•ä¸ªbagæ–‡ä»¶"""
            try:
                if use_rosbags:
                    # åˆ›å»ºä¸´æ—¶å…ƒæ•°æ®åˆ—è¡¨
                    temp_images = []
                    temp_pcs = []
                    temp_poses = []
                    
                    # æå–æ•°æ®
                    self._extract_streaming_rosbags_to_lists(
                        bag_file, image_topic, possible_topics,
                        temp_images, temp_pcs, temp_poses,
                        counter_lock=counter_lock
                    )
                    
                    # åˆå¹¶åˆ°ä¸»åˆ—è¡¨ï¼ˆéœ€è¦åŠ é”ï¼‰
                    with lock:
                        self.image_metadata.extend(temp_images)
                        self.pc_metadata.extend(temp_pcs)
                        self.pose_metadata.extend(temp_poses)
                    
                    return len(temp_images), len(temp_pcs), len(temp_poses)
                else:
                    # rosbagåº“æš‚ä¸æ”¯æŒå¹¶è¡Œï¼ˆGILé™åˆ¶ï¼‰
                    return 0, 0, 0
            except Exception as e:
                print(f"  é”™è¯¯å¤„ç† {bag_file.name}: {e}")
                return 0, 0, 0
        
        # âœ… ä¼˜åŒ–ï¼šä½¿ç”¨è¾ƒå°‘çš„å¹¶è¡Œåº¦é¿å…I/Oç«äº‰
        # ç‚¹äº‘è§£ææ˜¯CPUå¯†é›†å‹ï¼Œä½†æ–‡ä»¶I/Oæ˜¯ç“¶é¢ˆ
        import gc
        actual_workers = min(self.num_workers, 4)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†ï¼ˆI/Oå¯†é›†å‹ä»»åŠ¡ï¼‰
        # æ³¨æ„ï¼šç‚¹äº‘è§£ææ˜¯CPUå¯†é›†å‹ï¼Œä½†ç”±äºGILï¼Œçº¿ç¨‹æ± æ•ˆç‡æœ‰é™
        # ä½†è¿›ç¨‹æ± ä¼šå¯¼è‡´å†…å­˜é—®é¢˜ï¼Œæ‰€ä»¥ä¿æŒçº¿ç¨‹æ± 
        with ThreadPoolExecutor(max_workers=actual_workers) as executor:
            futures = {executor.submit(process_single_bag, bf): bf for bf in bag_files}
            
            completed = 0
            for future in tqdm(as_completed(futures), total=len(bag_files),
                             desc="  å¹¶è¡Œå¤„ç†bagæ–‡ä»¶", unit="bag"):
                bag_file = futures[future]
                try:
                    n_images, n_pcs, n_poses = future.result()
                    print(f"  âœ“ {bag_file.name}: {n_images} å›¾åƒ, {n_pcs} ç‚¹äº‘, {n_poses} ä½å§¿")
                except Exception as e:
                    print(f"  âœ— {bag_file.name}: é”™è¯¯ - {e}")
                
                # æ¯å¤„ç†10ä¸ªbagæ–‡ä»¶ï¼Œå¼ºåˆ¶GC
                completed += 1
                if completed % 10 == 0:
                    gc.collect()
    
    def _find_bag_files(self) -> List[Path]:
        """æŸ¥æ‰¾ bag æ–‡ä»¶"""
        if self.bag_path.is_file():
            return [self.bag_path]
        elif self.bag_path.is_dir():
            return sorted(self.bag_path.glob('**/*.bag'))
        return []
    
    def _extract_poses_only(self, bag_file: Path, use_rosbags: bool = True):
        """åªæå–ä½å§¿æ•°æ®ï¼ˆç¡®ä¿æ—¶é—´èŒƒå›´å®Œæ•´ï¼‰
        
        å‚è€ƒC++å®ç°ï¼Œä½å§¿æ•°æ®éœ€è¦è¦†ç›–æ‰€æœ‰å›¾åƒ/ç‚¹äº‘çš„æ—¶é—´èŒƒå›´
        """
        pose_count_before = len(self.pose_metadata)
        
        if use_rosbags:
            from rosbags.rosbag1 import Reader
            
            with Reader(str(bag_file)) as reader:
                # æ£€æŸ¥ä½å§¿topicæ˜¯å¦åœ¨å½“å‰bagä¸­
                if self.active_pose_topic and self.active_pose_topic not in reader.topics:
                    return
                
                # åªå…³æ³¨ä½å§¿topic
                for connection, timestamp, rawdata in reader.messages():
                    if self.active_pose_topic and connection.topic == self.active_pose_topic:
                        try:
                            data = self._extract_string_msg(rawdata)
                            if data:
                                # åˆ›å»ºä¸´æ—¶msgå¯¹è±¡
                                class TempMsg:
                                    def __init__(self, d):
                                        self.data = d
                                ts_sec = timestamp / 1e9
                                pose_data = self._decode_pose_msg(TempMsg(data), fallback_timestamp=ts_sec)
                                if pose_data:
                                    self.pose_metadata.append(pose_data)
                        except Exception as e:
                            pass
                    elif not self.active_pose_topic and connection.topic in self.LOCALIZATION_TOPICS:
                        # è‡ªåŠ¨æ£€æµ‹ä½å§¿topic
                        try:
                            data = self._extract_string_msg(rawdata)
                            if data:
                                class TempMsg:
                                    def __init__(self, d):
                                        self.data = d
                                ts_sec = timestamp / 1e9
                                pose_data = self._decode_pose_msg(TempMsg(data), fallback_timestamp=ts_sec)
                                if pose_data:
                                    self.active_pose_topic = connection.topic
                                    self.pose_metadata.append(pose_data)
                        except Exception as e:
                            pass
        else:
            import rosbag as rb
            with rb.Bag(str(bag_file), 'r') as bag:
                for topic, msg, t in bag.read_messages(topics=self.LOCALIZATION_TOPICS):
                    try:
                        pose_data = self._decode_pose_msg(msg)
                        if pose_data:
                            if not self.active_pose_topic:
                                self.active_pose_topic = topic
                            self.pose_metadata.append(pose_data)
                    except Exception as e:
                        pass
        
        pose_count_after = len(self.pose_metadata)
        if pose_count_after > pose_count_before:
            print(f"    æå– {pose_count_after - pose_count_before} ä¸ªä½å§¿")
    
    def _extract_streaming_rosbags(self, bag_file: Path, image_topic: Optional[str],
                                   possible_topics: List[str]):
        """ä½¿ç”¨ rosbags æµå¼æå–"""
        temp_images = []
        temp_pcs = []
        temp_poses = []
        
        self._extract_streaming_rosbags_to_lists(
            bag_file, image_topic, possible_topics,
            temp_images, temp_pcs, temp_poses
        )
        
        # åˆå¹¶åˆ°ä¸»åˆ—è¡¨
        self.image_metadata.extend(temp_images)
        self.pc_metadata.extend(temp_pcs)
        self.pose_metadata.extend(temp_poses)
    
    def _extract_streaming_rosbags_to_lists(self, bag_file: Path, image_topic: Optional[str],
                                           possible_topics: List[str],
                                           out_images: list, out_pcs: list, out_poses: list,
                                           counter_lock=None):
        """ä½¿ç”¨ rosbags æµå¼æå–ï¼ˆè¾“å‡ºåˆ°æŒ‡å®šåˆ—è¡¨ï¼‰
        
        æ³¨æ„ï¼šæ­¤å‡½æ•°ç›´æ¥å°†æ•°æ®æ·»åŠ åˆ° out_images, out_pcs, out_poses åˆ—è¡¨ã€‚
        ä½¿ç”¨bagæ–‡ä»¶å+å±€éƒ¨è®¡æ•°å™¨ä½œä¸ºæ–‡ä»¶åï¼Œé¿å…å¤šçº¿ç¨‹ç«äº‰ã€‚
        """
        from rosbags.rosbag1 import Reader
        import hashlib
        
        topics_to_check = [image_topic] if image_topic else possible_topics
        
        local_img_count = 0
        local_pc_count = 0
        local_pose_count = 0
        
        # ä½¿ç”¨bagæ–‡ä»¶åçš„hashä½œä¸ºå‰ç¼€ï¼Œé¿å…æ–‡ä»¶åå†²çª
        bag_hash = hashlib.md5(bag_file.name.encode()).hexdigest()[:8]
        
        with Reader(str(bag_file)) as reader:
            available = list(reader.topics.keys())
            topics_to_check = [t for t in topics_to_check if t in available]
            
            # æ£€æŸ¥ä½å§¿topicæ˜¯å¦å¯ç”¨
            pose_topic_available = self.active_pose_topic and self.active_pose_topic in available
            # æ£€æŸ¥lidar topicæ˜¯å¦å¯ç”¨
            lidar_topic_available = self.lidar_topic in available
            
            msg_count = 0
            for connection, timestamp, rawdata in tqdm(reader.messages(), 
                                                      desc=f"  æå–æ•°æ®",
                                                      unit="msg",
                                                      leave=False):  # ä¸ä¿ç•™è¿›åº¦æ¡
                msg_count += 1
                
                # bag_record_timeç”¨ä½œfallbackï¼ˆå½“headeræ—¶é—´æˆ³æå–å¤±è´¥æ—¶ï¼‰
                bag_record_time = timestamp / 1e9
                
                # æå–å›¾åƒ
                if connection.topic in topics_to_check:
                    data = self._extract_string_msg(rawdata)
                    if data:
                        header_ts = ProtobufUtils.extract_header_timestamp(data)
                        ts_sec = header_ts if header_ts is not None else bag_record_time
                        
                        image = self._decode_image_msg_from_bytes(data)
                        if image is not None:
                            # ä½¿ç”¨bag_hash+å±€éƒ¨è®¡æ•°å™¨ä½œä¸ºæ–‡ä»¶åï¼Œé¿å…å†²çª
                            filename = f"{bag_hash}_{local_img_count:06d}.jpg"
                            filepath = self.temp_image_dir / filename
                            cv2.imwrite(str(filepath), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
                            
                            out_images.append(ImageMetadata(
                                timestamp=ts_sec,
                                file_path=str(filepath)
                            ))
                            local_img_count += 1
                            del image  # ç«‹å³é‡Šæ”¾
                
                # æå–ç‚¹äº‘
                elif lidar_topic_available and connection.topic == self.lidar_topic:
                    data = self._extract_string_msg(rawdata)
                    if data:
                        header_ts = ProtobufUtils.extract_header_timestamp(data)
                        ts_sec = header_ts if header_ts is not None else bag_record_time
                        
                        # å°è¯•ä»é¦–ä¸ªç‚¹äº‘æ¶ˆæ¯æå– vehicle_to_sensing
                        if self.vehicle_to_sensing_from_bag is None:
                            v2s = self._extract_vehicle_to_sensing_from_pc_msg(data)
                            if v2s is not None:
                                self.vehicle_to_sensing_from_bag = v2s
                                print(f"âœ“ ä»bagç‚¹äº‘æ¶ˆæ¯ä¸­æå–åˆ° vehicle_to_sensing")
                        
                        points = PointCloudParser.parse_proto_pointcloud2(data, config_for_comparison=self.lidar_config)
                        if points is not None and points.shape[0] >= 50:
                            # ä½¿ç”¨bag_hash+å±€éƒ¨è®¡æ•°å™¨ä½œä¸ºæ–‡ä»¶åï¼Œé¿å…å†²çª
                            filename = f"{bag_hash}_{local_pc_count:06d}.bin"
                            filepath = self.temp_pc_dir / filename
                            
                            if points.shape[1] == 3:
                                intensity = np.zeros((points.shape[0], 1), dtype=np.float32)
                                points = np.hstack([points, intensity])
                            
                            points.astype(np.float32).tofile(str(filepath))
                            
                            out_pcs.append(PointCloudMetadata(
                                timestamp=ts_sec,
                                file_path=str(filepath)
                            ))
                            local_pc_count += 1
                            del points  # ç«‹å³é‡Šæ”¾
                
                # æå–ä½å§¿
                elif pose_topic_available and connection.topic == self.active_pose_topic:
                    data = self._extract_string_msg(rawdata)
                    if data:
                        class TempMsg:
                            def __init__(self, d):
                                self.data = d
                        pose = self._decode_pose_msg(TempMsg(data), fallback_timestamp=bag_record_time)
                        if pose:
                            out_poses.append(pose)
                            local_pose_count += 1
    
    def _extract_streaming_rosbag(self, bag_file: Path, image_topic: Optional[str],
                                  possible_topics: List[str]):
        """ä½¿ç”¨ rosbag æµå¼æå–"""
        import rosbag
        
        image_buffer = []
        pc_buffer = []
        
        # æ£€æŸ¥å¯ç”¨topics
        with rosbag.Bag(str(bag_file), 'r') as bag:
            info = bag.get_type_and_topic_info()[1]
            available_topics = list(info.keys())
            pose_topic_available = self.active_pose_topic and self.active_pose_topic in available_topics
        
        with rosbag.Bag(str(bag_file), 'r') as bag:
            msg_count = 0
            for topic, msg, t in tqdm(bag.read_messages(),
                                     desc=f"  æå–æ•°æ®",
                                     unit="msg"):
                # ğŸ”¥ æå‰ç»ˆæ­¢æ£€æŸ¥ï¼šæ¯10æ¡æ¶ˆæ¯æ£€æŸ¥ä¸€æ¬¡ï¼ˆå¿«é€Ÿæ¨¡å¼ç”¨æ›´ç»†ç²’åº¦ï¼‰
                msg_count += 1
                if self.max_frames is not None and msg_count % 10 == 0:
                    img_count = len(self.image_metadata) + len(image_buffer)
                    pc_count = len(self.pc_metadata) + len(pc_buffer)
                    if img_count >= self.max_frames * 1.1 and pc_count >= self.max_frames * 1.1:
                        print(f"\n  âš¡ æå‰ç»ˆæ­¢ï¼šå·²æ”¶é›†è¶³å¤Ÿæ•°æ® (å›¾åƒ:{img_count}, ç‚¹äº‘:{pc_count})")
                        break
                
                # âš ï¸ æ³¨æ„ï¼št.to_sec()æ˜¯bagè®°å½•æ—¶é—´ï¼Œä¸æ˜¯ä¼ æ„Ÿå™¨æ•°æ®æ—¶é—´æˆ³
                bag_record_time = t.to_sec()  # ç”¨ä½œfallback
                
                # æå–å›¾åƒ
                if (image_topic and topic == image_topic) or topic in possible_topics:
                    if hasattr(msg, 'data'):
                        data = msg.data
                        if isinstance(data, str):
                            data = data.encode('latin-1')
                        elif not isinstance(data, bytes):
                            data = None
                        
                        if data:
                            # âœ… å…³é”®ä¿®å¤ï¼šä»headeræå–æ—¶é—´æˆ³ï¼ˆå‚è€ƒC++: image_msg.header().timestamp_sec()ï¼‰
                            header_ts = ProtobufUtils.extract_header_timestamp(data)
                            ts_sec = header_ts if header_ts is not None else bag_record_time
                            
                            image = self._decode_image_msg_from_bytes(data)
                            if image is not None:
                                image_buffer.append((ts_sec, image))
                                # âœ… å†…å­˜ä¼˜åŒ–ï¼šé™ä½æ‰¹é‡å¤§å°
                                if len(image_buffer) >= min(self.batch_size, 50):
                                    self._save_image_batch(image_buffer)
                                    image_buffer.clear()
                
                # æå–ç‚¹äº‘
                elif topic == self.lidar_topic:
                    if hasattr(msg, 'data'):
                        data = msg.data
                        if isinstance(data, str):
                            data = data.encode('latin-1')
                        elif not isinstance(data, bytes):
                            continue
                        
                        # âœ… å…³é”®ä¿®å¤ï¼šä»headeræå–æ—¶é—´æˆ³ï¼ˆå‚è€ƒC++: cloud_msg->header().timestamp_sec()ï¼‰
                        header_ts = ProtobufUtils.extract_header_timestamp(data)
                        ts_sec = header_ts if header_ts is not None else bag_record_time
                        
                        # å°è¯•ä»é¦–ä¸ªç‚¹äº‘æ¶ˆæ¯æå– vehicle_to_sensing (Sensingâ†’Vehicle)
                        if self.vehicle_to_sensing_from_bag is None:
                            v2s = self._extract_vehicle_to_sensing_from_pc_msg(data)
                            if v2s is not None:
                                self.vehicle_to_sensing_from_bag = v2s
                                print(f"âœ“ ä»bagç‚¹äº‘æ¶ˆæ¯ä¸­æå–åˆ° vehicle_to_sensing")
                                print(f"   (C++å‘½å: T_vehicle_to_sensing = Sensingâ†’Vehicle)")
                        
                        points = PointCloudParser.parse_proto_pointcloud2(data, config_for_comparison=self.lidar_config)
                        if points is not None and points.shape[0] >= 50:
                            pc_buffer.append((ts_sec, points))
                            # âœ… å†…å­˜ä¼˜åŒ–ï¼šç‚¹äº‘æ•°æ®æ›´å¤§ï¼Œæ›´é¢‘ç¹åœ°ä¿å­˜
                            if len(pc_buffer) >= min(self.batch_size, 20):
                                self._save_pc_batch(pc_buffer)
                                pc_buffer.clear()
                
                # æå–ä½å§¿
                elif pose_topic_available and topic == self.active_pose_topic:
                    pose = self._decode_pose_msg(msg, fallback_timestamp=bag_record_time)
                    if pose is not None:
                        self.pose_metadata.append(pose)
        
        if image_buffer:
            self._save_image_batch(image_buffer)
        if pc_buffer:
            self._save_pc_batch(pc_buffer)
    
    def _save_image_batch(self, batch: List[Tuple[float, np.ndarray]]):
        """ä¿å­˜ä¸€æ‰¹å›¾åƒåˆ°ä¸´æ—¶ç›®å½•"""
        for ts, image in batch:
            filename = f"{self.image_counter:06d}.jpg"
            filepath = self.temp_image_dir / filename
            cv2.imwrite(str(filepath), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
            
            self.image_metadata.append(ImageMetadata(
                timestamp=ts,
                file_path=str(filepath)
            ))
            self.image_counter += 1
            
            del image  # ç«‹å³é‡Šæ”¾
    
    def _save_pc_batch(self, batch: List[Tuple[float, np.ndarray]]):
        """ä¿å­˜ä¸€æ‰¹ç‚¹äº‘åˆ°ä¸´æ—¶ç›®å½•ï¼ˆBIN æ ¼å¼ï¼Œä¿ç•™timestampç”¨äºå»ç•¸å˜ï¼‰"""
        for ts, points in batch:
            filename = f"{self.pc_counter:06d}.bin"
            filepath = self.temp_pc_dir / filename
            
            # ä¿å­˜ç‚¹äº‘ï¼ˆå¯èƒ½æ˜¯(N,4)æˆ–(N,5)ï¼Œä¿æŒåŸæ ·ï¼‰
            # (N,5)æ ¼å¼ï¼šx, y, z, intensity, timestampï¼ˆç”¨äºå»ç•¸å˜ï¼‰
            # (N,4)æ ¼å¼ï¼šx, y, z, intensityï¼ˆå·²ç»å»ç•¸å˜æˆ–æ— timestampï¼‰
            if points.shape[1] == 3:
                # æ·»åŠ å¼ºåº¦é€šé“ï¼ˆå…¨0ï¼‰
                intensity = np.zeros((points.shape[0], 1), dtype=np.float32)
                points = np.hstack([points, intensity])
            
            # ä¿å­˜ä¸º BIN æ ¼å¼
            points.astype(np.float32).tofile(str(filepath))
            
            self.pc_metadata.append(PointCloudMetadata(
                timestamp=ts,
                file_path=str(filepath)
            ))
            self.pc_counter += 1
            
            del points  # ç«‹å³é‡Šæ”¾
    
    def _extract_string_msg(self, rawdata: bytes) -> Optional[bytes]:
        """æå– std_msgs/String"""
        try:
            if len(rawdata) < 4:
                return None
            length = struct.unpack('<I', rawdata[:4])[0]
            if 0 < length < len(rawdata):
                return rawdata[4:4+length]
            return rawdata
        except:
            return rawdata
    
    def _decode_pose_msg(self, msg, fallback_timestamp: float = None) -> Optional[PoseMetadata]:
        """è§£ç ä½å§¿æ¶ˆæ¯ï¼ˆprotobuf æ ¼å¼ï¼‰- å‚è€ƒSelf-Cali-GSå®ç°"""
        try:
            if hasattr(msg, 'data'):
                data = msg.data
                if isinstance(data, str):
                    data = data.encode('latin-1')
                elif not isinstance(data, bytes):
                    return None
                
                # æå– String åŒ…è£…
                data = self._extract_string_msg(data)
                if not data or len(data) < 48:  # è‡³å°‘éœ€è¦6ä¸ªdouble (position+euler)
                    return None
                
                # å°è¯•wire formatè§£æ (å‚è€ƒSelf-Cali-GS)
                position, euler_angles, timestamp = self._parse_proto_localization_wire(data)
                
                if position is not None and euler_angles is not None:
                    # âœ… éªŒè¯positionä¸æ˜¯å…¨é›¶ï¼ˆå‚è€ƒSelf-Cali-GSï¼‰
                    if np.max(np.abs(position)) < 1e-6:
                        return None  # positionå…¨é›¶ï¼Œæ— æ•ˆæ•°æ®
                    
                    # ä»æ¬§æ‹‰è§’è®¡ç®—å››å…ƒæ•°
                    r = R.from_euler('xyz', euler_angles, degrees=False)
                    orientation = r.as_quat()  # [x, y, z, w]
                    
                    # å¦‚æœæ²¡æœ‰æå–åˆ°æ—¶é—´æˆ³ï¼Œä½¿ç”¨fallback
                    if timestamp is None:
                        timestamp = fallback_timestamp
                    
                    if timestamp is None:
                        return None
                    
                    return PoseMetadata(
                        timestamp=timestamp,
                        position=position,
                        orientation=orientation
                    )
            
            return None
        except Exception as e:
            return None
    
    def _parse_proto_localization_wire(self, data: bytes) -> Tuple[Optional[np.ndarray], Optional[np.ndarray], Optional[float]]:
        """æŒ‰ç…§wire formatè§£æå®šä½protoï¼ˆå®Œå…¨å¯¹é½Self-Cali-GSå®ç°ï¼‰
        
        Returns:
            (position, euler_angles, timestamp)
        """
        position = None
        euler_angles = None
        timestamp = None
        
        try:
            # è·³è¿‡DeepRouteçš„é¢å¤–header: $$$$ + <4 bytes length> + <header content>
            if data[:4] == b'$$$$':
                if len(data) < 8:
                    return None, None, None
                header_len = struct.unpack('<I', data[4:8])[0]
                if len(data) < 8 + header_len:
                    return None, None, None
                data = data[8 + header_len:]  # è·³è¿‡4å­—èŠ‚marker + 4å­—èŠ‚length + headerå†…å®¹
            # æ–¹æ³•1: å°è¯•JSONæ ¼å¼ï¼ˆæŸäº›bagä½¿ç”¨JSONï¼‰
            try:
                text = data.decode('utf-8', errors='ignore').strip()
                if text.startswith('{'):
                    import json
                    j = json.loads(text)
                    
                    # æå–timestamp
                    if 'measurement_time' in j:
                        timestamp = float(j['measurement_time']) / 1e6
                    
                    # æå–position
                    if 'position' in j:
                        p = j['position']
                        if isinstance(p, dict):
                            position = np.array([float(p.get('x', 0)), float(p.get('y', 0)), float(p.get('z', 0))])
                        elif isinstance(p, (list, tuple)):
                            position = np.array([float(p[0]), float(p[1]), float(p[2])])
                    
                    # æå–euler_angles
                    if 'euler_angles' in j:
                        e = j['euler_angles']
                        if isinstance(e, dict):
                            euler_angles = np.array([float(e.get('x', 0)), float(e.get('y', 0)), float(e.get('z', 0))])
                        else:
                            euler_angles = np.array([float(e[0]), float(e[1]), float(e[2])])
                    
                    if position is not None and euler_angles is not None:
                        return position, euler_angles, timestamp
            except:
                pass
            
            # æ–¹æ³•2: Wire formatè§£æ
            i = 0
            while i < len(data) - 1:
                tag = data[i]
                i += 1
                
                field_number = tag >> 3
                wire_type = tag & 0x7
                
                if wire_type == 0:  # Varint
                    while i < len(data):
                        byte = data[i]
                        i += 1
                        if (byte & 0x80) == 0:
                            break
                elif wire_type == 1:  # Fixed64 (sfixed64, double)
                    if i + 8 > len(data):
                        break
                    val = struct.unpack_from('<q', data, i)[0]  # int64
                    i += 8
                    # field 2 é€šå¸¸æ˜¯ measurement_time (å¾®ç§’)
                    if field_number == 2 and 1.5e15 < val < 2e15:
                        timestamp = float(val) / 1e6  # å¾®ç§’ â†’ ç§’ï¼ˆæ˜¾å¼è½¬æ¢ï¼‰
                elif wire_type == 2:  # Length-delimited
                    if i >= len(data):
                        break
                    # è¯»å–é•¿åº¦
                    length = 0
                    shift = 0
                    while i < len(data):
                        byte = data[i]
                        i += 1
                        length |= (byte & 0x7F) << shift
                        if (byte & 0x80) == 0:
                            break
                        shift += 7
                    
                    if i + length > len(data):
                        break
                    
                    payload = data[i:i+length]
                    i += length
                    
                    # Point3D å¯èƒ½æ˜¯24 bytes (3ä¸ªçº¯double) æˆ– 27 bytes (å¸¦tagçš„double)
                    if length == 24:
                        try:
                            coords = struct.unpack_from('<ddd', payload, 0)
                            if field_number == 5:  # position
                                position = np.array(coords, dtype=float)
                            elif field_number == 6:  # euler_angles
                                euler_angles = np.array(coords, dtype=float)
                        except:
                            pass
                    elif length == 27:
                        # DeepRouteæ ¼å¼: æ¯ä¸ªdoubleå‰æœ‰tag (field + wire_type)
                        # tag (1 byte) + double (8 bytes) = 9 bytes per value
                        try:
                            j = 0
                            coords = []
                            while j < len(payload) - 8:
                                if (payload[j] & 0x7) == 1:  # Fixed64 (double)
                                    val = struct.unpack_from('<d', payload, j+1)[0]
                                    coords.append(val)
                                    j += 9
                                else:
                                    j += 1
                            
                            if len(coords) == 3:
                                if field_number == 5:  # position
                                    position = np.array(coords, dtype=float)
                                elif field_number == 6:  # euler_angles
                                    euler_angles = np.array(coords, dtype=float)
                        except:
                            pass
                elif wire_type == 5:  # Fixed32
                    if i + 4 > len(data):
                        break
                    i += 4
                else:
                    break
            
            # æ–¹æ³•3: Fallbackå¯å‘å¼æœç´¢ - æœç´¢è¿ç»­6ä¸ªdouble (position+euler)
            # è¿™æ˜¯æœ€é²æ£’çš„æ–¹æ³•ï¼Œå¯¹é½Self-Cali-GS
            if position is None or euler_angles is None:
                for i in range(0, len(data) - 47, 1):
                    try:
                        d = [struct.unpack_from('<d', data, i + k * 8)[0] for k in range(6)]
                        # Self-Cali-GSçš„éªŒè¯æ¡ä»¶ï¼ˆåŠ å¼ºç‰ˆï¼‰ï¼š
                        # 1. positionåœ¨åˆç†èŒƒå›´å†…ï¼ˆ< 1e6ç±³ï¼Œå³1000å…¬é‡Œï¼‰
                        # 2. eulerè§’åº¦åº”åœ¨ [-4, 4] èŒƒå›´å†…ï¼ˆ~Â±229åº¦ï¼‰
                        if not all(abs(v) < 1e6 and not (np.isnan(v) or np.isinf(v)) for v in d[0:3]):
                            continue
                        if not all(abs(v) < 4 for v in d[3:6]):  # euleræ›´ä¸¥æ ¼
                            continue
                        
                        position = np.array(d[0:3], dtype=float)
                        euler_angles = np.array(d[3:6], dtype=float)
                        
                        # æœç´¢timestampï¼ˆåœ¨æ‰¾åˆ°pos+eulerä¹‹åï¼‰
                        if timestamp is None:
                            for j in range(0, min(i, len(data) - 8)):
                                try:
                                    v = struct.unpack_from('<q', data, j)[0]  # int64
                                    if 1.5e15 < v < 2e15:
                                        timestamp = float(v) / 1e6  # å¾®ç§’ â†’ ç§’ï¼ˆæ˜¾å¼è½¬æ¢ï¼‰
                                        break
                                except:
                                    continue
                        break
                    except:
                        continue
            
            # æ–¹æ³•4: åªæœç´¢euler_angles (3ä¸ªdouble)ï¼Œä½œä¸ºæœ€åçš„fallback
            if position is None and euler_angles is None:
                for i in range(0, len(data) - 23, 1):
                    try:
                        d = [struct.unpack_from('<d', data, i + k * 8)[0] for k in range(3)]
                        if all(abs(v) < 4 for v in d):  # eulerèŒƒå›´æ£€æŸ¥
                            euler_angles = np.array(d, dtype=float)
                            # å¦‚æœåªæœ‰eulerï¼Œpositionè®¾ä¸ºé›¶ï¼ˆè™½ç„¶ä¸ç†æƒ³ï¼‰
                            break
                    except:
                        continue
            
            # æœ€åæœç´¢æ—¶é—´æˆ³ï¼ˆå¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼‰
            if timestamp is None:
                for i in range(0, len(data) - 8, 1):
                    try:
                        val = struct.unpack_from('<q', data, i)[0]  # int64
                        if 1.5e15 < val < 2e15:  # å¾®ç§’èŒƒå›´éªŒè¯
                            timestamp = float(val) / 1e6  # å¾®ç§’ â†’ ç§’ï¼ˆæ˜¾å¼è½¬æ¢ï¼‰
                            break
                    except:
                        continue
            
            return position, euler_angles, timestamp
            
        except Exception:
            return None, None, None
    
    def _extract_proto_timestamp(self, data: bytes) -> Optional[float]:
        """ä» protobuf ä¸­æå–æ—¶é—´æˆ³"""
        try:
            # æŸ¥æ‰¾æ—¶é—´æˆ³ï¼ˆé€šå¸¸æ˜¯ int64 æˆ– doubleï¼‰
            # Protobuf tag for timestamp é€šå¸¸æ˜¯ field 3 æˆ– 4
            for i in range(min(200, len(data) - 8)):
                try:
                    # å°è¯•è¯»å–ä¸º uint64 (nanoseconds since epoch)
                    ts_ns = struct.unpack('<Q', data[i:i+8])[0]
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆç†çš„æ—¶é—´æˆ³ï¼ˆ2020-2030å¹´ï¼‰
                    if 1577836800e9 < ts_ns < 1893456000e9:
                        return ts_ns / 1e9
                    
                    # å°è¯•è¯»å–ä¸º double (seconds since epoch)
                    ts_sec = struct.unpack('<d', data[i:i+8])[0]
                    if 1577836800 < ts_sec < 1893456000:
                        return ts_sec
                except:
                    pass
            
            return None
        except:
            return None
    
    def _decode_image(self, rawdata: bytes) -> Optional[np.ndarray]:
        """è§£ç å›¾åƒï¼ˆrosbagsï¼‰"""
        try:
            data = self._extract_string_msg(rawdata)
            if not data:
                return None
            
            # JPEG
            jpeg_start = data.find(b'\xff\xd8')
            if jpeg_start != -1:
                jpeg_end = data.rfind(b'\xff\xd9')
                if jpeg_end > jpeg_start:
                    img_array = np.frombuffer(data[jpeg_start:jpeg_end+2], np.uint8)
                    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                    if image is not None:
                        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # PNG
            png_start = data.find(b'\x89PNG')
            if png_start != -1:
                img_array = np.frombuffer(data[png_start:], np.uint8)
                image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                if image is not None:
                    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except:
            pass
        return None
    
    def _decode_image_msg_from_bytes(self, data: bytes) -> Optional[np.ndarray]:
        """ä»bytesè§£ç å›¾åƒ"""
        try:
            jpeg_start = data.find(b'\xff\xd8')
            if jpeg_start != -1:
                jpeg_end = data.rfind(b'\xff\xd9')
                if jpeg_end > jpeg_start:
                    img_array = np.frombuffer(data[jpeg_start:jpeg_end+2], np.uint8)
                    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                    if image is not None:
                        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        except:
            pass
        return None
    
    def _decode_image_msg(self, msg) -> Optional[np.ndarray]:
        """è§£ç å›¾åƒï¼ˆrosbagï¼‰"""
        try:
            if hasattr(msg, 'data'):
                data = msg.data
                if isinstance(data, str):
                    data = data.encode('latin-1')
                elif not isinstance(data, bytes):
                    return None
                return self._decode_image_msg_from_bytes(data)
        except:
            pass
        return None
    
    def _process_single_frame(self, args):
        """å¤„ç†å•å¸§æ•°æ®ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰"""
        idx, img_idx, pc_idx, image_dir, velodyne_dir = args
        
        # å¤åˆ¶å›¾åƒï¼ˆä½¿ç”¨shutil.copyæ›´å¿«ï¼‰
        src_img = Path(self.image_metadata[img_idx].file_path)
        dst_img = image_dir / f"{idx:06d}.png"
        
        try:
            # å¦‚æœæºæ–‡ä»¶æ˜¯PNGï¼Œç›´æ¥å¤åˆ¶ï¼›å¦åˆ™è½¬æ¢
            if src_img.suffix.lower() == '.png':
                import shutil
                shutil.copy2(str(src_img), str(dst_img))
            else:
                img = Image.open(src_img)
                img.save(dst_img)
        except Exception as e:
            # å›¾åƒè¯»å–/ä¿å­˜å¤±è´¥ï¼Œè·³è¿‡è¯¥å¸§
            if idx == 0:
                print(f"âš ï¸  å›¾åƒå¤„ç†å¤±è´¥: {e}")
            return None
        
        # è¯»å–å¹¶å»ç•¸å˜ç‚¹äº‘
        src_pc = Path(self.pc_metadata[pc_idx].file_path)
        dst_pc = velodyne_dir / f"{idx:06d}.bin"
        
        # è¯»å–åŸå§‹ç‚¹äº‘
        try:
            points_data = np.fromfile(str(src_pc), dtype=np.float32)
        except Exception as e:
            if dst_img.exists():
                dst_img.unlink()
            return False
        
        # åˆ¤æ–­æ˜¯å¦æœ‰timestampï¼ˆ5åˆ—ï¼‰
        if len(points_data) % 5 == 0:
            # (N, 5): x, y, z, intensity, timestamp
            points_raw = points_data.reshape(-1, 5)
            
            if self.pose_metadata and len(self.pose_metadata) > 0:
                # æœ‰poseæ•°æ®ï¼Œåº”ç”¨å»ç•¸å˜
                # âœ… å»ç•¸å˜åŸç†ï¼šå°†ç‚¹äº‘ä»æ¿€å…‰é›·è¾¾æ‰«ææ—¶åˆ»(cloud_ts)è½¬æ¢åˆ°å›¾åƒæ—¶åˆ»(target_ts)
                # âœ… å»ç•¸å˜åçš„ç‚¹äº‘åœ¨ç©ºé—´ä¸Šå¯¹åº”äºå›¾åƒæ—¶åˆ»ï¼Œæ¶ˆé™¤äº†è¿åŠ¨ç•¸å˜
                cloud_ts = self.pc_metadata[pc_idx].timestamp  # LiDARæ‰«æå¼€å§‹æ—¶åˆ»
                target_ts = self.image_metadata[img_idx].timestamp  # å›¾åƒæ›å…‰æ—¶åˆ»ï¼ˆç›®æ ‡å¯¹é½æ—¶åˆ»ï¼‰
                
                # ç‚¹äº‘å»ç•¸å˜ï¼ˆposeså·²ç»æ˜¯Sensingç³»ï¼ŒLiDARç³»=Sensingç³»ï¼‰
                # æ³¨ï¼šè°ƒè¯•ä¿¡æ¯åªåœ¨verboseæ¨¡å¼ä¸”ç¬¬ä¸€å¸§æ—¶æ‰“å°
                points_undistorted = UndistortionUtils.undistort_pointcloud(
                    points_raw, cloud_ts, target_ts, self.pose_metadata,
                    debug=(idx == 0 and self.verbose),
                    frame_idx=idx
                )
                
                # âœ… å…³é”®ä¿®å¤ï¼šå¦‚æœå»ç•¸å˜å¤±è´¥ï¼ˆè¿”å›Noneï¼‰ï¼Œè·³è¿‡è¯¥å¸§
                if points_undistorted is None:
                    # åˆ é™¤å·²ä¿å­˜çš„å›¾åƒ
                    if dst_img.exists():
                        dst_img.unlink()
                    return None  # è¿”å› None è¡¨ç¤ºè¯¥å¸§è¢«è·³è¿‡
                
                # ğŸ” æ‰“å°å»ç•¸å˜å‰åçš„ç‚¹äº‘èŒƒå›´ï¼ˆä»…verboseæ¨¡å¼ï¼‰
                if idx == 0 and self.verbose:
                    print(f"\n  å»ç•¸å˜å‰ç‚¹äº‘èŒƒå›´:")
                    print(f"    X: [{points_raw[:, 0].min():.2f}, {points_raw[:, 0].max():.2f}]")
                    print(f"    Y: [{points_raw[:, 1].min():.2f}, {points_raw[:, 1].max():.2f}]")
                    print(f"    Z: [{points_raw[:, 2].min():.2f}, {points_raw[:, 2].max():.2f}]")
                    print(f"  å»ç•¸å˜åç‚¹äº‘èŒƒå›´:")
                    print(f"    X: [{points_undistorted[:, 0].min():.2f}, {points_undistorted[:, 0].max():.2f}]")
                    print(f"    Y: [{points_undistorted[:, 1].min():.2f}, {points_undistorted[:, 1].max():.2f}]")
                    print(f"    Z: [{points_undistorted[:, 2].min():.2f}, {points_undistorted[:, 2].max():.2f}]")
            else:
                # æ²¡æœ‰poseæ•°æ®ï¼Œç›´æ¥ä½¿ç”¨å‰4åˆ—
                points_undistorted = points_raw[:, :4]
                if idx == 0 and self.verbose:
                    print(f"  âš ï¸  è­¦å‘Šï¼šæ²¡æœ‰poseæ•°æ®, ç›´æ¥ä½¿ç”¨å‰4åˆ—")
        elif len(points_data) % 4 == 0:
            # (N, 4): x, y, z, intensityï¼Œæ— timestamp
            points_raw = points_data.reshape(-1, 4)
            points_undistorted = points_raw
        else:
            return False  # æ ¼å¼å¼‚å¸¸
        
        # âœ… å…³é”®ä¿®å¤ï¼šç‚¹äº‘ä¿æŒåœ¨Sensingç³»ï¼ˆä¸C++å®ç°ä¸€è‡´ï¼‰
        # 
        # C++å®ç°å‚è€ƒï¼šmanual_sensor_calib.cpp
        # - ç‚¹äº‘å»ç•¸å˜ååœ¨ Sensing åæ ‡ç³»
        # - æŠ•å½±æ—¶ä½¿ç”¨ Sensingâ†’Camera å˜æ¢
        # - è¿™æ ·å¯ä»¥ç›´æ¥ä½¿ç”¨ kitti_dataset.pyï¼Œæ— éœ€é¢å¤–çš„åæ ‡è½¬æ¢
        #
        # å˜æ¢é“¾ï¼š
        # - ç‚¹äº‘åœ¨Sensingç³»ï¼šP_sensingï¼ˆå»ç•¸å˜åï¼‰
        # - å˜æ¢åˆ°Cameraç³»ï¼šP_camera = T_sensing_to_camera * P_sensing
        # - æŠ•å½±åˆ°å›¾åƒï¼šp = K * P_camera
        #
        # æ³¨æ„ï¼šTrçŸ©é˜µä¹Ÿéœ€è¦ç›¸åº”ä¿®æ”¹ä¸º Sensingâ†’Camera
        
        # ç›´æ¥ä½¿ç”¨å»ç•¸å˜åçš„ç‚¹äº‘ï¼ˆSensingç³»ï¼‰
        points_final = points_undistorted
        
        # ä»…åœ¨ç¬¬ä¸€å¸§ä¸”verboseæ¨¡å¼æ‰“å°åæ ‡ç³»ä¿¡æ¯
        # if idx == 0 and self.verbose:
        #     print(f"\n  ç‚¹äº‘åæ ‡ç³»: Sensingç³»ï¼ˆä¸C++ä¸€è‡´ï¼‰")
        
        # ä¿å­˜ç‚¹äº‘ï¼ˆSensingç³»ï¼Œä¸C++ä¸€è‡´ï¼‰
        # æ ¼å¼ï¼š(N, 4) = [x, y, z, intensity]
        points_final.astype(np.float32).tofile(str(dst_pc))
        
        # âœ… å†…å­˜ä¼˜åŒ–ï¼šæ˜¾å¼åˆ é™¤å¤§æ•°ç»„
        del points_data, points_raw, points_undistorted, points_final
        
        return True
    
    def sync_and_save(self, sequence_id: str = "00"):
        """åŒæ­¥å¹¶ç”Ÿæˆæœ€ç»ˆæ•°æ®é›†ï¼ˆå‚è€ƒC++çš„GetSyncCalibrationDataé€»è¾‘ï¼‰
        
        å‚è€ƒï¼šlidar_online_calibrator.cpp:525-744
        - ä¸¥æ ¼ä½¿ç”¨motion_interpolateè¿›è¡Œä½å§¿æ’å€¼
        - å¦‚æœæ’å€¼å¤±è´¥ï¼Œè·³è¿‡è¯¥å¸§ï¼ˆä¸åšæ—¶é—´æˆ³æ ¡æ­£ï¼‰
        - ä½¿ç”¨æ—¶é—´å·®é˜ˆå€¼è¿›è¡Œæ•°æ®å¯¹é½ï¼ˆkMaxLidarCameraDelta=55msï¼‰
        
        ğŸ¯ æ—¶é—´å¯¹é½åŸç†ï¼š
            1. æ¯ä¸€å¸§æ•°æ®çš„é€»è¾‘æ—¶åˆ» = å›¾åƒæ›å…‰æ—¶åˆ» (image_timestamp)
            2. ç‚¹äº‘é€šè¿‡å»ç•¸å˜ä»LiDARæ‰«ææ—¶åˆ»è½¬æ¢åˆ°å›¾åƒæ—¶åˆ»
            3. ä½å§¿ä½¿ç”¨motion_interpolateæ’å€¼åˆ°å›¾åƒæ—¶åˆ»
            4. æœ€ç»ˆï¼šå›¾åƒã€ç‚¹äº‘ã€ä½å§¿ åœ¨å›¾åƒæ—¶åˆ»å®Œå…¨å¯¹é½
        """
        print(f"\n{'='*80}")
        print(f"é˜¶æ®µ 2/3: åŒæ­¥æ•°æ®")
        print(f"{'='*80}")
        
        sync_start_time = time.time()
        
        if not self.image_metadata or not self.pc_metadata:
            raise ValueError("å›¾åƒæˆ–ç‚¹äº‘æ•°æ®ä¸ºç©º")
        
        # æ‰“å°æ—¶é—´æˆ³èŒƒå›´ç”¨äºè¯Šæ–­
        if self.pose_metadata:
            data_ts_min = min(self.image_metadata[0].timestamp, self.pc_metadata[0].timestamp)
            data_ts_max = max(self.image_metadata[-1].timestamp, self.pc_metadata[-1].timestamp)
            pose_ts_min = self.pose_metadata[0].timestamp
            pose_ts_max = self.pose_metadata[-1].timestamp
            
            print(f"\næ—¶é—´æˆ³èŒƒå›´:")
            print(f"  æ•°æ®: [{data_ts_min:.3f}, {data_ts_max:.3f}]")
            print(f"  ä½å§¿: [{pose_ts_min:.3f}, {pose_ts_max:.3f}]")
            
            if data_ts_min < pose_ts_min or data_ts_max > pose_ts_max:
                print(f"  âš ï¸  è­¦å‘Š: æ•°æ®æ—¶é—´æˆ³è¶…å‡ºä½å§¿èŒƒå›´ï¼Œè¿™äº›å¸§å°†è·³è¿‡å»ç•¸å˜")
                print(f"     å‚è€ƒC++å®ç°ï¼Œmotion_interpolateå¤±è´¥æ—¶ä¼šè·³è¿‡è¯¥å¸§")
        
        # åˆ›å»ºæœ€ç»ˆç›®å½•
        seq_dir = self.output_dir / 'sequences' / sequence_id
        seq_dir.mkdir(parents=True, exist_ok=True)
        image_dir = seq_dir / 'image_2'
        velodyne_dir = seq_dir / 'velodyne'
        image_dir.mkdir(exist_ok=True)
        velodyne_dir.mkdir(exist_ok=True)
        
        # ========================================================================
        # åŒæ­¥å›¾åƒå’Œç‚¹äº‘ - å®Œå…¨å¯¹é½C++ get_sync_obstacles_innerå®ç°
        # ========================================================================
        synced_pairs = []
        rejected_pairs = 0  # ç»Ÿè®¡å› æ—¶é—´å·®è¿‡å¤§è€Œè¢«æ‹’ç»çš„å¯¹æ•°
        rejected_details = []  # å­˜å‚¨æ‹’ç»é…å¯¹çš„è¯¦ç»†ä¿¡æ¯
        
        img_idx = 0
        pc_idx = 0
        
        print(f"\nå¼€å§‹åŒæ­¥ï¼ˆå¯¹é½C++å®ç°ï¼‰:")
        print(f"  å›¾åƒæ•°é‡: {len(self.image_metadata)}")
        print(f"  ç‚¹äº‘æ•°é‡: {len(self.pc_metadata)}")
        print(f"  åŒæ­¥é˜ˆå€¼: {self.max_time_diff*1000:.0f}ms (kMaxLidarCameraDelta)")
        
        with tqdm(total=min(len(self.image_metadata), len(self.pc_metadata)),
                 desc="åŒæ­¥æ•°æ®") as pbar:
            while img_idx < len(self.image_metadata) and pc_idx < len(self.pc_metadata):
                # è·å–å½“å‰å›¾åƒå’Œç‚¹äº‘çš„æ—¶é—´æˆ³ï¼ˆå¾®ç§’ï¼‰
                image_time = self.image_metadata[img_idx].timestamp
                cloud_time = self.pc_metadata[pc_idx].timestamp
                
                # âœ… C++é€»è¾‘ï¼šæ‰¾åˆ°æœ€å¤§æ—¶é—´æˆ³ä½œä¸ºå‚è€ƒç‚¹
                max_stamp = max(image_time, cloud_time)
                stamp_lower_bound = max_stamp - self.max_time_diff
                
                # âœ… C++é€»è¾‘ï¼šç§»é™¤è¿‡æ—§çš„æ•°æ®ï¼ˆæ—¶é—´æˆ³ < max_stamp - kMaxLidarCameraDeltaï¼‰
                is_data_sync = True
                
                if image_time < stamp_lower_bound:
                    # å›¾åƒè¿‡æ—§ï¼Œè·³è¿‡
                    img_idx += 1
                    is_data_sync = False
                    pbar.update(1)
                    continue
                
                if cloud_time < stamp_lower_bound:
                    # ç‚¹äº‘è¿‡æ—§ï¼Œè·³è¿‡
                    pc_idx += 1
                    is_data_sync = False
                    pbar.update(1)
                    continue
                
                # âœ… C++é€»è¾‘ï¼šæ£€æŸ¥å›¾åƒå’Œç‚¹äº‘çš„æ—¶é—´å·®
                lidar_camera_delta = abs(image_time - cloud_time)
                
                if lidar_camera_delta <= self.max_time_diff:
                    # æ—¶é—´å·®åœ¨é˜ˆå€¼å†…ï¼Œé…å¯¹æˆåŠŸ
                    synced_pairs.append((img_idx, pc_idx))
                    img_idx += 1
                    pc_idx += 1
                    pbar.update(1)
                else:
                    # æ—¶é—´å·®è¿‡å¤§ï¼Œç§»é™¤æ—¶é—´æˆ³è¾ƒå°çš„é‚£ä¸ª
                    rejected_pairs += 1
                    delta_ms = lidar_camera_delta * 1000
                    exceed_ms = delta_ms - self.max_time_diff * 1000
                    rejected_details.append((img_idx, pc_idx, delta_ms, exceed_ms))
                    
                    if image_time < cloud_time:
                        img_idx += 1
                    else:
                        pc_idx += 1
                    pbar.update(1)
        
        # å…³é”®ï¼šè¿‡æ»¤æ‰æ— æ³•è¿›è¡Œä½å§¿æ’å€¼çš„å¸§
        # ğŸ”§ æ”¹è¿›ï¼šæ”¯æŒä¸è¿ç»­çš„bagæ•°æ®ï¼ˆçº¿ä¸Šæ ¹æ®è½¦é€Ÿ/åœºæ™¯è¿‡æ»¤åçš„æ•°æ®ï¼‰
        # å‚è€ƒ C++ manual_sensor_calib.cpp çš„ min_delta é€»è¾‘
        if self.pose_metadata:
            pose_ts_min = self.pose_metadata[0].timestamp
            pose_ts_max = self.pose_metadata[-1].timestamp
            
            # âœ… ä¸¤ç§æ£€æŸ¥æ–¹å¼ï¼š
            # 1. max_pose_gap: ç”¨äºæ’å€¼æ—¶æ£€æŸ¥ç›¸é‚»poseçš„é—´éš”
            # 2. max_pose_delta: ç”¨äºæœ€è¿‘é‚»æ–¹å¼æ£€æŸ¥æœ€è¿‘poseçš„æ—¶é—´å·®
            # å‚è€ƒC++ manual_sensor_calib.cpp: min_delta < 0.1e9 (100ms)
            MAX_POSE_GAP = self.max_pose_gap  # ç”¨äºæ’å€¼æ£€æŸ¥
            MAX_POSE_DELTA = 0.15  # 150msï¼Œç”¨äºæœ€è¿‘é‚»æ£€æŸ¥ï¼ˆæ¯”C++çš„100msç¨å®½æ¾ï¼‰
            
            synced_pairs_filtered = []
            skipped_reasons = {'no_file': 0, 'no_pose_coverage': 0, 'pose_too_far': 0}
            
            print(f"\n  æ£€æŸ¥poseè¦†ç›–ï¼ˆæ”¯æŒä¸è¿ç»­bagæ•°æ®ï¼‰:")
            print(f"    æ’å€¼æ¨¡å¼: æœ€å¤§poseé—´éš” {MAX_POSE_GAP:.1f}s")
            print(f"    æœ€è¿‘é‚»æ¨¡å¼: æœ€å¤§æ—¶é—´å·® {MAX_POSE_DELTA*1000:.0f}ms (å‚è€ƒC++ min_delta)")
            
            for img_idx, pc_idx in synced_pairs:
                pc_meta = self.pc_metadata[pc_idx]
                pc_ts = pc_meta.timestamp
                img_ts = self.image_metadata[img_idx].timestamp
                
                # âœ… ä¿®å¤ï¼šä½¿ç”¨ pc_metadata ä¸­å­˜å‚¨çš„å®é™…æ–‡ä»¶è·¯å¾„
                temp_pc_file = Path(pc_meta.file_path)
                
                if not temp_pc_file.exists():
                    skipped_reasons['no_file'] += 1
                    continue
                
                # è¯»å–ç‚¹äº‘è·å–æ‰«ææ—¶é—´èŒƒå›´
                try:
                    points_raw = np.fromfile(str(temp_pc_file), dtype=np.float32)
                    if len(points_raw) % 5 == 0:
                        points_raw = points_raw.reshape(-1, 5)
                    elif len(points_raw) % 4 == 0:
                        points_raw = points_raw.reshape(-1, 4)
                        # æ²¡æœ‰timestampåˆ—ï¼Œå‡è®¾æ‰«ææ—¶é—´ä¸º0.1ç§’
                        end_ts = pc_ts + 0.1
                    else:
                        skipped_reasons['no_file'] += 1
                        continue
                    
                    if points_raw.shape[1] >= 5:
                        max_inner_ts_us = points_raw[:, 4].max()
                        delta_time_us = max_inner_ts_us * 2  # å•ä½æ˜¯2å¾®ç§’
                        end_ts = pc_ts + delta_time_us * 1e-6
                    else:
                        end_ts = pc_ts + 0.1  # å‡è®¾æ‰«ææ—¶é—´ä¸º0.1ç§’
                    
                    # ğŸ”§ æ”¹è¿›ï¼šä½¿ç”¨ä¸¤ç§æ–¹å¼æ£€æŸ¥poseè¦†ç›–
                    # æ–¹å¼1ï¼šä¼ ç»Ÿæ’å€¼æ£€æŸ¥ï¼ˆè¦æ±‚æ—¶é—´æˆ³åœ¨ä¸¤ä¸ªposeä¹‹é—´ï¼‰
                    can_interp_pc_start = UndistortionUtils.can_interpolate(
                        self.pose_metadata, pc_ts, MAX_POSE_GAP)
                    can_interp_pc_end = UndistortionUtils.can_interpolate(
                        self.pose_metadata, end_ts, MAX_POSE_GAP)
                    can_interp_img = UndistortionUtils.can_interpolate(
                        self.pose_metadata, img_ts, MAX_POSE_GAP)
                    
                    # æ–¹å¼2ï¼šæœ€è¿‘é‚»æ£€æŸ¥ï¼ˆå‚è€ƒC++ min_deltaé€»è¾‘ï¼‰
                    # åªè¦æœ‰è¶³å¤Ÿè¿‘çš„poseå°±å¯ä»¥ä½¿ç”¨
                    can_nearest_pc_start = UndistortionUtils.can_interpolate_nearest(
                        self.pose_metadata, pc_ts, MAX_POSE_DELTA)
                    can_nearest_pc_end = UndistortionUtils.can_interpolate_nearest(
                        self.pose_metadata, end_ts, MAX_POSE_DELTA)
                    can_nearest_img = UndistortionUtils.can_interpolate_nearest(
                        self.pose_metadata, img_ts, MAX_POSE_DELTA)
                    
                    # âœ… åªè¦æ»¡è¶³ä»»ä¸€æ–¹å¼å³å¯
                    can_process = (
                        (can_interp_pc_start and can_interp_pc_end and can_interp_img) or
                        (can_nearest_pc_start and can_nearest_pc_end and can_nearest_img)
                    )
                    
                    if can_process:
                        synced_pairs_filtered.append((img_idx, pc_idx))
                    else:
                        # åŒºåˆ†è·³è¿‡åŸå› 
                        if (pc_ts < pose_ts_min - MAX_POSE_DELTA or 
                            end_ts > pose_ts_max + MAX_POSE_DELTA or 
                            img_ts < pose_ts_min - MAX_POSE_DELTA or 
                            img_ts > pose_ts_max + MAX_POSE_DELTA):
                            skipped_reasons['no_pose_coverage'] += 1
                        else:
                            skipped_reasons['pose_too_far'] += 1
                        
                except Exception as e:
                    skipped_reasons['no_file'] += 1
                    continue
            
            if len(synced_pairs_filtered) < len(synced_pairs):
                print(f"\n  âš ï¸  è¿‡æ»¤æ— æ³•æ’å€¼çš„å¸§: {len(synced_pairs)} â†’ {len(synced_pairs_filtered)}")
                if skipped_reasons['no_file'] > 0:
                    print(f"      - æ–‡ä»¶ä¸å­˜åœ¨/è¯»å–å¤±è´¥: {skipped_reasons['no_file']}")
                if skipped_reasons['no_pose_coverage'] > 0:
                    print(f"      - è¶…å‡ºposeæ—¶é—´èŒƒå›´: {skipped_reasons['no_pose_coverage']}")
                if skipped_reasons['pose_too_far'] > 0:
                    print(f"      - æœ€è¿‘poseæ—¶é—´å·®>{MAX_POSE_DELTA*1000:.0f}ms: {skipped_reasons['pose_too_far']}")
                    print(f"        ğŸ’¡ æç¤º: è¿™äº›å¸§é™„è¿‘æ²¡æœ‰è¶³å¤Ÿè¿‘çš„poseæ•°æ®")
            else:
                print(f"    âœ“ æ‰€æœ‰ {len(synced_pairs)} å¸§éƒ½æœ‰poseè¦†ç›–")
            synced_pairs = synced_pairs_filtered
        
        # âœ… å¯é€‰ï¼šåŸºäºtarget_fpsè¿›è¡Œé™é‡‡æ ·ï¼ˆå¦‚æœåŒæ­¥å¸§æ•°è¿‡å¤šï¼‰
        if len(synced_pairs) > 0 and self.target_fps is not None:
            # è®¡ç®—åŸå§‹å¸§ç‡
            if len(synced_pairs) >= 2:
                first_img_idx, first_pc_idx = synced_pairs[0]
                last_img_idx, last_pc_idx = synced_pairs[-1]
                # æ—¶é—´è·¨åº¦ï¼ˆlast_idx >= first_idx æ€»æ˜¯æˆç«‹ï¼Œæ‰€ä»¥ä¸éœ€è¦absï¼‰
                time_span = (self.image_metadata[last_img_idx].timestamp - 
                            self.image_metadata[first_img_idx].timestamp)
                if time_span > 0:  # é˜²æ­¢é™¤é›¶ï¼ˆæç«¯æƒ…å†µï¼šæ‰€æœ‰å¸§æ—¶é—´æˆ³ç›¸åŒï¼‰
                    original_fps = (len(synced_pairs) - 1) / time_span
                    
                    # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°é™é‡‡æ ·åˆ¤æ–­çš„è¯¦ç»†ä¿¡æ¯
                    print(f"\n  é™é‡‡æ ·åˆ¤æ–­:")
                    print(f"    åŒæ­¥å¸§æ•°: {len(synced_pairs)}")
                    print(f"    æ—¶é—´è·¨åº¦: {time_span:.3f}s")
                    print(f"    åŸå§‹å¸§ç‡: {original_fps:.2f} fps")
                    print(f"    ç›®æ ‡å¸§ç‡: {self.target_fps:.1f} fps")
                    
                    # å¦‚æœåŸå§‹å¸§ç‡ > target_fpsï¼Œè¿›è¡Œé™é‡‡æ ·
                    if original_fps > self.target_fps:
                        target_interval = 1.0 / self.target_fps
                        downsampled_pairs = []
                        last_selected_time = -float('inf')
                        
                        for img_idx, pc_idx in synced_pairs:
                            current_time = self.image_metadata[img_idx].timestamp
                            if current_time - last_selected_time >= target_interval:
                                downsampled_pairs.append((img_idx, pc_idx))
                                last_selected_time = current_time
                        
                        if len(downsampled_pairs) < len(synced_pairs):
                            print(f"\n  ğŸ“‰ é™é‡‡æ ·: {len(synced_pairs)} â†’ {len(downsampled_pairs)} å¸§ (ç›®æ ‡: {self.target_fps:.1f} fps)")
                            synced_pairs = downsampled_pairs
                    else:
                        print(f"    âœ“ æ— éœ€é™é‡‡æ ·ï¼ˆåŸå§‹å¸§ç‡ <= ç›®æ ‡å¸§ç‡ï¼‰")
        
        # æ‰“å°åŒæ­¥ç»Ÿè®¡ï¼ˆå‚è€ƒC++ kMaxLidarCameraDeltaï¼‰
        print(f"\nåŒæ­¥ç»Ÿè®¡:")
        print(f"  æˆåŠŸé…å¯¹: {len(synced_pairs)} å¸§")
        if rejected_pairs > 0:
            print(f"  æ‹’ç»é…å¯¹: {rejected_pairs} å¯¹ï¼ˆlidar-cameraæ—¶é—´å·® > {self.max_time_diff*1000:.0f}msï¼‰")
            # æ‰“å°æ¯ä¸ªè¢«æ‹’ç»é…å¯¹çš„è¯¦ç»†ä¿¡æ¯
            for img_idx, pc_idx, delta_ms, exceed_ms in rejected_details[:10]:  # æœ€å¤šæ˜¾ç¤ºå‰10ä¸ª
                print(f"    - å›¾åƒ#{img_idx:04d} & ç‚¹äº‘#{pc_idx:04d}: Î”t={delta_ms:.1f}ms (è¶…å‡º{exceed_ms:.1f}ms)")
            if len(rejected_details) > 10:
                print(f"    ... è¿˜æœ‰ {len(rejected_details)-10} ä¸ªè¢«æ‹’ç»çš„é…å¯¹")
        
        # é™åˆ¶å¤„ç†å¸§æ•°ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        if self.max_frames is not None and len(synced_pairs) > self.max_frames:
            print(f"  âš ï¸  é™åˆ¶å¤„ç†å¸§æ•°: {len(synced_pairs)} â†’ {self.max_frames}")
            synced_pairs = synced_pairs[:self.max_frames]
        
        sync_time = time.time() - sync_start_time
        
        print(f"\nâœ“ åŒæ­¥å®Œæˆ:")
        print(f"  åŒæ­¥å¯¹æ•°: {len(synced_pairs)}")
        print(f"  è€—æ—¶: {timedelta(seconds=int(sync_time))}")
        print(f"  é€Ÿåº¦: {len(synced_pairs) / sync_time:.2f} å¯¹/ç§’")
        
        # ========================================================================
        # ä¿å­˜è°ƒè¯•æ ·æœ¬ï¼ˆæœªå»ç•¸å˜çš„ç‚¹äº‘ï¼Œç”¨äºå¯è§†åŒ–å¯¹æ¯”ï¼‰
        # ========================================================================
        if self.save_debug_samples > 0 and len(synced_pairs) > 0:
            debug_dir = seq_dir / 'debug_raw_pointclouds'
            debug_dir.mkdir(exist_ok=True)
            
            # å‡åŒ€é‡‡æ ·
            sample_interval = max(1, len(synced_pairs) // self.save_debug_samples)
            sample_indices = list(range(0, len(synced_pairs), sample_interval))[:self.save_debug_samples]
            
            print(f"\nğŸ“¸ ä¿å­˜è°ƒè¯•æ ·æœ¬ï¼ˆæœªå»ç•¸å˜ç‚¹äº‘ï¼‰:")
            print(f"  æ ·æœ¬æ•°é‡: {len(sample_indices)}")
            print(f"  é‡‡æ ·é—´éš”: æ¯ {sample_interval} å¸§")
            print(f"  ä¿å­˜ä½ç½®: {debug_dir}")
            
            for sample_idx, pair_idx in enumerate(tqdm(sample_indices, desc="  ä¿å­˜è°ƒè¯•æ ·æœ¬")):
                img_idx, pc_idx = synced_pairs[pair_idx]
                pc_meta = self.pc_metadata[pc_idx]
                
                # å¤åˆ¶åŸå§‹ç‚¹äº‘
                # âš ï¸ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ pair_idxï¼ˆå¸§ç´¢å¼•ï¼‰è€Œä¸æ˜¯ sample_idx ä½œä¸ºæ–‡ä»¶å
                # è¿™æ · debug_raw_pointclouds/000005_raw.bin ç›´æ¥å¯¹åº” velodyne/000005.bin
                src_path = Path(pc_meta.file_path)
                if src_path.exists():
                    dst_path = debug_dir / f"{pair_idx:06d}_raw.bin"  # ä½¿ç”¨ pair_idx
                    import shutil
                    shutil.copy2(src_path, dst_path)
                    
                    # åŒæ—¶ä¿å­˜å¯¹åº”çš„å›¾åƒ
                    img_meta = self.image_metadata[img_idx]
                    img_src = Path(img_meta.file_path)
                    if img_src.exists():
                        img_dst = debug_dir / f"{pair_idx:06d}_image.jpg"  # ä½¿ç”¨ pair_idx
                        shutil.copy2(img_src, img_dst)
            
            print(f"  âœ“ å·²ä¿å­˜ {len(sample_indices)} ä¸ªè°ƒè¯•æ ·æœ¬")
            print(f"  ğŸ’¡ æç¤º: å»ç•¸å˜åçš„ç‚¹äº‘å°†ä¿å­˜åœ¨ velodyne/ ç›®å½•")
            print(f"     å¯å¯¹æ¯” debug_raw_pointclouds/ å’Œ velodyne/ æŸ¥çœ‹å»ç•¸å˜æ•ˆæœ")
        
        # ä¿å­˜æœ€ç»ˆæ•°æ®é›†ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰
        print(f"\n{'='*80}")
        print(f"é˜¶æ®µ 3/3: å»ç•¸å˜å¹¶ä¿å­˜ (ä½¿ç”¨ {self.num_workers} ä¸ªçº¿ç¨‹)")
        print(f"{'='*80}")
        
        save_start_time = time.time()
        
        # âœ… ä¼˜åŒ–ï¼šç›´æ¥åœ¨ä¿å­˜æ—¶å¤„ç†å»ç•¸å˜ï¼Œè·³è¿‡é¢„éªŒè¯æ­¥éª¤
        # é¢„éªŒè¯å¤ªæ…¢ï¼Œæ”¹ä¸ºåœ¨ä¿å­˜æ—¶æ£€æµ‹å¹¶è·³è¿‡å¤±è´¥å¸§
        valid_pairs = synced_pairs  # ç›´æ¥ä½¿ç”¨æ‰€æœ‰é…å¯¹ï¼Œåœ¨ä¿å­˜æ—¶è¿‡æ»¤
        skipped_count = 0  # å°†åœ¨ä¿å­˜é˜¶æ®µç»Ÿè®¡
        
        # ä½¿ç”¨åŸå§‹é…å¯¹ï¼Œåœ¨ä¿å­˜æ—¶è¿‡æ»¤
        synced_pairs = valid_pairs
        
        # ä¿å­˜å¸§ï¼ˆå»ç•¸å˜å’Œä¿å­˜åˆå¹¶å¤„ç†ï¼‰
        print(f"\n  å»ç•¸å˜å¹¶ä¿å­˜...")
        
        # âœ… å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶å¹¶è¡Œåº¦ï¼Œé¿å…OOM
        # æ¯ä¸ªç‚¹äº‘çº¦ 200MB (100ä¸‡ç‚¹ * 5 * 4å­—èŠ‚ * 10å€å¤„ç†å¼€é”€)
        # 8ä¸ªå¹¶è¡Œ = 1.6GB å†…å­˜ä½¿ç”¨ï¼Œå®‰å…¨é˜ˆå€¼
        actual_workers = min(self.num_workers, 8)
        print(f"  ä½¿ç”¨ {actual_workers} ä¸ªå¹¶è¡Œå·¥ä½œçº¿ç¨‹ (å†…å­˜å®‰å…¨æ¨¡å¼)")
        
        # å‡†å¤‡ä»»åŠ¡ï¼ˆä½¿ç”¨ä¸´æ—¶ç´¢å¼•ï¼Œåç»­é‡æ–°ç¼–å·ï¼‰
        tasks = [
            (tmp_idx, img_idx, pc_idx, image_dir, velodyne_dir)
            for tmp_idx, (img_idx, pc_idx) in enumerate(synced_pairs)
        ]
        
        # âœ… å†…å­˜ä¼˜åŒ–ï¼šåˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹å¤„ç†åå¼ºåˆ¶GC
        import gc
        batch_size = 200  # æ¯æ‰¹200å¸§
        results = []
        
        for batch_start in range(0, len(tasks), batch_size):
            batch_end = min(batch_start + batch_size, len(tasks))
            batch_tasks = tasks[batch_start:batch_end]
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†å½“å‰æ‰¹æ¬¡
            with ThreadPoolExecutor(max_workers=actual_workers) as executor:
                futures = [executor.submit(self._process_single_frame, task) for task in batch_tasks]
                for future in tqdm(futures, desc=f"  æ‰¹æ¬¡ {batch_start//batch_size + 1}/{(len(tasks)-1)//batch_size + 1}", 
                                   total=len(batch_tasks), leave=False):
                    result = future.result()
                    results.append(result)
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è·³è¿‡çš„å¸§ï¼Œå¦‚æœæœ‰åˆ™éœ€è¦é‡æ–°ç¼–å·
        skipped_indices = [i for i, r in enumerate(results) if r is None or r is False]
        if skipped_indices:
            print(f"\n  é‡æ–°ç¼–å·ï¼ˆè·³è¿‡ {len(skipped_indices)} å¸§ï¼‰...")
            # æ”¶é›†æˆåŠŸçš„å¸§
            success_indices = [i for i, r in enumerate(results) if r is True]
            
            # âœ… ä¿®å¤ï¼šä½¿ç”¨ä¸´æ—¶ç›®å½•é¿å…æ–‡ä»¶è¦†ç›–é—®é¢˜
            import tempfile
            import shutil
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_rename_dir = self.temp_dir / 'rename_temp'
            temp_rename_dir.mkdir(exist_ok=True)
            temp_img_dir = temp_rename_dir / 'images'
            temp_pc_dir = temp_rename_dir / 'pointclouds'
            temp_img_dir.mkdir(exist_ok=True)
            temp_pc_dir.mkdir(exist_ok=True)
            
            # ç¬¬ä¸€æ­¥ï¼šå°†æˆåŠŸçš„å¸§ç§»åŠ¨åˆ°ä¸´æ—¶ç›®å½•å¹¶é‡æ–°ç¼–å·
            for new_idx, old_idx in enumerate(tqdm(success_indices, desc="  é‡ç¼–å·(1/2)")):
                old_img = image_dir / f"{old_idx:06d}.png"
                old_pc = velodyne_dir / f"{old_idx:06d}.bin"
                new_img = temp_img_dir / f"{new_idx:06d}.png"
                new_pc = temp_pc_dir / f"{new_idx:06d}.bin"
                
                if old_img.exists():
                    shutil.move(str(old_img), str(new_img))
                if old_pc.exists():
                    shutil.move(str(old_pc), str(new_pc))
            
            # ç¬¬äºŒæ­¥ï¼šæ¸…ç©ºåŸç›®å½•ä¸­çš„æ®‹ç•™æ–‡ä»¶
            for f in image_dir.glob('*.png'):
                f.unlink()
            for f in velodyne_dir.glob('*.bin'):
                f.unlink()
            
            # ç¬¬ä¸‰æ­¥ï¼šå°†é‡æ–°ç¼–å·çš„æ–‡ä»¶ç§»å›åŸç›®å½•
            for f in tqdm(list(temp_img_dir.glob('*.png')), desc="  é‡ç¼–å·(2/2)", leave=False):
                shutil.move(str(f), str(image_dir / f.name))
            for f in temp_pc_dir.glob('*.bin'):
                shutil.move(str(f), str(velodyne_dir / f.name))
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            shutil.rmtree(str(temp_rename_dir))
            
            # æ›´æ–° synced_pairs ä¸ºåªåŒ…å«æˆåŠŸçš„å¸§
            synced_pairs = [synced_pairs[i] for i in success_indices]
            
            print(f"  âœ“ é‡æ–°ç¼–å·å®Œæˆ: {len(success_indices)} å¸§")
        
        save_time = time.time() - save_start_time
        
        # ç»Ÿè®¡ç»“æœ
        success_count = sum(1 for r in results if r is True)
        failed_count = sum(1 for r in results if r is False)
        skipped_in_save = sum(1 for r in results if r is None)
        
        print(f"\nâœ“ å»ç•¸å˜å’Œä¿å­˜å®Œæˆ:")
        print(f"  æˆåŠŸ: {success_count} å¸§")
        if failed_count > 0:
            print(f"  æ ¼å¼é”™è¯¯: {failed_count} å¸§")
        if skipped_in_save > 0:
            print(f"  å»ç•¸å˜å¤±è´¥è·³è¿‡: {skipped_in_save} å¸§")
        print(f"  è€—æ—¶: {timedelta(seconds=int(save_time))}")
        if len(results) > 0:
            print(f"  é€Ÿåº¦: {len(results) / save_time:.2f} å¸§/ç§’")
            print(f"  å¹³å‡: {save_time / len(results):.2f} ç§’/å¸§")
        
        # ä¿å­˜æ ‡å®šæ–‡ä»¶
        self._save_calib_file(seq_dir)
        
        # ä¿å­˜ä½å§¿æ–‡ä»¶
        if self.pose_metadata:
            self._save_poses_file(synced_pairs, sequence_id)
        else:
            print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°ä½å§¿æ•°æ®ï¼Œè·³è¿‡ poses æ–‡ä»¶ç”Ÿæˆ")
        
        # ä¿å­˜æ—¶é—´æˆ³æ–‡ä»¶
        self._save_times_file(synced_pairs, seq_dir)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        # æ³¨æ„ï¼šå¦‚æœéœ€è¦éªŒè¯å»ç•¸å˜æ•ˆæœï¼Œè¯·ä¿ç•™tempç›®å½•
        # temp/pointclouds/ ä¸­å­˜å‚¨çš„æ˜¯å»ç•¸å˜å‰çš„åŸå§‹ç‚¹äº‘
        print(f"\nğŸ’¡ æç¤º: tempç›®å½•åŒ…å«å»ç•¸å˜å‰çš„åŸå§‹ç‚¹äº‘")
        print(f"   ä½ç½®: {self.temp_dir}")
        print(f"   å¦‚æœéœ€è¦éªŒè¯å»ç•¸å˜æ•ˆæœï¼Œè¯·ä¿ç•™æ­¤ç›®å½•")
        print(f"   å¦‚æœä¸éœ€è¦ï¼Œå¯ä»¥æ‰‹åŠ¨åˆ é™¤ä»¥èŠ‚çœç©ºé—´")
        # import shutil
        # shutil.rmtree(self.temp_dir)  # æ³¨é‡Šæ‰è‡ªåŠ¨åˆ é™¤
        
        # è®¡ç®—æ€»è€—æ—¶
        total_time = getattr(self, '_extract_time', 0) + sync_time + save_time
        
        print(f"\n{'='*80}")
        print(f"æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
        print(f"{'='*80}")
        print(f"\nğŸ“ è¾“å‡ºä½ç½®:")
        print(f"  æ•°æ®é›†: {seq_dir}")
        print(f"  ä¸´æ—¶æ–‡ä»¶: {self.temp_dir} (å·²ä¿ç•™)")
        
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æœ‰æ•ˆå›¾åƒ: {success_count} å¼ ")
        print(f"  æœ‰æ•ˆç‚¹äº‘: {success_count} å¸§")
        if skipped_count > 0:
            print(f"  å»ç•¸å˜å¤±è´¥è·³è¿‡: {skipped_count} å¸§ (ä¸ä¿å­˜)")
        if self.pose_metadata:
            print(f"  ä½å§¿: {len(self.pose_metadata)} ä¸ª")
        
        print(f"\nâ±ï¸  è€—æ—¶ç»Ÿè®¡:")
        if hasattr(self, '_extract_time'):
            print(f"  1. æ•°æ®æå–: {timedelta(seconds=int(self._extract_time))} ({self._extract_time/total_time*100:.1f}%)")
        print(f"  2. æ•°æ®åŒæ­¥: {timedelta(seconds=int(sync_time))} ({sync_time/total_time*100:.1f}%)")
        print(f"  3. å»ç•¸å˜ä¿å­˜: {timedelta(seconds=int(save_time))} ({save_time/total_time*100:.1f}%)")
        print(f"  {'â”€'*40}")
        print(f"  æ€»è®¡: {timedelta(seconds=int(total_time))}")
        print(f"  å¹³å‡é€Ÿåº¦: {len(synced_pairs) / total_time:.2f} å¸§/ç§’")
        
        print(f"\nğŸš€ æ€§èƒ½æŒ‡æ ‡:")
        print(f"  çº¿ç¨‹æ•°: {self.num_workers}")
        print(f"  æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        if hasattr(self, '_extract_time') and len(synced_pairs) > 0:
            print(f"  æå–æ•ˆç‡: {len(self.image_metadata) / self._extract_time:.2f} å¸§/ç§’")
        print(f"  ä¿å­˜æ•ˆç‡: {len(synced_pairs) / save_time:.2f} å¸§/ç§’")
    
    def _save_calib_file(self, seq_dir: Path):
        """ä¿å­˜æ ‡å®šæ–‡ä»¶ï¼ˆç¬¦åˆKITTIæ ‡å‡†æ ¼å¼ï¼‰
        
        å‚è€ƒï¼š
        - KITTI Odometry æ•°æ®é›†æ ¼å¼è§„èŒƒ
        - åæ ‡ç³»æ–‡æ¡£ï¼šP_A = T^A_B * P_B
        
        **KITTIæ ‡å‡†æ ¼å¼**ï¼š
        - ç‚¹äº‘åœ¨Sensingç³»ï¼ˆå»ç•¸å˜åï¼‰
        - TrçŸ©é˜µï¼š**Camera â†’ Sensing**ï¼ˆä»ç›¸æœºæŒ‡å‘ä¼ æ„Ÿå™¨çš„å˜æ¢ï¼‰
        
        **åæ ‡å˜æ¢é“¾**ï¼š
        - ç‚¹äº‘åœ¨Sensingç³»ï¼šP_sensingï¼ˆå»ç•¸å˜åï¼‰
        - KITTIçš„Træ˜¯åå‘å˜æ¢ï¼šTr = Camera â†’ Sensing
        - ä½¿ç”¨æ—¶éœ€è¦å–é€†ï¼šP_camera = inv(Tr) * P_sensing
        - æŠ•å½±åˆ°å›¾åƒï¼šp = K * P_cameraï¼ˆP_camera.z > 0æ—¶å¯è§ï¼‰
        
        **é‡è¦**ï¼š
        - ä¸ºäº†ä¸KITTIæ ‡å‡†æ ¼å¼å…¼å®¹ï¼Œè¿™é‡Œå†™å…¥ Cameraâ†’Sensingï¼ˆTrçš„é€†çŸ©é˜µï¼‰
        - è¿™æ · kitti_dataset.py å’Œ custom_dataset.py å¯ä»¥ä½¿ç”¨ç›¸åŒçš„åŠ è½½é€»è¾‘
        """
        calib_path = seq_dir / 'calib.txt'
        
        # P2: å·¦ä¾§å½©è‰²ç›¸æœºçš„æŠ•å½±çŸ©é˜µ (3x4)
        P2 = np.zeros((3, 4))
        P2[:3, :3] = self.K
        
        # Tr: Cameraåˆ°Sensingçš„å˜æ¢çŸ©é˜µï¼ˆCamera â†’ Sensingï¼‰ç¬¦åˆKITTIæ ‡å‡†
        # self.T_camera_to_sensing æ˜¯ Sensingâ†’Cameraï¼Œéœ€è¦å–é€†å¾—åˆ° Cameraâ†’Sensing
        T_sensing_to_cam = np.linalg.inv(self.T_camera_to_sensing)  # Camera â†’ Sensing (KITTIæ ‡å‡†)
        Tr_3x4 = T_sensing_to_cam[:3, :]  # åªå–å‰3è¡Œï¼ˆKITTIæ ‡å‡†ï¼š3x4çŸ©é˜µï¼‰
        
        # D: ç•¸å˜ç³»æ•°ï¼ˆå‚è€ƒC++å®ç°ï¼ŒæŠ•å½±æ—¶éœ€è¦ï¼‰
        # æ”¯æŒä¸¤ç§æ¨¡å‹ï¼š
        # 1. pinhole: k1, k2, p1, p2, k3 (OpenCVæ ‡å‡†ï¼Œ5ä¸ªå‚æ•°)
        # 2. fisheye: k1, k2, k3, k4 (KANNALA_BRANDTé±¼çœ¼æ¨¡å‹ï¼Œ4ä¸ªå‚æ•°)
        distortion = self.camera_config.get('distortion', {})
        model_type = distortion.get('model_type', 'pinhole')
        
        if model_type == 'fisheye':
            # é±¼çœ¼æ¨¡å‹ï¼šk1, k2, k3, k4ï¼ˆæ— åˆ‡å‘ç•¸å˜ï¼‰
            D = np.array([
                distortion.get('k1', 0.0),
                distortion.get('k2', 0.0),
                distortion.get('k3', 0.0),
                distortion.get('k4', 0.0)
            ])
        else:
            # Pinholeæ¨¡å‹ï¼šk1, k2, p1, p2, k3
            D = np.array([
                distortion.get('k1', 0.0),
                distortion.get('k2', 0.0),
                distortion.get('p1', 0.0),
                distortion.get('p2', 0.0),
                distortion.get('k3', 0.0)
            ])
        
        with open(calib_path, 'w') as f:
            # å®Œæ•´çš„KITTIæ ¼å¼åŒ…å«P0-P3ï¼Œä½†BEVCalibåªéœ€è¦P2
            # ä¸ºäº†å…¼å®¹æ€§ï¼Œæˆ‘ä»¬ä¹Ÿå†™å…¥P0, P1, P3ï¼ˆä½¿ç”¨ç›¸åŒçš„P2ï¼‰
            for i in range(4):
                f.write(f"P{i}: ")
                f.write(" ".join([f"{val:.12e}" for val in P2.flatten()]))
                f.write("\n")
            
            # Tr: 3x4çŸ©é˜µï¼ˆ12ä¸ªæ•°ï¼‰- Camera â†’ Sensing (KITTIæ ‡å‡†æ ¼å¼)
            f.write("Tr: ")
            f.write(" ".join([f"{val:.12e}" for val in Tr_3x4.flatten()]))
            f.write("\n")
            
            # D: ç•¸å˜ç³»æ•°
            # pinholeæ¨¡å‹ï¼šk1, k2, p1, p2, k3 (5ä¸ªå‚æ•°)
            # fisheyeæ¨¡å‹ï¼šk1, k2, k3, k4 (4ä¸ªå‚æ•°)
            # C++å‚è€ƒï¼šlidar_cam_fusion_manualéœ€è¦ç•¸å˜ç³»æ•°è¿›è¡Œå»ç•¸å˜
            f.write("D: ")
            f.write(" ".join([f"{val:.12e}" for val in D]))
            f.write("\n")
            
            # ä¿å­˜ç›¸æœºæ¨¡å‹ç±»å‹ï¼ˆç”¨äºæŠ•å½±æ—¶é€‰æ‹©æ­£ç¡®çš„å»ç•¸å˜æ–¹æ³•ï¼‰
            f.write(f"camera_model: {model_type}\n")
        
        print(f"æ ‡å®šæ–‡ä»¶å·²ä¿å­˜: {calib_path} (KITTIæ ‡å‡†æ ¼å¼ + ç•¸å˜ç³»æ•°)")
        print(f"  âœ“ ç‚¹äº‘åæ ‡ç³»: Sensingç³»")
        print(f"  âœ“ æŠ•å½±å˜æ¢: Tr (Cameraâ†’Sensing, KITTIæ ‡å‡†)")
        
        # æ ¹æ®æ¨¡å‹ç±»å‹æ‰“å°ç•¸å˜ç³»æ•°
        if model_type == 'fisheye':
            print(f"  âœ“ ç•¸å˜æ¨¡å‹: {model_type} (KANNALA_BRANDT)")
            print(f"  âœ“ ç•¸å˜ç³»æ•°: D (k1={D[0]:.6f}, k2={D[1]:.6f}, k3={D[2]:.6f}, k4={D[3]:.6f})")
        else:
            print(f"  âœ“ ç•¸å˜æ¨¡å‹: {model_type}")
            print(f"  âœ“ ç•¸å˜ç³»æ•°: D (k1={D[0]:.6f}, k2={D[1]:.6f}, p1={D[2]:.6f}, p2={D[3]:.6f}, k3={D[4]:.6f})")
    
    def _save_poses_file(self, synced_pairs: List[Tuple[int, int]], sequence_id: str):
        """ä¿å­˜ä½å§¿æ–‡ä»¶ï¼ˆKITTI-Odometry æ ¼å¼ï¼‰
        
        KITTIæ ¼å¼è¦æ±‚ï¼š
        1. æ¯è¡Œæ˜¯ä»ç¬¬iå¸§åˆ°ç¬¬0å¸§çš„å˜æ¢çŸ©é˜µ T_0_to_i
        2. P_0 = T_0_to_i @ P_i ï¼ˆå°†ç¬¬iå¸§çš„ç‚¹æŠ•å½±åˆ°ç¬¬0å¸§ï¼‰
        3. ä½¿ç”¨çº¿æ€§æ’å€¼è·å¾—å›¾åƒæ—¶åˆ»çš„ç²¾ç¡®ä½å§¿
        """
        poses_dir = self.output_dir / 'poses'
        poses_dir.mkdir(exist_ok=True)
        poses_file = poses_dir / f'{sequence_id}.txt'
        
        print(f"ç”Ÿæˆä½å§¿æ–‡ä»¶...")
        
        # âœ… å¤ç”¨å·²æœ‰çš„æ’å€¼/å¤–æ¨å®ç°
        # 1. ä¼˜å…ˆä½¿ç”¨ motion_interpolateï¼ˆæä»£æ•°æ’å€¼ï¼‰
        # 2. æ’å€¼å¤±è´¥æ—¶ä½¿ç”¨ motion_extrapolateï¼ˆå¤–æ¨ï¼‰
        # 3. éƒ½å¤±è´¥æ—¶ä½¿ç”¨æœ€è¿‘é‚»ï¼ˆæç«¯æƒ…å†µï¼‰
        poses_world = []
        interpolated_count = 0
        extrapolated_count = 0
        nearest_count = 0
        
        for idx, (img_idx, _) in enumerate(synced_pairs):
            img_ts = self.image_metadata[img_idx].timestamp
            
            # ä½¿ç”¨å·²æœ‰çš„motion_interpolateæ–¹æ³•ï¼ˆä¸¥æ ¼å‚è€ƒC++å®ç°ï¼‰
            result = UndistortionUtils.motion_interpolate(self.pose_metadata, img_ts)
            
            if result is not None:
                # æ’å€¼æˆåŠŸ
                R_mat, t_vec = result
                T_world = np.eye(4)
                T_world[:3, :3] = R_mat
                T_world[:3, 3] = t_vec
                poses_world.append(T_world)
                interpolated_count += 1
            else:
                # æ’å€¼å¤±è´¥ï¼ˆæ—¶é—´æˆ³è¶…å‡ºèŒƒå›´ï¼‰ï¼Œå°è¯•å¤–æ¨
                result_extrap = UndistortionUtils.motion_extrapolate(self.pose_metadata, img_ts)
                
                if result_extrap is not None:
                    # å¤–æ¨æˆåŠŸ
                    R_mat, t_vec = result_extrap
                    T_world = np.eye(4)
                    T_world[:3, :3] = R_mat
                    T_world[:3, 3] = t_vec
                    poses_world.append(T_world)
                    extrapolated_count += 1
                else:
                    # å¤–æ¨ä¹Ÿå¤±è´¥ï¼ˆæç«¯æƒ…å†µï¼šposeæ•°é‡<2ï¼‰ï¼Œä½¿ç”¨æœ€è¿‘é‚»
                    best_pose = None
                    best_diff = float('inf')
                    for pose in self.pose_metadata:
                        diff = abs(pose.timestamp - img_ts)
                        if diff < best_diff:
                            best_diff = diff
                            best_pose = pose
                    
                    if best_pose is not None:
                        T_world = np.eye(4)
                        T_world[:3, :3] = R.from_quat(best_pose.orientation).as_matrix()
                        T_world[:3, 3] = best_pose.position
                        poses_world.append(T_world)
                        nearest_count += 1
                    else:
                        # æ²¡æœ‰ä»»ä½•poseï¼Œä½¿ç”¨å•ä½çŸ©é˜µæˆ–ä¸Šä¸€å¸§
                        if poses_world:
                            poses_world.append(poses_world[-1].copy())
                        else:
                            poses_world.append(np.eye(4))
        
        # âœ… ä¿®å¤2ï¼šè½¬æ¢ä¸ºç›¸å¯¹äºç¬¬0å¸§çš„ä½å§¿
        # KITTIæ ¼å¼ï¼šT_0_to_i = inv(T_0_to_world) @ T_i_to_world
        # 
        # C++å‘½åçº¦å®šï¼ˆä»å³å¾€å·¦è¯»ï¼‰ï¼š
        #   T_0_to_world = ç¬¬0å¸§â†’Worldï¼ˆç¬¬0å¸§åœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
        #   T_i_to_world = ç¬¬iå¸§â†’Worldï¼ˆç¬¬iå¸§åœ¨Worldç³»ä¸­çš„ä½å§¿ï¼‰
        #   T_world_to_0 = inv(T_0_to_world) = Worldâ†’ç¬¬0å¸§
        #   T_0_to_i = Worldâ†’ç¬¬0å¸§ @ ç¬¬iå¸§â†’World = ç¬¬iå¸§â†’ç¬¬0å¸§
        if len(poses_world) == 0:
            print("è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„ä½å§¿æ•°æ®")
            return
        
        T_0_to_world = poses_world[0]  # ç¬¬0å¸§â†’Worldï¼ˆC++å‘½åçº¦å®šï¼‰
        T_world_to_0 = np.linalg.inv(T_0_to_world)  # Worldâ†’ç¬¬0å¸§
        
        poses_relative = []
        for T_i_to_world in poses_world:  # ç¬¬iå¸§â†’World
            # ä»ç¬¬iå¸§åˆ°ç¬¬0å¸§çš„å˜æ¢
            T_0_to_i = T_world_to_0 @ T_i_to_world  # ç¬¬iå¸§â†’ç¬¬0å¸§
            poses_relative.append(T_0_to_i)
        
        # å†™å…¥æ–‡ä»¶ï¼ˆKITTI æ ¼å¼ï¼šæ¯è¡Œ12ä¸ªæ•°ï¼Œä»£è¡¨ 3x4 å˜æ¢çŸ©é˜µï¼‰
        with open(poses_file, 'w') as f:
            for T in poses_relative:
                # åªä¿å­˜å‰3è¡Œï¼ˆ3x4 çŸ©é˜µï¼‰
                pose_line = T[:3, :].flatten()
                f.write(' '.join([f"{val:.12e}" for val in pose_line]))
                f.write('\n')
        
        print(f"ä½å§¿æ–‡ä»¶å·²ä¿å­˜: {poses_file}")
        print(f"  æ€»å¸§æ•°: {len(poses_relative)}")
        print(f"  æ’å€¼å¸§æ•°: {interpolated_count} (æä»£æ•°æ’å€¼)")
        if extrapolated_count > 0:
            print(f"  å¤–æ¨å¸§æ•°: {extrapolated_count} (æä»£æ•°å¤–æ¨)")
        if nearest_count > 0:
            print(f"  æœ€è¿‘é‚»: {nearest_count}")
        
        # éªŒè¯ç¬¬0å¸§åº”è¯¥æ˜¯å•ä½çŸ©é˜µ
        if not np.allclose(poses_relative[0], np.eye(4), atol=1e-6):
            print(f"  âš ï¸  è­¦å‘Š: ç¬¬0å¸§ä½å§¿ä¸æ˜¯å•ä½çŸ©é˜µï¼ˆé¢„æœŸè¡Œä¸ºï¼‰")
        else:
            print(f"  âœ“ ç¬¬0å¸§ä½å§¿ä¸ºå•ä½çŸ©é˜µï¼ˆå‚è€ƒåæ ‡ç³»ï¼‰")
    
    def _save_times_file(self, synced_pairs: List[Tuple[int, int]], seq_dir: Path):
        """ä¿å­˜æ—¶é—´æˆ³æ–‡ä»¶ï¼ˆKITTI-Odometry æ ¼å¼ï¼‰
        
        KITTIæ ¼å¼è¦æ±‚ï¼š
        1. æ¯è¡Œä¸€ä¸ªæµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºè¯¥å¸§çš„æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
        2. æ—¶é—´æˆ³ç›¸å¯¹äºç¬¬ä¸€å¸§ï¼ˆç¬¬0å¸§æ—¶é—´æˆ³ä¸º0ï¼‰
        3. é«˜ç²¾åº¦æµ®ç‚¹æ•°æ ¼å¼ï¼ˆä¿ç•™è¶³å¤Ÿç²¾åº¦ï¼‰
        
        times.txt æŠ€æœ¯ç‰¹ç‚¹ï¼š
        - ç¡®ä¿ä¸åŒä¼ æ„Ÿå™¨æ•°æ®ä¹‹é—´çš„æ—¶é—´åŒæ­¥
        - ç”¨äºè½¨è¿¹æ’å€¼å’Œè¿åŠ¨è¡¥å¿
        - æ”¯æŒæ—¶åºæ•°æ®çš„ç²¾ç¡®å¯¹é½
        """
        times_file = seq_dir / 'times.txt'
        
        print(f"\nç”Ÿæˆæ—¶é—´æˆ³æ–‡ä»¶...")
        
        if not synced_pairs:
            print("  âš ï¸  è­¦å‘Š: æ²¡æœ‰åŒæ­¥çš„å¸§ï¼Œè·³è¿‡ times.txt ç”Ÿæˆ")
            return
        
        # æå–æ‰€æœ‰å›¾åƒçš„æ—¶é—´æˆ³
        timestamps = []
        for img_idx, _ in synced_pairs:
            img_ts = self.image_metadata[img_idx].timestamp
            timestamps.append(img_ts)
        
        # è½¬æ¢ä¸ºç›¸å¯¹ç¬¬ä¸€å¸§çš„æ—¶é—´ï¼ˆKITTIæ ¼å¼ï¼‰
        first_timestamp = timestamps[0]
        relative_timestamps = [ts - first_timestamp for ts in timestamps]
        
        # å†™å…¥æ–‡ä»¶
        with open(times_file, 'w') as f:
            for ts in relative_timestamps:
                # ä½¿ç”¨è¶³å¤Ÿçš„ç²¾åº¦ï¼ˆ6ä½å°æ•°ï¼Œè¶³ä»¥è¡¨ç¤ºæ¯«ç§’çº§ç²¾åº¦ï¼‰
                f.write(f"{ts:.6f}\n")
        
        print(f"æ—¶é—´æˆ³æ–‡ä»¶å·²ä¿å­˜: {times_file}")
        print(f"  æ€»å¸§æ•°: {len(relative_timestamps)}")
        print(f"  æ—¶é—´èŒƒå›´: {relative_timestamps[0]:.3f}s ~ {relative_timestamps[-1]:.3f}s")
        print(f"  æ€»æ—¶é•¿: {relative_timestamps[-1]:.3f}s")
        
        # è®¡ç®—å¹³å‡å¸§ç‡
        if len(relative_timestamps) > 1:
            total_duration = relative_timestamps[-1] - relative_timestamps[0]
            if total_duration > 0:
                avg_fps = (len(relative_timestamps) - 1) / total_duration
                print(f"  å¹³å‡å¸§ç‡: {avg_fps:.2f} fps")
        
        # éªŒè¯ç¬¬0å¸§æ—¶é—´æˆ³åº”è¯¥æ˜¯0
        if abs(relative_timestamps[0]) > 1e-9:
            print(f"  âš ï¸  è­¦å‘Š: ç¬¬0å¸§æ—¶é—´æˆ³ä¸æ˜¯0 ({relative_timestamps[0]:.9f})")
        else:
            print(f"  âœ“ ç¬¬0å¸§æ—¶é—´æˆ³ä¸º0ï¼ˆå‚è€ƒæ—¶åˆ»ï¼‰")


def main():
    parser = argparse.ArgumentParser(description='å‡†å¤‡ BEVCalib æ•°æ®é›†ï¼ˆæµå¼å¤„ç†ï¼‰')
    parser.add_argument('--bag_dir', type=str, required=True)
    parser.add_argument('--config_dir', type=str, required=True)
    parser.add_argument('--output_dir', type=str, required=True)
    parser.add_argument('--camera_name', type=str, default='traffic_2')
    parser.add_argument('--target_fps', type=float, default=10.0)
    parser.add_argument('--max_time_diff', type=float, default=0.055,
                       help='æœ€å¤§æ—¶é—´å·®é˜ˆå€¼ï¼ˆç§’ï¼‰ã€‚å‚è€ƒC++: kMaxLidarCameraDelta=55msã€‚'
                            'è¶…è¿‡æ­¤é˜ˆå€¼çš„lidar-å›¾åƒå¯¹å°†è¢«ä¸¢å¼ƒã€‚')
    parser.add_argument('--lidar_topic', type=str,
                       default='/sensors/lidar/combined_point_cloud_proto')
    parser.add_argument('--pose_topic', type=str,
                       default="/localization/pose",
                       help='ä½å§¿ topicï¼ˆé»˜è®¤: /localization/poseï¼‰')
    parser.add_argument('--sequence_id', type=str, default='00')
    parser.add_argument('--batch_size', type=int, default=500,
                       help='æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤: 500ï¼Œå¢å¤§å¯æå‡é€Ÿåº¦ï¼‰')
    parser.add_argument('--num_workers', type=int, default=4,
                       help='å¹¶è¡Œå¤„ç†çš„çº¿ç¨‹æ•°ï¼ˆé»˜è®¤: 4ï¼‰')
    parser.add_argument('--max_frames', type=int, default=None,
                       help='æœ€å¤§å¤„ç†å¸§æ•°ï¼Œç”¨äºæµ‹è¯•ï¼ˆé»˜è®¤: Noneï¼Œå¤„ç†æ‰€æœ‰å¸§ï¼‰')
    parser.add_argument('--save_debug_samples', type=int, default=0,
                       help='ä¿å­˜ç”¨äºè°ƒè¯•çš„æœªå»ç•¸å˜ç‚¹äº‘æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤: 0ï¼Œä¸ä¿å­˜ï¼‰ã€‚'
                            'è®¾ç½®ä¸º10-20å¯ä¿å­˜å‡åŒ€é‡‡æ ·çš„æ ·æœ¬ç”¨äºå¯è§†åŒ–å¯¹æ¯”ã€‚')
    parser.add_argument('--max_pose_gap', type=float, default=0.5,
                       help='æœ€å¤§å…è®¸çš„poseé—´éš”ï¼ˆç§’ï¼‰ã€‚ç”¨äºå¤„ç†ä¸è¿ç»­çš„bagæ•°æ®ã€‚'
                            'è¶…è¿‡æ­¤é—´éš”çš„æ—¶é—´æ®µå°†è¢«è®¤ä¸ºæ•°æ®ä¸è¿ç»­ï¼Œç›¸å…³å¸§ä¼šè¢«è·³è¿‡ã€‚'
                            'å¯¹äºè¿ç»­æ•°æ®ï¼Œé»˜è®¤0.5ç§’è¶³å¤Ÿï¼›å¯¹äºä¸è¿ç»­æ•°æ®ï¼Œå¯é€‚å½“å¢å¤§ã€‚')
    args = parser.parse_args()
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print(f"\n{'='*80}")
    print(f"BEVCalib æ•°æ®é›†ç”Ÿæˆå·¥å…·")
    print(f"{'='*80}")
    print(f"\nâš™ï¸  é…ç½®:")
    print(f"  Bagç›®å½•: {args.bag_dir}")
    print(f"  é…ç½®ç›®å½•: {args.config_dir}")
    print(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"  ç›¸æœº: {args.camera_name}")
    print(f"  ç›®æ ‡å¸§ç‡: {args.target_fps} fps")
    print(f"  æ‰¹æ¬¡å¤§å°: {args.batch_size}")
    print(f"  çº¿ç¨‹æ•°: {args.num_workers}")
    print(f"  æœ€å¤§poseé—´éš”: {args.max_pose_gap}sï¼ˆç”¨äºå¤„ç†ä¸è¿ç»­bagæ•°æ®ï¼‰")
    
    total_start_time = time.time()
    
    preparer = BEVCalibDatasetPreparer(
        bag_path=args.bag_dir,
        config_dir=args.config_dir,
        output_dir=args.output_dir,
        camera_name=args.camera_name,
        target_fps=args.target_fps,
        max_time_diff=args.max_time_diff,
        lidar_topic=args.lidar_topic,
        pose_topic=args.pose_topic,
        batch_size=args.batch_size,
        num_workers=args.num_workers,
        max_frames=args.max_frames,
        save_debug_samples=args.save_debug_samples,
        max_pose_gap=args.max_pose_gap,
    )
    
    preparer.extract_data_from_bag()
    preparer.sync_and_save(sequence_id=args.sequence_id)
    
    total_time = time.time() - total_start_time
    
    print(f"\n{'='*80}")
    print(f"âœ“ å…¨éƒ¨å®Œæˆï¼")
    print(f"{'='*80}")
    print(f"\næ€»ç”¨æ—¶: {timedelta(seconds=int(total_time))}")
    print(f"\nğŸ“š ä¸‹ä¸€æ­¥:")
    print(f"  1. éªŒè¯æ•°æ®é›†:")
    print(f"     python validate_kitti_odometry.py --dataset_root {args.output_dir}")
    print(f"\n  2. å¯è§†åŒ–å»ç•¸å˜æ•ˆæœ:")
    print(f"     python visualize_undistortion.py {args.output_dir} --frame 0")
    print(f"\n  4. å¼€å§‹è®­ç»ƒ:")
    print(f"     python kitti-bev-calib/train_kitti.py --dataset_root {args.output_dir}")
    print(f"\n{'='*80}\n")


if __name__ == '__main__':
    main()
