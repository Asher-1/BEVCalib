#!/usr/bin/env python3
"""
éªŒè¯æ•°æ®é›†æ˜¯å¦ç¬¦åˆ KITTI-Odometry æ ‡å‡†æ ¼å¼
"""

import numpy as np
from pathlib import Path
import argparse


class KITTIOdometryValidator:
    """KITTI-Odometry æ ¼å¼éªŒè¯å™¨"""
    
    def __init__(self, dataset_root: str):
        self.dataset_root = Path(dataset_root)
        self.errors = []
        self.warnings = []
        self.passed = []
    
    def validate(self, sequence_id: str = "00"):
        """éªŒè¯æ•°æ®é›†"""
        print(f"ğŸ” éªŒè¯ KITTI-Odometry æ•°æ®é›†: {self.dataset_root}")
        print(f"   åºåˆ—: {sequence_id}\n")
        
        # 1. éªŒè¯ç›®å½•ç»“æ„
        self._validate_directory_structure(sequence_id)
        
        # 2. éªŒè¯ calib.txt
        self._validate_calib(sequence_id)
        
        # 3. éªŒè¯ poses æ–‡ä»¶
        self._validate_poses(sequence_id)
        
        # 4. éªŒè¯å›¾åƒæ–‡ä»¶
        self._validate_images(sequence_id)
        
        # 5. éªŒè¯ç‚¹äº‘æ–‡ä»¶
        self._validate_velodyne(sequence_id)
        
        # 6. éªŒè¯æ•°æ®å¯¹é½
        self._validate_alignment(sequence_id)
        
        # è¾“å‡ºæŠ¥å‘Š
        self._print_report()
    
    def _validate_directory_structure(self, sequence_id: str):
        """éªŒè¯ç›®å½•ç»“æ„"""
        seq_dir = self.dataset_root / 'sequences' / sequence_id
        
        if not seq_dir.exists():
            self.errors.append(f"âŒ åºåˆ—ç›®å½•ä¸å­˜åœ¨: {seq_dir}")
            return
        self.passed.append(f"âœ“ åºåˆ—ç›®å½•å­˜åœ¨: sequences/{sequence_id}/")
        
        # æ£€æŸ¥å¿…éœ€çš„å­ç›®å½•
        required_dirs = ['image_2', 'velodyne']
        for dir_name in required_dirs:
            dir_path = seq_dir / dir_name
            if not dir_path.exists():
                self.errors.append(f"âŒ ç¼ºå°‘ç›®å½•: sequences/{sequence_id}/{dir_name}/")
            else:
                self.passed.append(f"âœ“ ç›®å½•å­˜åœ¨: sequences/{sequence_id}/{dir_name}/")
        
        # æ£€æŸ¥ calib.txt
        calib_file = seq_dir / 'calib.txt'
        if not calib_file.exists():
            self.errors.append(f"âŒ ç¼ºå°‘æ–‡ä»¶: sequences/{sequence_id}/calib.txt")
        else:
            self.passed.append(f"âœ“ æ–‡ä»¶å­˜åœ¨: sequences/{sequence_id}/calib.txt")
    
    def _validate_calib(self, sequence_id: str):
        """éªŒè¯ calib.txt æ ¼å¼"""
        calib_file = self.dataset_root / 'sequences' / sequence_id / 'calib.txt'
        
        if not calib_file.exists():
            return
        
        with open(calib_file, 'r') as f:
            lines = f.readlines()
        
        # è§£æ calib.txt
        calib_data = {}
        for line in lines:
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if len(parts) < 2:
                continue
            
            key = parts[0].rstrip(':')
            
            # è·³è¿‡éæ•°å€¼è¡Œï¼ˆå¦‚ camera_model: pinholeï¼‰
            try:
                values = [float(v) for v in parts[1:]]
                calib_data[key] = values
            except ValueError:
                # è·³è¿‡æ— æ³•è½¬æ¢ä¸ºæµ®ç‚¹æ•°çš„è¡Œ
                continue
        
        # éªŒè¯ P0-P3
        for i in range(4):
            key = f'P{i}'
            if key in calib_data:
                if len(calib_data[key]) == 12:
                    self.passed.append(f"âœ“ {key}: 3Ã—4 æŠ•å½±çŸ©é˜µ (12ä¸ªæ•°) âœ“")
                else:
                    self.warnings.append(f"âš ï¸  {key}: æ•°å€¼ä¸ªæ•° {len(calib_data[key])} (åº”è¯¥æ˜¯12)")
            else:
                self.warnings.append(f"âš ï¸  ç¼ºå°‘ {key} (éå¼ºåˆ¶ï¼Œä½†æ¨è)")
        
        # éªŒè¯ Tr
        if 'Tr' in calib_data:
            num_values = len(calib_data['Tr'])
            if num_values == 12:
                self.passed.append(f"âœ“ Tr: 3Ã—4 å˜æ¢çŸ©é˜µ (12ä¸ªæ•°) âœ“")
                
                # éªŒè¯çŸ©é˜µæ˜¯å¦åˆç†ï¼ˆæ—‹è½¬çŸ©é˜µçš„è¡Œåˆ—å¼åº”è¯¥æ¥è¿‘1ï¼‰
                Tr = np.array(calib_data['Tr']).reshape(3, 4)
                R = Tr[:3, :3]
                det = np.linalg.det(R)
                if 0.99 < det < 1.01:
                    self.passed.append(f"âœ“ Træ—‹è½¬çŸ©é˜µè¡Œåˆ—å¼: {det:.6f} (æ¥è¿‘1) âœ“")
                else:
                    self.warnings.append(f"âš ï¸  Træ—‹è½¬çŸ©é˜µè¡Œåˆ—å¼: {det:.6f} (åº”è¯¥æ¥è¿‘1)")
            elif num_values == 16:
                self.errors.append(f"âŒ Tr: 4Ã—4 çŸ©é˜µ (16ä¸ªæ•°)ï¼Œåº”è¯¥æ˜¯ 3Ã—4 (12ä¸ªæ•°)")
                self.warnings.append(f"   ä¿®å¤å»ºè®®: åªä¿å­˜TrçŸ©é˜µçš„å‰3è¡Œ")
            else:
                self.errors.append(f"âŒ Tr: æ•°å€¼ä¸ªæ•° {num_values} (åº”è¯¥æ˜¯12)")
        else:
            self.errors.append(f"âŒ ç¼ºå°‘ Tr å˜æ¢çŸ©é˜µ")
    
    def _validate_poses(self, sequence_id: str):
        """éªŒè¯ poses æ–‡ä»¶"""
        poses_file = self.dataset_root / 'poses' / f'{sequence_id}.txt'
        
        if not poses_file.exists():
            self.warnings.append(f"âš ï¸  ç¼ºå°‘ poses/{sequence_id}.txt (éå¼ºåˆ¶)")
            return
        
        self.passed.append(f"âœ“ æ–‡ä»¶å­˜åœ¨: poses/{sequence_id}.txt")
        
        with open(poses_file, 'r') as f:
            lines = f.readlines()
        
        # éªŒè¯æ¯ä¸€è¡Œ
        invalid_lines = []
        for i, line in enumerate(lines):
            parts = line.strip().split()
            if len(parts) != 12:
                invalid_lines.append((i, len(parts)))
        
        if not invalid_lines:
            self.passed.append(f"âœ“ posesæ–‡ä»¶æ ¼å¼æ­£ç¡®: {len(lines)}è¡Œï¼Œæ¯è¡Œ12ä¸ªæ•° âœ“")
        else:
            for line_num, num_values in invalid_lines[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                self.errors.append(f"âŒ posesæ–‡ä»¶ç¬¬{line_num+1}è¡Œ: {num_values}ä¸ªæ•° (åº”è¯¥æ˜¯12)")
            if len(invalid_lines) > 5:
                self.errors.append(f"   ... è¿˜æœ‰ {len(invalid_lines)-5} è¡Œæ ¼å¼é”™è¯¯")
    
    def _validate_images(self, sequence_id: str):
        """éªŒè¯å›¾åƒæ–‡ä»¶"""
        image_dir = self.dataset_root / 'sequences' / sequence_id / 'image_2'
        
        if not image_dir.exists():
            return
        
        images = sorted(image_dir.glob('*.png'))
        
        if not images:
            self.errors.append(f"âŒ image_2/ ç›®å½•ä¸ºç©º")
            return
        
        self.passed.append(f"âœ“ å›¾åƒæ•°é‡: {len(images)} å¼ ")
        
        # éªŒè¯å‘½åæ ¼å¼ (000000.png, 000001.png, ...)
        expected_names = [f"{i:06d}.png" for i in range(len(images))]
        actual_names = [img.name for img in images]
        
        if actual_names == expected_names:
            self.passed.append(f"âœ“ å›¾åƒå‘½åæ ¼å¼æ­£ç¡® (6ä½è¡¥é›¶) âœ“")
        else:
            mismatches = [i for i, (e, a) in enumerate(zip(expected_names, actual_names)) if e != a]
            if mismatches:
                self.warnings.append(f"âš ï¸  å›¾åƒå‘½åä¸è¿ç»­ï¼Œä»ç´¢å¼• {mismatches[0]} å¼€å§‹")
    
    def _validate_velodyne(self, sequence_id: str):
        """éªŒè¯ç‚¹äº‘æ–‡ä»¶"""
        velodyne_dir = self.dataset_root / 'sequences' / sequence_id / 'velodyne'
        
        if not velodyne_dir.exists():
            return
        
        clouds = sorted(velodyne_dir.glob('*.bin'))
        
        if not clouds:
            self.errors.append(f"âŒ velodyne/ ç›®å½•ä¸ºç©º")
            return
        
        self.passed.append(f"âœ“ ç‚¹äº‘æ•°é‡: {len(clouds)} å¸§")
        
        # éªŒè¯å‘½åæ ¼å¼
        expected_names = [f"{i:06d}.bin" for i in range(len(clouds))]
        actual_names = [pc.name for pc in clouds]
        
        if actual_names == expected_names:
            self.passed.append(f"âœ“ ç‚¹äº‘å‘½åæ ¼å¼æ­£ç¡® (6ä½è¡¥é›¶) âœ“")
        else:
            mismatches = [i for i, (e, a) in enumerate(zip(expected_names, actual_names)) if e != a]
            if mismatches:
                self.warnings.append(f"âš ï¸  ç‚¹äº‘å‘½åä¸è¿ç»­ï¼Œä»ç´¢å¼• {mismatches[0]} å¼€å§‹")
        
        # éªŒè¯ç‚¹äº‘æ ¼å¼ï¼ˆæ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼‰
        if clouds:
            first_cloud = clouds[0]
            data = np.fromfile(str(first_cloud), dtype=np.float32)
            
            if len(data) % 4 == 0:
                num_points = len(data) // 4
                self.passed.append(f"âœ“ ç‚¹äº‘æ ¼å¼: Float32, æ¯ç‚¹4ä¸ªå€¼ (N={num_points}) âœ“")
                
                # æ£€æŸ¥åæ ‡èŒƒå›´æ˜¯å¦åˆç†
                points = data.reshape(-1, 4)
                x_range = (points[:, 0].min(), points[:, 0].max())
                y_range = (points[:, 1].min(), points[:, 1].max())
                z_range = (points[:, 2].min(), points[:, 2].max())
                
                self.passed.append(f"âœ“ åæ ‡èŒƒå›´:")
                self.passed.append(f"   X: [{x_range[0]:.2f}, {x_range[1]:.2f}] m")
                self.passed.append(f"   Y: [{y_range[0]:.2f}, {y_range[1]:.2f}] m")
                self.passed.append(f"   Z: [{z_range[0]:.2f}, {z_range[1]:.2f}] m")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
                if abs(x_range[0]) > 1000 or abs(x_range[1]) > 1000:
                    self.warnings.append(f"âš ï¸  Xåæ ‡èŒƒå›´å¼‚å¸¸ (>1000m)")
                if abs(y_range[0]) > 1000 or abs(y_range[1]) > 1000:
                    self.warnings.append(f"âš ï¸  Yåæ ‡èŒƒå›´å¼‚å¸¸ (>1000m)")
                if abs(z_range[0]) > 100 or abs(z_range[1]) > 100:
                    self.warnings.append(f"âš ï¸  Zåæ ‡èŒƒå›´å¼‚å¸¸ (>100m)")
            else:
                self.errors.append(f"âŒ ç‚¹äº‘æ ¼å¼é”™è¯¯: æ•°æ®é•¿åº¦ {len(data)} ä¸æ˜¯4çš„å€æ•°")
    
    def _validate_alignment(self, sequence_id: str):
        """éªŒè¯æ•°æ®å¯¹é½ï¼ˆå›¾åƒã€ç‚¹äº‘ã€ä½å§¿æ•°é‡æ˜¯å¦ä¸€è‡´ï¼‰"""
        image_dir = self.dataset_root / 'sequences' / sequence_id / 'image_2'
        velodyne_dir = self.dataset_root / 'sequences' / sequence_id / 'velodyne'
        poses_file = self.dataset_root / 'poses' / f'{sequence_id}.txt'
        
        counts = {}
        
        if image_dir.exists():
            counts['images'] = len(list(image_dir.glob('*.png')))
        
        if velodyne_dir.exists():
            counts['velodyne'] = len(list(velodyne_dir.glob('*.bin')))
        
        if poses_file.exists():
            with open(poses_file, 'r') as f:
                counts['poses'] = len(f.readlines())
        
        if len(set(counts.values())) == 1:
            self.passed.append(f"âœ“ æ•°æ®å¯¹é½: å›¾åƒã€ç‚¹äº‘ã€ä½å§¿æ•°é‡ä¸€è‡´ ({counts.get('images', 0)}) âœ“")
        else:
            self.warnings.append(f"âš ï¸  æ•°æ®æ•°é‡ä¸ä¸€è‡´:")
            for key, count in counts.items():
                self.warnings.append(f"   {key}: {count}")
    
    def _print_report(self):
        """è¾“å‡ºéªŒè¯æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š éªŒè¯æŠ¥å‘Š")
        print("="*80)
        
        if self.passed:
            print("\nâœ… é€šè¿‡çš„æ£€æŸ¥é¡¹:")
            for item in self.passed:
                print(f"   {item}")
        
        if self.warnings:
            print("\nâš ï¸  è­¦å‘Š:")
            for item in self.warnings:
                print(f"   {item}")
        
        if self.errors:
            print("\nâŒ é”™è¯¯:")
            for item in self.errors:
                print(f"   {item}")
        
        print("\n" + "="*80)
        print(f"æ€»ç»“: {len(self.passed)} é¡¹é€šè¿‡, {len(self.warnings)} é¡¹è­¦å‘Š, {len(self.errors)} é¡¹é”™è¯¯")
        print("="*80)
        
        if not self.errors:
            print("\nğŸ‰ æ•°æ®é›†æ ¼å¼éªŒè¯é€šè¿‡ï¼å¯ä»¥ç”¨äºè®­ç»ƒã€‚")
            return 0
        else:
            print("\nâš ï¸  å‘ç°é”™è¯¯ï¼Œå»ºè®®ä¿®å¤åå†è¿›è¡Œè®­ç»ƒã€‚")
            return 1


def main():
    parser = argparse.ArgumentParser(description='éªŒè¯ KITTI-Odometry æ•°æ®é›†æ ¼å¼')
    parser.add_argument('dataset_root', type=str, help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--sequence', type=str, default='00', help='åºåˆ—ID (é»˜è®¤: 00)')
    
    args = parser.parse_args()
    
    validator = KITTIOdometryValidator(args.dataset_root)
    exit_code = validator.validate(args.sequence)
    
    return exit_code


if __name__ == '__main__':
    exit(main())
