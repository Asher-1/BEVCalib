#!/usr/bin/env python3
"""
ç‚¹äº‘æŠ•å½±å¯è§†åŒ–å·¥å…·

æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
1. project: å•çº¯çš„ç‚¹äº‘æŠ•å½±åˆ°å›¾åƒ
2. compare: å¯¹æ¯”å»ç•¸å˜å‰åçš„æ•ˆæœ
"""

import numpy as np
import cv2
from pathlib import Path
import argparse
from typing import Tuple, Optional


# ============================================================
# æŠ•å½±å·¥å…·å‡½æ•°
# ============================================================

def get_camera_fov(K: np.ndarray, D: np.ndarray, image_size: tuple) -> float:
    """
    è®¡ç®—ç›¸æœºFOVï¼ˆå®Œå…¨å¯¹é½C++å®ç°ï¼‰
    
    å‚è€ƒ: C++ manual_sensor_calib.cpp: get_camera_fov()
    
    C++å®ç°é€»è¾‘ï¼š
    1. è·å–å›¾åƒ4ä¸ªè§’ç‚¹
    2. ä½¿ç”¨cv::undistortPointså»ç•¸å˜ï¼ˆå¾—åˆ°å½’ä¸€åŒ–ç›¸æœºåæ ‡ï¼‰
    3. è®¡ç®—æ¯ä¸ªè§’ç‚¹çš„è§’åº¦ï¼šangle = atan(norm(x, y))
    4. å–æœ€å¤§è§’åº¦å¹¶ä¹˜ä»¥2
    
    Args:
        K: (3, 3) ç›¸æœºå†…å‚çŸ©é˜µ
        D: (N,) ç•¸å˜ç³»æ•°
        image_size: (height, width) å›¾åƒå°ºå¯¸
    
    Returns:
        fov: ç›¸æœºFOVï¼ˆå¼§åº¦ï¼‰
    """
    h, w = image_size
    
    # C++å‚è€ƒ: è·å–å›¾åƒçš„4ä¸ªè§’ç‚¹
    vertex = np.array([
        [0, 0],
        [0, h],
        [w, h],
        [w, 0]
    ], dtype=np.float32).reshape(-1, 1, 2)  # OpenCVè¦æ±‚çš„æ ¼å¼
    
    # âœ… ä½¿ç”¨cv::undistortPointså»ç•¸å˜ï¼ˆå¯¹é½C++ï¼‰
    if D is not None and len(D) >= 4:
        if len(D) == 4:
            # fisheye model
            vertex_undist = cv2.fisheye.undistortPoints(vertex, K, D)
        else:
            # pinhole model (5 or 8 parameters)
            vertex_undist = cv2.undistortPoints(vertex, K, D)
    else:
        # æ— ç•¸å˜ï¼Œç›´æ¥ä½¿ç”¨K_invè½¬æ¢
        K_inv = np.linalg.inv(K)
        vertex_undist = []
        for point in vertex[:, 0, :]:
            p_homo = np.array([point[0], point[1], 1.0])
            p_norm = K_inv @ p_homo
            vertex_undist.append(p_norm[:2])
        vertex_undist = np.array(vertex_undist).reshape(-1, 1, 2)
    
    # C++å‚è€ƒ: è®¡ç®—æ¯ä¸ªè§’ç‚¹çš„è§’åº¦
    angles = []
    for point in vertex_undist[:, 0, :]:
        # C++å‚è€ƒ: double angle = atan(p.norm())
        # å…¶ä¸­pæ˜¯å½’ä¸€åŒ–ç›¸æœºåæ ‡(x, y)
        angle = np.arctan(np.linalg.norm(point))
        angles.append(angle)
    
    # C++å‚è€ƒ: fov = max_angle * 2.0
    fov = max(angles) * 2.0
    
    return fov


def load_calib(calib_file: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray, str]:
    """
    åŠ è½½KITTIæ ¼å¼çš„æ ‡å®šæ–‡ä»¶
    
    Args:
        calib_file: æ ‡å®šæ–‡ä»¶è·¯å¾„
    
    Returns:
        Tr: (4, 4) ç‚¹äº‘åæ ‡ç³»â†’Cameraå˜æ¢çŸ©é˜µ
            - å¯¹äºæ ‡å‡†KITTI: LiDARâ†’Camera
            - å¯¹äºè‡ªå®šä¹‰æ•°æ®é›†: Sensingâ†’Cameraï¼ˆä¸C++ä¸€è‡´ï¼‰
        K: (3, 3) ç›¸æœºå†…å‚çŸ©é˜µ
        D: (N,) ç•¸å˜ç³»æ•° (pinhole: 5ä¸ª, fisheye: 4ä¸ª)
        camera_model: ç›¸æœºæ¨¡å‹ ('pinhole' æˆ– 'fisheye')
    """
    calib = {}
    with open(calib_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if len(parts) < 2:
                continue
            
            key = parts[0].rstrip(':')
            
            # è¯»å–éæ•°å€¼å­—æ®µï¼ˆå¦‚ camera_modelï¼‰
            if key == 'camera_model':
                calib['camera_model'] = parts[1] if len(parts) > 1 else 'pinhole'
                continue
            
            try:
                values = np.array([float(v) for v in parts[1:]])
            except ValueError:
                # è·³è¿‡æ— æ³•è½¬æ¢ä¸ºæµ®ç‚¹æ•°çš„è¡Œ
                continue
            
            if key == 'P2':
                P2 = values.reshape(3, 4)
                calib['K'] = P2[:3, :3]  # æå–å†…å‚çŸ©é˜µ
            elif key == 'Tr':
                if len(values) == 12:
                    Tr_3x4 = values.reshape(3, 4)
                    calib['Tr'] = np.vstack([Tr_3x4, [0, 0, 0, 1]])  # æ‰©å±•ä¸º4x4
                elif len(values) == 16:
                    calib['Tr'] = values.reshape(4, 4)
            elif key == 'D':
                # ç•¸å˜ç³»æ•°ï¼špinhole: k1, k2, p1, p2, k3; fisheye: k1, k2, k3, k4
                calib['D'] = values
    
    K = calib.get('K')
    Tr = calib.get('Tr')
    D = calib.get('D', np.zeros(5))
    camera_model = calib.get('camera_model', 'pinhole')
    
    if K is None or Tr is None:
        raise ValueError(f"æ— æ³•ä» {calib_file} åŠ è½½P2å’ŒTr")
    
    return Tr, K, D, camera_model


def project_points_to_camera(points: np.ndarray, 
                             Tr: np.ndarray,
                             min_depth: float = 0.0,  # å¯¹é½C++ï¼šä¸è¿‡æ»¤è¿‘ç‚¹
                             max_depth: float = 200.0,  # âœ… ä¿®å¤ï¼šå¢å¤§åˆ°200mï¼Œé¿å…è¿‡æ»¤è¿œå¤„ç‚¹äº‘
                             use_fov_filter: bool = True,  # âœ… å¯¹é½C++
                             use_distance_filter: bool = False,  # âœ… æ–°å¢ï¼šé»˜è®¤å…³é—­è·ç¦»è¿‡æ»¤ï¼ˆå¯¹é½C++ï¼‰
                             K: Optional[np.ndarray] = None,
                             D: Optional[np.ndarray] = None,
                             image_size: Optional[tuple] = None) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    å°†LiDARç‚¹äº‘è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»å¹¶è¿‡æ»¤ï¼ˆå®Œå…¨å¯¹é½C++å®ç°ï¼‰
    
    å‚è€ƒ: C++ math_utils.cpp: lidar_cam_fusion_manual()
          - åªä½¿ç”¨FOVè¿‡æ»¤ï¼Œä¸ä½¿ç”¨è·ç¦»è¿‡æ»¤ï¼
          - double theta = abs(atan2(pc.segment(0, 2).norm(), pc(2)));
          - if (pc(2) > 0 && theta < 0.5 * fov) { ... }
    
    âš ï¸ å…³é”®ä¿®å¤ï¼šC++ç‰ˆæœ¬çš„lidar_cam_fusion_manual()ä¸ä½¿ç”¨è·ç¦»è¿‡æ»¤ï¼
       åªæœ‰filter_pointcloud_by_distance()æ‰ä½¿ç”¨è·ç¦»è¿‡æ»¤ï¼Œä½†æŠ•å½±æ—¶ä¸è°ƒç”¨å®ƒã€‚
    
    Args:
        points: (N, 3) æˆ– (N, 4) LiDARåæ ‡ç³»ä¸‹çš„ç‚¹äº‘ [x, y, z] æˆ– [x, y, z, intensity]
        Tr: (4, 4) LiDARâ†’Cameraå˜æ¢çŸ©é˜µ
        min_depth: æœ€å°3Dè·ç¦»ï¼ˆé»˜è®¤0.0ï¼Œä¸è¿‡æ»¤è¿‘ç‚¹ï¼‰
        max_depth: æœ€å¤§3Dè·ç¦»ï¼ˆé»˜è®¤200.0ï¼Œå¢å¤§ä»¥ä¿ç•™è¿œå¤„ç‚¹äº‘ï¼‰
        use_fov_filter: æ˜¯å¦ä½¿ç”¨FOVè¿‡æ»¤ï¼ˆé»˜è®¤Trueï¼Œå¯¹é½C++ï¼‰
        use_distance_filter: æ˜¯å¦ä½¿ç”¨è·ç¦»è¿‡æ»¤ï¼ˆé»˜è®¤Falseï¼Œå¯¹é½C++ï¼‰
        K: (3, 3) å†…å‚çŸ©é˜µï¼ˆFOVè¿‡æ»¤æ—¶éœ€è¦ï¼‰
        D: (N,) ç•¸å˜ç³»æ•°ï¼ˆFOVè¿‡æ»¤æ—¶éœ€è¦ï¼‰
        image_size: (height, width) å›¾åƒå°ºå¯¸ï¼ˆFOVè¿‡æ»¤æ—¶éœ€è¦ï¼‰
    
    Returns:
        pts_cam: (M, 3) ç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹äº‘ [x, y, z]
        depths: (M,) Zæ·±åº¦å€¼ï¼ˆç”¨äºé¢œè‰²æ˜ å°„ï¼‰
        valid_mask: (N,) æœ‰æ•ˆç‚¹çš„mask
    """
    # æå–xyz
    if points.shape[1] >= 3:
        pts_3d = points[:, :3]
    else:
        raise ValueError("ç‚¹äº‘è‡³å°‘éœ€è¦3åˆ—(x,y,z)")
    
    # è½¬æ¢ä¸ºé½æ¬¡åæ ‡ (N, 4)
    pts_3d_homo = np.hstack([pts_3d, np.ones((pts_3d.shape[0], 1))])
    
    # âœ… æ­¥éª¤1: LiDARåæ ‡ç³» â†’ ç›¸æœºåæ ‡ç³»
    # C++å‚è€ƒ: pc = rot * p + trans
    pts_cam = (Tr @ pts_3d_homo.T).T  # (N, 4)
    
    # âœ… æ­¥éª¤2: è¿‡æ»¤ç›¸æœºåæ–¹çš„ç‚¹ï¼ˆå¿…é¡»ï¼‰
    # C++å‚è€ƒ: if (pc(2) > 0 && theta < 0.5 * fov) { ... }
    valid_mask = pts_cam[:, 2] > 0
    
    # âœ… æ­¥éª¤3: å¯é€‰çš„è·ç¦»è¿‡æ»¤ï¼ˆé»˜è®¤å…³é—­ï¼Œå¯¹é½C++ï¼‰
    if use_distance_filter:
        # è®¡ç®—3Dæ¬§å‡ é‡Œå¾—è·ç¦»
        distances_3d = np.sqrt(pts_cam[:, 0]**2 + pts_cam[:, 1]**2 + pts_cam[:, 2]**2)
        valid_mask = valid_mask & (distances_3d <= max_depth)
        if min_depth > 0:
            valid_mask = valid_mask & (distances_3d >= min_depth)
    
    # âœ… æ­¥éª¤4: FOVè¿‡æ»¤ï¼ˆå¯¹é½C++ï¼‰
    if use_fov_filter and K is not None and D is not None and image_size is not None:
        # è®¡ç®—FOVè§’åº¦ï¼ˆå¯¹é½C++å®ç°ï¼‰
        fov_rad = get_camera_fov(K, D, image_size)
        
        # è®¡ç®—æ¯ä¸ªç‚¹ç›¸å¯¹äºZè½´çš„è§’åº¦
        # C++å‚è€ƒ: double theta = abs(atan2(pc.segment(0, 2).norm(), pc(2)))
        xy_norm = np.linalg.norm(pts_cam[:, :2], axis=1)
        theta = np.abs(np.arctan2(xy_norm, pts_cam[:, 2]))
        
        # FOVè¿‡æ»¤
        valid_mask = valid_mask & (theta < 0.5 * fov_rad)
    
    pts_cam_valid = pts_cam[valid_mask, :3]  # (M, 3)
    depths = pts_cam[valid_mask, 2]  # (M,)
    
    return pts_cam_valid, depths, valid_mask


def project_camera_to_image(pts_cam: np.ndarray,
                            K: np.ndarray,
                            D: np.ndarray,
                            camera_model: str,
                            image_size: tuple) -> np.ndarray:
    """
    å°†ç›¸æœºåæ ‡ç³»çš„ç‚¹æŠ•å½±åˆ°å›¾åƒå¹³é¢ï¼ˆå®Œå…¨å¯¹é½C++å®ç°ï¼‰
    
    å‚è€ƒ: C++ cv::projectPoints() / cv::fisheye::projectPoints()
    
    Args:
        pts_cam: (N, 3) ç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹äº‘ [x, y, z]
        K: (3, 3) å†…å‚çŸ©é˜µ
        D: (M,) ç•¸å˜ç³»æ•°
        camera_model: ç›¸æœºæ¨¡å‹ ('pinhole' æˆ– 'fisheye')
        image_size: (height, width) å›¾åƒå°ºå¯¸
    
    Returns:
        pts_2d: (N, 2) å›¾åƒåæ ‡ [u, v]
    """
    # å‡†å¤‡æŠ•å½±å‚æ•°
    rvec = np.zeros(3, dtype=np.float32)
    tvec = np.zeros(3, dtype=np.float32)
    
    if np.any(np.abs(D) > 1e-6):
        # æœ‰ç•¸å˜ï¼Œæ ¹æ®ç›¸æœºæ¨¡å‹é€‰æ‹©æŠ•å½±å‡½æ•°
        pts_3d_cam = pts_cam.reshape(-1, 1, 3).astype(np.float32)
        
        if camera_model == 'fisheye':
            # ä½¿ç”¨é±¼çœ¼ç›¸æœºæŠ•å½±ï¼ˆå¯¹é½C++ï¼‰
            try:
                pts_2d, _ = cv2.fisheye.projectPoints(
                    pts_3d_cam, rvec, tvec,
                    K.astype(np.float32),
                    D.astype(np.float32)
                )
                pts_2d = pts_2d.reshape(-1, 2)
            except cv2.error as e:
                # å¦‚æœfisheyeæŠ•å½±å¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šæŠ•å½±
                print(f"âš ï¸  é±¼çœ¼æŠ•å½±å¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šæŠ•å½±: {e}")
                pts_2d, _ = cv2.projectPoints(
                    pts_3d_cam, rvec, tvec,
                    K.astype(np.float32),
                    D.astype(np.float32)
                )
                pts_2d = pts_2d.reshape(-1, 2)
        else:
            # ä½¿ç”¨é’ˆå­”ç›¸æœºæŠ•å½±ï¼ˆå¯¹é½C++ï¼‰
            pts_2d, _ = cv2.projectPoints(
                pts_3d_cam, rvec, tvec,
                K.astype(np.float32),
                D.astype(np.float32)
            )
            pts_2d = pts_2d.reshape(-1, 2)
    else:
        # å¦‚æœæ²¡æœ‰ç•¸å˜ï¼Œä½¿ç”¨çŸ©é˜µæŠ•å½±
        pts_2d_homo = (K @ pts_cam.T).T  # (N, 3)
        pts_2d = pts_2d_homo[:, :2] / pts_2d_homo[:, 2:3]
    
    return pts_2d


def filter_image_bounds(pts_2d: np.ndarray, 
                        depths: np.ndarray,
                        image_size: tuple) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    è¿‡æ»¤å›¾åƒè¾¹ç•Œå¤–çš„ç‚¹
    
    Args:
        pts_2d: (N, 2) å›¾åƒåæ ‡
        depths: (N,) æ·±åº¦å€¼
        image_size: (height, width) å›¾åƒå°ºå¯¸
    
    Returns:
        pts_2d_valid: (M, 2) æœ‰æ•ˆçš„å›¾åƒåæ ‡
        depths_valid: (M,) æœ‰æ•ˆçš„æ·±åº¦
        img_mask: (N,) æœ‰æ•ˆç‚¹çš„mask
    """
    h, w = image_size
    img_mask = (pts_2d[:, 0] >= 0) & (pts_2d[:, 0] < w) & \
               (pts_2d[:, 1] >= 0) & (pts_2d[:, 1] < h)
    
    return pts_2d[img_mask], depths[img_mask], img_mask


def color_from_depth(depth: float, unit_depth: float = 2.0) -> tuple:
    """
    æ ¹æ®æ·±åº¦å€¼ç”Ÿæˆé¢œè‰²ï¼ˆå®Œå…¨å¯¹é½C++å®ç°ï¼‰
    
    å‚è€ƒ: C++ manual_sensor_calib.cpp: color_from_depth()
    
    Args:
        depth: æ·±åº¦å€¼ï¼ˆç±³ï¼‰
        unit_depth: å•ä½æ·±åº¦ï¼ˆé»˜è®¤2.0ç±³ï¼Œå¯¹é½C++ï¼‰
    
    Returns:
        (b, g, r): BGRé¢œè‰²å…ƒç»„
    """
    # C++: 6è‰²è¡¨ï¼ˆæ³¨æ„ï¼šC++æ˜¯BGRæ ¼å¼ï¼ŒOpenCVä¹Ÿæ˜¯BGRï¼‰
    color_table = np.array([
        [255, 0, 0],     # è“è‰²
        [0, 255, 0],     # ç»¿è‰²
        [0, 0, 255],     # çº¢è‰²
        [255, 255, 0],   # é’è‰²
        [0, 255, 255],   # é»„è‰²
        [255, 0, 255]    # å“çº¢
    ], dtype=np.float32)
    
    color_table_size = 6
    
    # C++é€»è¾‘
    depth_scale = depth / unit_depth
    idx = int(np.floor(depth_scale))
    scale = (depth - idx * unit_depth) / unit_depth  # å½’ä¸€åŒ–åˆ°[0,1]
    idx = idx % color_table_size
    
    left_color = color_table[idx]
    right_color = color_table[(idx + 1) % color_table_size]
    
    # çº¿æ€§æ’å€¼
    color = left_color + scale * (right_color - left_color)
    
    return tuple(color.astype(np.uint8))


def render_points_on_image(image: np.ndarray,
                           pts_2d: np.ndarray,
                           depths: np.ndarray,
                           max_depth: float = 100.0,
                           min_depth: float = 0.0,
                           point_radius: int = 3,
                           unit_depth: float = 2.0) -> np.ndarray:
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶æ·±åº¦ç€è‰²çš„ç‚¹ï¼ˆå®Œå…¨å¯¹é½C++å®ç°ï¼‰
    
    å‚è€ƒ: C++ manual_sensor_calib.cpp: lidar_cam_fusion_manual()
          - color_from_depth(depth, unit_depth)
          - circle(img, image_points[i], radius, color, -1)
    
    Args:
        image: è¾“å…¥å›¾åƒ
        pts_2d: (N, 2) å›¾åƒåæ ‡
        depths: (N,) æ·±åº¦å€¼ï¼ˆZåæ ‡ï¼‰
        max_depth: æœ€å¤§æ·±åº¦ï¼ˆç”¨äºè¿‡æ»¤ï¼Œä¸ç”¨äºé¢œè‰²æ˜ å°„ï¼‰
        min_depth: æœ€å°æ·±åº¦
        point_radius: ç‚¹çš„åŠå¾„ï¼ˆå¯¹é½C++ï¼‰
        unit_depth: å•ä½æ·±åº¦ï¼ˆé»˜è®¤2.0ç±³ï¼Œå¯¹é½C++ï¼‰
    
    Returns:
        img_with_points: ç»˜åˆ¶äº†ç‚¹çš„å›¾åƒ
    """
    img_copy = image.copy()
    
    # C++å‚è€ƒ: circle(img, image_points[i], radius, color, -1)
    for i in range(len(pts_2d)):
        u, v = int(pts_2d[i, 0]), int(pts_2d[i, 1])
        depth = depths[i]
        
        # ä½¿ç”¨C++çš„é¢œè‰²æ˜ å°„ï¼ˆ6è‰²è¡¨ + unit_depth=2.0ï¼‰
        b, g, r = color_from_depth(depth, unit_depth)
        
        # C++å‚è€ƒ: circle(img, image_points[i], radius, color, -1)
        # OpenCVéœ€è¦intç±»å‹çš„BGRå…ƒç»„
        cv2.circle(img_copy, (u, v), point_radius, (int(b), int(g), int(r)), -1)
    
    return img_copy


def project_and_render(points: np.ndarray,
                      image: np.ndarray,
                      K: np.ndarray,
                      Tr: np.ndarray,
                      D: np.ndarray,
                      camera_model: str = 'pinhole',
                      min_depth: float = 0.0,
                      max_depth: float = 200.0,  # âœ… ä¿®å¤ï¼šå¢å¤§åˆ°200m
                      use_fov_filter: bool = True,  # âœ… å¯¹é½C++
                      use_distance_filter: bool = False,  # âœ… æ–°å¢ï¼šé»˜è®¤å…³é—­è·ç¦»è¿‡æ»¤
                      point_radius: int = 3,
                      unit_depth: float = 2.0,  # âœ… å¯¹é½C++çš„é¢œè‰²æ˜ å°„
                      verbose: bool = True) -> Tuple[np.ndarray, int]:
    """
    å®Œæ•´çš„æŠ•å½±å’Œæ¸²æŸ“æµç¨‹ï¼ˆä¸€ç«™å¼æ¥å£ï¼Œå®Œå…¨å¯¹é½C++ï¼‰
    
    å‚è€ƒ: C++ math_utils.cpp: lidar_cam_fusion_manual()
    
    âš ï¸ å…³é”®ä¿®å¤ï¼šC++ç‰ˆæœ¬åªä½¿ç”¨FOVè¿‡æ»¤ï¼Œä¸ä½¿ç”¨è·ç¦»è¿‡æ»¤ï¼
    
    Args:
        points: (N, 3) æˆ– (N, 4) LiDARç‚¹äº‘
        image: è¾“å…¥å›¾åƒ
        K: (3, 3) ç›¸æœºå†…å‚çŸ©é˜µ
        Tr: (4, 4) LiDARâ†’Cameraå˜æ¢çŸ©é˜µ
        D: (M,) ç•¸å˜ç³»æ•°
        camera_model: ç›¸æœºæ¨¡å‹ ('pinhole' æˆ– 'fisheye')
        min_depth: æœ€å°3Dè·ç¦»ï¼ˆé»˜è®¤0.0ï¼‰
        max_depth: æœ€å¤§3Dè·ç¦»ï¼ˆé»˜è®¤200.0ï¼Œå¢å¤§ä»¥ä¿ç•™è¿œå¤„ç‚¹äº‘ï¼‰
        use_fov_filter: æ˜¯å¦ä½¿ç”¨FOVè¿‡æ»¤ï¼ˆé»˜è®¤Trueï¼Œå¯¹é½C++ï¼‰
        use_distance_filter: æ˜¯å¦ä½¿ç”¨è·ç¦»è¿‡æ»¤ï¼ˆé»˜è®¤Falseï¼Œå¯¹é½C++ï¼‰
        point_radius: ç‚¹çš„åŠå¾„
        unit_depth: é¢œè‰²æ˜ å°„çš„å•ä½æ·±åº¦ï¼ˆé»˜è®¤2.0ç±³ï¼Œå¯¹é½C++ï¼‰
        verbose: æ˜¯å¦æ‰“å°ä¿¡æ¯
    
    Returns:
        img_with_points: ç»˜åˆ¶äº†ç‚¹çš„å›¾åƒ
        num_valid_points: æœ‰æ•ˆæŠ•å½±ç‚¹æ•°
    """
    h, w = image.shape[:2]
    
    # æ­¥éª¤1: è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»ï¼ˆå¯¹é½C++ï¼šåªä½¿ç”¨FOVè¿‡æ»¤ï¼‰
    pts_cam, depths, valid_mask = project_points_to_camera(
        points, Tr, min_depth, max_depth, use_fov_filter, use_distance_filter, K, D, (h, w)
    )
    
    if len(pts_cam) == 0:
        if verbose:
            print("âš ï¸  æ²¡æœ‰ç‚¹åœ¨ç›¸æœºå‰æ–¹æˆ–FOVå†…")
        return image.copy(), 0
    
    # æ­¥éª¤2: æŠ•å½±åˆ°å›¾åƒå¹³é¢
    pts_2d = project_camera_to_image(pts_cam, K, D, camera_model, (h, w))
    
    # æ­¥éª¤3: è¿‡æ»¤å›¾åƒè¾¹ç•Œ
    pts_2d_valid, depths_valid, img_mask = filter_image_bounds(pts_2d, depths, (h, w))
    
    if verbose:
        print(f"  æœ‰æ•ˆæŠ•å½±ç‚¹æ•°: {len(pts_2d_valid)} / {len(points)}")
    
    # æ­¥éª¤4: æ¸²æŸ“åˆ°å›¾åƒï¼ˆå¯¹é½C++çš„é¢œè‰²æ˜ å°„ï¼‰
    img_with_points = render_points_on_image(
        image, pts_2d_valid, depths_valid, max_depth, min_depth, point_radius, unit_depth
    )
    
    return img_with_points, len(pts_2d_valid)


# ============================================================
# ç”¨æˆ·åŠŸèƒ½å‡½æ•°
# ============================================================

def visualize_single_projection(dataset_root: Path, 
                                sequence_id: str, 
                                frame_idx: int,
                                output_path: Optional[Path] = None):
    """
    å•çº¯çš„ç‚¹äº‘æŠ•å½±å¯è§†åŒ–
    
    Args:
        dataset_root: æ•°æ®é›†æ ¹ç›®å½•
        sequence_id: åºåˆ—ID
        frame_idx: å¸§ç´¢å¼•
        output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    seq_dir = dataset_root / 'sequences' / sequence_id
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    image_path = seq_dir / 'image_2' / f'{frame_idx:06d}.png'
    pc_path = seq_dir / 'velodyne' / f'{frame_idx:06d}.bin'
    calib_path = seq_dir / 'calib.txt'
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
    if not image_path.exists():
        print(f"âŒ å›¾åƒä¸å­˜åœ¨: {image_path}")
        return
    if not pc_path.exists():
        print(f"âŒ ç‚¹äº‘ä¸å­˜åœ¨: {pc_path}")
        return
    if not calib_path.exists():
        print(f"âŒ æ ‡å®šæ–‡ä»¶ä¸å­˜åœ¨: {calib_path}")
        return
    
    print(f"\n{'='*60}")
    print(f"ç‚¹äº‘æŠ•å½±å¯è§†åŒ– - å¸§ {frame_idx:06d}")
    print(f"{'='*60}\n")
    
    # 1. åŠ è½½å›¾åƒ
    img = cv2.imread(str(image_path))
    print(f"âœ“ åŠ è½½å›¾åƒ: {img.shape}")
    
    # 2. åŠ è½½ç‚¹äº‘
    points = np.fromfile(str(pc_path), dtype=np.float32)
    
    if len(points) % 4 == 0:
        points = points.reshape(-1, 4)
    elif len(points) % 3 == 0:
        points = points.reshape(-1, 3)
    else:
        raise ValueError(f"ç‚¹äº‘æ ¼å¼é”™è¯¯: {len(points)} ä¸æ˜¯3æˆ–4çš„å€æ•°")
    
    print(f"âœ“ åŠ è½½ç‚¹äº‘: {points.shape}")
    print(f"  X: [{points[:, 0].min():.2f}, {points[:, 0].max():.2f}]")
    print(f"  Y: [{points[:, 1].min():.2f}, {points[:, 1].max():.2f}]")
    print(f"  Z: [{points[:, 2].min():.2f}, {points[:, 2].max():.2f}]")
    
    # 3. åŠ è½½æ ‡å®šå‚æ•°
    Tr, K, D, camera_model = load_calib(str(calib_path))
    
    print(f"âœ“ åŠ è½½æ ‡å®šå‚æ•°")
    print(f"  Tr shape: {Tr.shape}")
    print(f"  K shape: {K.shape}")
    print(f"  ç›¸æœºæ¨¡å‹: {camera_model}")
    if len(D) == 4:
        print(f"  D (ç•¸å˜ç³»æ•°/é±¼çœ¼): k1={D[0]:.6f}, k2={D[1]:.6f}, k3={D[2]:.6f}, k4={D[3]:.6f}")
    elif len(D) >= 5:
        print(f"  D (ç•¸å˜ç³»æ•°/é’ˆå­”): k1={D[0]:.6f}, k2={D[1]:.6f}, p1={D[2]:.6f}, p2={D[3]:.6f}, k3={D[4]:.6f}")
    else:
        print(f"  D (ç•¸å˜ç³»æ•°): {D}")
    print(f"  ç‚¹äº‘åæ ‡ç³»: Sensingç³»ï¼ˆä¸C++ä¸€è‡´ï¼‰æˆ–LiDARç³»ï¼ˆKITTIæ ‡å‡†ï¼‰")
    
    # 4. æŠ•å½±ç‚¹äº‘åˆ°å›¾åƒï¼ˆå®Œå…¨å¯¹é½C++ï¼‰
    img_with_points, num_valid = project_and_render(
        points, img, K, Tr, D,
        camera_model=camera_model,
        min_depth=0.0,        # å¯¹é½C++ï¼šä¸è¿‡æ»¤è¿‘ç‚¹
        max_depth=200.0,      # ç”¨æˆ·è®¾ç½®ï¼š200ç±³
        use_fov_filter=True,  # âœ… å¯¹é½C++ï¼šä½¿ç”¨FOVè¿‡æ»¤
        point_radius=3,
        unit_depth=2.0,       # âœ… å¯¹é½C++ï¼š6è‰²è¡¨é¢œè‰²æ˜ å°„
        verbose=False
    )
    
    print(f"âœ“ æŠ•å½±ç‚¹äº‘: {num_valid}/{len(points)} ä¸ªç‚¹åœ¨å›¾åƒå†…")
    
    if num_valid == 0:
        print("âŒ æ²¡æœ‰ç‚¹è¢«æŠ•å½±åˆ°å›¾åƒä¸Šï¼")
        return
    
    # 5. æ·»åŠ ä¿¡æ¯æ–‡æœ¬
    text_lines = [
        f"Total points: {len(points)}",
        f"Projected points: {num_valid}",
    ]
    
    y_offset = 30
    for line in text_lines:
        cv2.putText(img_with_points, line, (10, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        y_offset += 30
    
    # 6. æ˜¾ç¤ºå’Œä¿å­˜
    if output_path is None:
        output_path = dataset_root / f'projection_{sequence_id}_{frame_idx:06d}.jpg'
    
    cv2.imwrite(str(output_path), img_with_points)
    print(f"âœ“ ä¿å­˜ç»“æœ: {output_path}")
    
    # æ˜¾ç¤ºï¼ˆç¼©å°ä»¥é€‚åº”å±å¹•ï¼‰
    scale = 0.6
    h, w = img_with_points.shape[:2]
    img_display = cv2.resize(img_with_points, (int(w * scale), int(h * scale)))
    
    cv2.imshow('Point Cloud Projection', img_display)
    print("\næŒ‰ä»»æ„é”®å…³é—­çª—å£...")
    cv2.waitKey(0)
    cv2.destroyAllWindows()


def compare_undistortion(dataset_root: Path,
                         sequence_id: str,
                         frame_idx: int,
                         temp_dir: Optional[Path] = None,
                         debug_sample_idx: Optional[int] = None) -> bool:
    """
    å¯¹æ¯”å»ç•¸å˜å‰åçš„æ•ˆæœ
    
    âš ï¸ é‡è¦ç´¢å¼•è¯´æ˜ï¼š
    - frame_idx: æœ€ç»ˆæ•°æ®é›†ä¸­çš„å¸§ç´¢å¼•ï¼ˆvelodyne/000000.binå¯¹åº”çš„ç´¢å¼•ï¼‰
    - debug_sample_idx: debug_raw_pointcloudsç›®å½•ä¸­çš„æ ·æœ¬ç´¢å¼•
    - temp_pc_files: temp/pointcloudsç›®å½•ä¸­çš„åŸå§‹ç‚¹äº‘æ–‡ä»¶
    
    ç”±äºå»ç•¸å˜è¿‡ç¨‹ä¸­ä¼šè·³è¿‡ä¸€äº›å¸§ï¼Œtempç›®å½•ä¸­çš„æ–‡ä»¶ç´¢å¼•å¯èƒ½ä¸ç­‰äºæœ€ç»ˆå¸§ç´¢å¼•ï¼
    éœ€è¦é€šè¿‡æ—¶é—´æˆ³æˆ–å…¶ä»–æ–¹å¼è¿›è¡ŒåŒ¹é…ã€‚
    
    Args:
        dataset_root: æ•°æ®é›†æ ¹ç›®å½•
        sequence_id: åºåˆ—ID
        frame_idx: å¸§ç´¢å¼•ï¼ˆå»ç•¸å˜åçš„å¸§ç´¢å¼•ï¼‰
        temp_dir: ä¸´æ—¶ç›®å½•ï¼ˆå­˜å‚¨å»ç•¸å˜å‰çš„ç‚¹äº‘ï¼Œæ—§ç‰ˆæœ¬ï¼‰
        debug_sample_idx: è°ƒè¯•æ ·æœ¬ç´¢å¼•ï¼ˆæ–°ç‰ˆæœ¬ï¼Œä½¿ç”¨debug_raw_pointcloudsç›®å½•ï¼‰
    
    Returns:
        bool: Trueè¡¨ç¤ºç»§ç»­ï¼ŒFalseè¡¨ç¤ºé€€å‡º
    """
    print(f"\n{'='*80}")
    print(f"å¯¹æ¯”å¸§ {frame_idx:06d} çš„å»ç•¸å˜æ•ˆæœ")
    print(f"{'='*80}\n")
    
    seq_dir = dataset_root / 'sequences' / sequence_id
    
    # 1. åŠ è½½æ ‡å®šå‚æ•°
    calib_path = seq_dir / 'calib.txt'
    Tr, K, D, camera_model = load_calib(str(calib_path))
    
    print(f"âœ“ åŠ è½½æ ‡å®šå‚æ•°")
    print(f"  ç›¸æœºæ¨¡å‹: {camera_model}")
    
    # æ‰“å°TrçŸ©é˜µï¼ˆå…³é”®ï¼šè¿™æ˜¯Sensingâ†’Cameraå˜æ¢ï¼‰
    print(f"  Tr (Sensingâ†’Camera):")
    print(f"    æ—‹è½¬:\n{Tr[:3, :3]}")
    print(f"    å¹³ç§»: {Tr[:3, 3]}")
    
    # 2. åŠ è½½å»ç•¸å˜åçš„ç‚¹äº‘å’Œå›¾åƒ
    pc_after_path = seq_dir / 'velodyne' / f'{frame_idx:06d}.bin'
    image_path = seq_dir / 'image_2' / f'{frame_idx:06d}.png'
    
    if not pc_after_path.exists():
        print(f"âŒ å»ç•¸å˜åç‚¹äº‘ä¸å­˜åœ¨: {pc_after_path}")
        return False
    if not image_path.exists():
        print(f"âŒ å›¾åƒä¸å­˜åœ¨: {image_path}")
        return False
    
    image = cv2.imread(str(image_path))
    print(f"âœ“ åŠ è½½å›¾åƒ: {image.shape}")
    
    pc_after = np.fromfile(str(pc_after_path), dtype=np.float32).reshape(-1, 4)
    print(f"âœ“ åŠ è½½å»ç•¸å˜åç‚¹äº‘ (Sensingåæ ‡ç³»): {pc_after.shape}")
    print(f"  X: [{pc_after[:, 0].min():.2f}, {pc_after[:, 0].max():.2f}]")
    print(f"  Y: [{pc_after[:, 1].min():.2f}, {pc_after[:, 1].max():.2f}]")
    print(f"  Z: [{pc_after[:, 2].min():.2f}, {pc_after[:, 2].max():.2f}]")
    
    # 3. å°è¯•åŠ è½½å»ç•¸å˜å‰çš„ç‚¹äº‘ï¼ˆæ”¯æŒä¸¤ç§è·¯å¾„æ ¼å¼ï¼‰
    pc_before = None
    image_before = None
    actual_sample_idx = None  # å®é™…ä½¿ç”¨çš„æ ·æœ¬ç´¢å¼•
    
    # æ–¹å¼1ï¼šæ–°ç‰ˆæœ¬ - debug_raw_pointcloudsç›®å½•ï¼ˆè°ƒè¯•æ ·æœ¬ï¼Œæ–‡ä»¶åå¯¹åº”å¸§ç´¢å¼•ï¼‰
    debug_dir = seq_dir / 'debug_raw_pointclouds'
    if debug_dir.exists():
        # åˆ—å‡ºæ‰€æœ‰è°ƒè¯•æ ·æœ¬
        debug_files = sorted(debug_dir.glob('*_raw.bin'))
        
        print(f"\nğŸ“‹ debug_raw_pointcloudsç›®å½•: {len(debug_files)} ä¸ªæ ·æœ¬")
        
        # ç›´æ¥ä½¿ç”¨å¸§ç´¢å¼•æŸ¥æ‰¾å¯¹åº”çš„è°ƒè¯•æ ·æœ¬æ–‡ä»¶
        # æ–‡ä»¶åæ ¼å¼ï¼š{frame_idx:06d}_raw.bin
        pc_before_path = debug_dir / f'{frame_idx:06d}_raw.bin'
        image_before_path = debug_dir / f'{frame_idx:06d}_image.jpg'
        
        if pc_before_path.exists():
            actual_sample_idx = frame_idx
            pc_before_data = np.fromfile(str(pc_before_path), dtype=np.float32)
            
            # åˆ¤æ–­æ ¼å¼ï¼ˆå¯èƒ½æ˜¯NÃ—5æˆ–NÃ—4ï¼‰
            if len(pc_before_data) % 5 == 0:
                pc_before = pc_before_data.reshape(-1, 5)[:, :4]
                print(f"âœ“ åŠ è½½å»ç•¸å˜å‰ç‚¹äº‘ (å¸§ {frame_idx}): {pc_before.shape} (NÃ—5æ ¼å¼)")
            elif len(pc_before_data) % 4 == 0:
                pc_before = pc_before_data.reshape(-1, 4)
                print(f"âœ“ åŠ è½½å»ç•¸å˜å‰ç‚¹äº‘ (å¸§ {frame_idx}): {pc_before.shape}")
            
            # åŒæ—¶åŠ è½½å¯¹åº”çš„åŸå§‹å›¾åƒ
            if image_before_path.exists():
                image_before = cv2.imread(str(image_before_path))
                print(f"âœ“ åŠ è½½å»ç•¸å˜å‰å›¾åƒ: {image_before.shape}")
            
            if pc_before is not None:
                print(f"  X: [{pc_before[:, 0].min():.2f}, {pc_before[:, 0].max():.2f}]")
                print(f"  Y: [{pc_before[:, 1].min():.2f}, {pc_before[:, 1].max():.2f}]")
                print(f"  Z: [{pc_before[:, 2].min():.2f}, {pc_before[:, 2].max():.2f}]")
        else:
            print(f"âš ï¸  å¸§ {frame_idx} æ²¡æœ‰å¯¹åº”çš„è°ƒè¯•æ ·æœ¬")
            print(f"   å¯ç”¨çš„è°ƒè¯•æ ·æœ¬å¸§: {[int(f.stem.replace('_raw', '')) for f in debug_files]}")
    
    # æ–¹å¼2ï¼šæ—§ç‰ˆæœ¬ - temp/pointcloudsç›®å½•
    if pc_before is None:
        if temp_dir is None:
            temp_dir = dataset_root / 'temp'
        
        if temp_dir.exists() and (temp_dir / 'pointclouds').exists():
            temp_pc_files = sorted((temp_dir / 'pointclouds').glob('*.bin'))
            
            # âš ï¸ é‡è¦ï¼štempç›®å½•ä¸­çš„æ–‡ä»¶å¯èƒ½å› ä¸ºè·³å¸§è€Œä¸å¯¹åº”
            print(f"\nğŸ“‹ temp/pointcloudsç›®å½•: {len(temp_pc_files)} ä¸ªæ–‡ä»¶")
            print(f"   âš ï¸ æ³¨æ„ï¼šç”±äºå»ç•¸å˜ä¼šè·³è¿‡ä¸€äº›å¸§ï¼Œç´¢å¼•å¯èƒ½ä¸å¯¹åº”ï¼")
            
            if frame_idx < len(temp_pc_files):
                pc_before_path = temp_pc_files[frame_idx]
                pc_before_data = np.fromfile(str(pc_before_path), dtype=np.float32)
                
                # åˆ¤æ–­æ ¼å¼
                if len(pc_before_data) % 5 == 0:
                    pc_before = pc_before_data.reshape(-1, 5)[:, :4]
                    print(f"âœ“ åŠ è½½å»ç•¸å˜å‰ç‚¹äº‘ (temp): {pc_before.shape} (NÃ—5æ ¼å¼)")
                elif len(pc_before_data) % 4 == 0:
                    pc_before = pc_before_data.reshape(-1, 4)
                    print(f"âœ“ åŠ è½½å»ç•¸å˜å‰ç‚¹äº‘ (temp): {pc_before.shape}")
                
                if pc_before is not None:
                    print(f"  X: [{pc_before[:, 0].min():.2f}, {pc_before[:, 0].max():.2f}]")
                    print(f"  Y: [{pc_before[:, 1].min():.2f}, {pc_before[:, 1].max():.2f}]")
                    print(f"  Z: [{pc_before[:, 2].min():.2f}, {pc_before[:, 2].max():.2f}]")
    
    if pc_before is None:
        print(f"âš ï¸  æœªæ‰¾åˆ°å»ç•¸å˜å‰çš„ç‚¹äº‘ï¼Œåªæ˜¾ç¤ºå»ç•¸å˜åçš„ç»“æœ")
        print(f"   ğŸ’¡ æç¤ºï¼šè¿è¡Œprepare_custom_dataset.pyæ—¶æ·»åŠ  --save_debug_samples 10 æ¥ä¿å­˜è°ƒè¯•æ ·æœ¬")
    
    # ä½¿ç”¨å»ç•¸å˜å‰çš„å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨å»ç•¸å˜åçš„å›¾åƒ
    display_image = image_before if image_before is not None else image
    
    # 4. æŠ•å½±ç‚¹äº‘åˆ°å›¾åƒï¼ˆå®Œå…¨å¯¹é½C++ï¼‰
    print(f"\næŠ•å½±ç‚¹äº‘åˆ°å›¾åƒ...")
    
    # å»ç•¸å˜å
    print(f"  [å»ç•¸å˜å]")
    img_after, num_after = project_and_render(
        pc_after, image, K, Tr, D,
        camera_model=camera_model,
        min_depth=0.0, max_depth=200.0, use_fov_filter=True,  # âœ… FOVè¿‡æ»¤
        point_radius=4, unit_depth=2.0, verbose=True
    )
    
    # å»ç•¸å˜å‰
    if pc_before is not None:
        print(f"  [å»ç•¸å˜å‰]")
        img_before, num_before = project_and_render(
            pc_before, display_image, K, Tr, D,
            camera_model=camera_model,
            min_depth=0.0, max_depth=200.0, use_fov_filter=True,  # âœ… FOVè¿‡æ»¤
            point_radius=4, unit_depth=2.0, verbose=True
        )
    else:
        img_before = display_image.copy()
        num_before = 0
        cv2.putText(img_before, "No raw pointcloud data", (50, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    
    # 5. å¹¶æ’æ˜¾ç¤º
    font = cv2.FONT_HERSHEY_SIMPLEX
    
    # æ·»åŠ æ ‡é¢˜å’Œç»Ÿè®¡ä¿¡æ¯
    cv2.putText(img_before, f"Before Undistortion ({num_before} pts)", (20, 40), font, 1.2, (0, 255, 0), 2)
    cv2.putText(img_after, f"After Undistortion ({num_after} pts)", (20, 40), font, 1.2, (0, 255, 0), 2)
    
    if pc_before is not None:
        # æ˜¾ç¤ºç‚¹äº‘èŒƒå›´å·®å¼‚
        cv2.putText(img_before, f"X:[{pc_before[:,0].min():.1f},{pc_before[:,0].max():.1f}]", (20, 80), font, 0.8, (255, 255, 0), 2)
        cv2.putText(img_after, f"X:[{pc_after[:,0].min():.1f},{pc_after[:,0].max():.1f}]", (20, 80), font, 0.8, (255, 255, 0), 2)
    
    # ç¼©å°å›¾åƒä»¥ä¾¿å¹¶æ’æ˜¾ç¤º
    scale = 0.5
    h, w = image.shape[:2]
    new_h, new_w = int(h * scale), int(w * scale)
    
    img_before_small = cv2.resize(img_before, (new_w, new_h))
    img_after_small = cv2.resize(img_after, (new_w, new_h))
    
    # æ¨ªå‘æ‹¼æ¥
    comparison = np.hstack([img_before_small, img_after_small])
    
    # 6. æ˜¾ç¤ºå’Œä¿å­˜
    output_path = dataset_root / f'undistortion_comparison_{frame_idx:06d}.jpg'
    cv2.imwrite(str(output_path), comparison)
    print(f"\nâœ“ å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")
    
    # æ‰“å°å¯¹æ¯”æ€»ç»“
    if pc_before is not None:
        print(f"\nğŸ“Š å¯¹æ¯”æ€»ç»“:")
        print(f"  å»ç•¸å˜å‰æŠ•å½±ç‚¹æ•°: {num_before}")
        print(f"  å»ç•¸å˜åæŠ•å½±ç‚¹æ•°: {num_after}")
        if num_before > 0:
            improvement = (num_after - num_before) / num_before * 100
            print(f"  å˜åŒ–: {improvement:+.1f}%")
    
    # æ˜¾ç¤ºçª—å£
    cv2.namedWindow('Undistortion Comparison', cv2.WINDOW_NORMAL)
    cv2.imshow('Undistortion Comparison', comparison)
    print(f"\næŒ‰ä»»æ„é”®ç»§ç»­ï¼ŒESCé€€å‡º...")
    key = cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    return key != 27  # ESCé”®é€€å‡º


def batch_compare(dataset_root: Path,
                 sequence_id: str,
                 start_idx: int = 0,
                 num_frames: int = 5,
                 temp_dir: Optional[Path] = None):
    """
    æ‰¹é‡å¯¹æ¯”å¤šå¸§
    
    Args:
        dataset_root: æ•°æ®é›†æ ¹ç›®å½•
        sequence_id: åºåˆ—ID
        start_idx: èµ·å§‹å¸§ç´¢å¼•
        num_frames: å¯¹æ¯”å¸§æ•°
        temp_dir: ä¸´æ—¶ç›®å½•
    """
    print(f"\næ‰¹é‡å¯¹æ¯” {num_frames} å¸§ï¼Œä»ç´¢å¼• {start_idx} å¼€å§‹\n")
    
    for i in range(num_frames):
        frame_idx = start_idx + i
        
        if not compare_undistortion(dataset_root, sequence_id, frame_idx, temp_dir):
            print("ç”¨æˆ·å–æ¶ˆ")
            break
        
        print("\n" + "="*80 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description='ç‚¹äº‘æŠ•å½±å¯è§†åŒ–å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ¨¡å¼è¯´æ˜:
  project   - å•çº¯çš„ç‚¹äº‘æŠ•å½±åˆ°å›¾åƒ
  compare   - å¯¹æ¯”å»ç•¸å˜å‰åçš„æ•ˆæœ

ç¤ºä¾‹:
  # æŠ•å½±å•å¸§ç‚¹äº‘
  %(prog)s --mode project --dataset_root /path/to/data --frame 0
  
  # å¯¹æ¯”å»ç•¸å˜æ•ˆæœ
  %(prog)s --mode compare --dataset_root /path/to/data --frame 0
  
  # æ‰¹é‡å¯¹æ¯”å¤šå¸§
  %(prog)s --mode compare --dataset_root /path/to/data --frame 0 --num_frames 5
        """
    )
    
    parser.add_argument('--mode', type=str, required=True, choices=['project', 'compare'],
                       help='è¿è¡Œæ¨¡å¼: project=æŠ•å½±, compare=å¯¹æ¯”å»ç•¸å˜')
    parser.add_argument('--dataset_root', type=str, required=True,
                       help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--sequence', type=str, default='00',
                       help='åºåˆ—ID (é»˜è®¤: 00)')
    parser.add_argument('--frame', type=int, default=0,
                       help='å¸§ç´¢å¼• (é»˜è®¤: 0)')
    parser.add_argument('--output', type=str, default=None,
                       help='è¾“å‡ºå›¾åƒè·¯å¾„ (ä»…projectæ¨¡å¼ï¼Œå¯é€‰)')
    parser.add_argument('--num_frames', type=int, default=1,
                       help='å¯¹æ¯”å¸§æ•° (ä»…compareæ¨¡å¼ï¼Œé»˜è®¤: 1)')
    parser.add_argument('--temp_dir', type=str, default=None,
                       help='ä¸´æ—¶ç›®å½• (ä»…compareæ¨¡å¼ï¼Œå­˜å‚¨å»ç•¸å˜å‰çš„ç‚¹äº‘)')
    parser.add_argument('--debug_sample', type=int, default=None,
                       help='è°ƒè¯•æ ·æœ¬ç´¢å¼• (ä»…compareæ¨¡å¼ï¼Œä½¿ç”¨debug_raw_pointcloudsç›®å½•)')
    
    args = parser.parse_args()
    
    dataset_root = Path(args.dataset_root)
    
    if args.mode == 'project':
        # æŠ•å½±æ¨¡å¼
        output_path = Path(args.output) if args.output else None
        visualize_single_projection(dataset_root, args.sequence, args.frame, output_path)
    elif args.mode == 'compare':
        # å¯¹æ¯”æ¨¡å¼
        temp_dir = Path(args.temp_dir) if args.temp_dir else None
        if args.num_frames == 1:
            compare_undistortion(dataset_root, args.sequence, args.frame, temp_dir, args.debug_sample)
        else:
            batch_compare(dataset_root, args.sequence, args.frame, args.num_frames, temp_dir)
    
    print("\nâœ“ å®Œæˆ")


if __name__ == '__main__':
    main()
