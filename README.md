# [CoRL 2025] BEVCalib: LiDAR-Camera Calibration via Geometry-Guided Bird's-Eye View Representation

[![arXiv](https://img.shields.io/badge/arXiv-2506.02587-df2a2a.svg?style=for-the-badge)](https://arxiv.org/abs/2506.02587) [![Website](https://img.shields.io/badge/Website-BEVCalib-blue?style=for-the-badge)](https://cisl.ucr.edu/BEVCalib) [![HF Models](https://img.shields.io/badge/%F0%9F%A4%97-Models-yellow?style=for-the-badge)](https://huggingface.co/cisl-hf/BEVCalib) [![PyTorch](https://img.shields.io/badge/PyTorch-2.6.0-EE4C2C.svg?style=for-the-badge&logo=pytorch)](https://pytorch.org/get-started/locally/) [![License](https://img.shields.io/github/license/TRI-ML/prismatic-vlms?style=for-the-badge)](LICENSE)

> **ðŸŽ‰ NEW (2026-01-27)**: `prepare_custom_dataset.py` v2.0 å‘å¸ƒï¼  
> - ðŸš€ **5-8x é€Ÿåº¦æå‡**ï¼ˆå¹¶è¡Œå¤„ç† + æ‰¹å¤„ç†ä¼˜åŒ–ï¼‰  
> - ðŸ‘ï¸ **PLY æ ¼å¼ä¸´æ—¶ç‚¹äº‘**ï¼ˆå¯ç”¨ CloudCompare ç›´æŽ¥æŸ¥çœ‹éªŒè¯ï¼‰  
> - ðŸ“‹ æŸ¥çœ‹è¯¦æƒ…: [QUICKSTART_PERFORMANCE.md](QUICKSTART_PERFORMANCE.md) | [CHANGELOG_v2.0.md](CHANGELOG_v2.0.md)

<hr style="border: 2px solid gray;"></hr>

## Getting Started

### Prerequistes
First create a conda environment:
```bash
conda create -n bevcalib python=3.11
conda activate bevcalib
pip3 install -r requirements.txt
```

The code is built with following libraries:

- Python = 3.11
- Pytorch = 2.6.0
- CUDA = 11.8
- cuda-toolkit = 11.8
- [spconv-cu118](https://github.com/traveller59/spconv)
- OpenCV
- pandas
- open3d
- transformers
- [deformable_attention](https://github.com/lucidrains/deformable-attention)
- tensorboard
- wandb
- pykitti

We recommend using the following command to install cuda-toolkit=11.8:
```bash
conda install -c "nvidia/label/cuda-11.8.0" cuda-toolkit
```

After installing the above dependencies, please run the following command to install [bev_pool](https://github.com/mit-han-lab/bevfusion) operation
```bash
cd ./kitti-bev-calib/img_branch/bev_pool && python setup.py build_ext --inplace
```

We also provide a [Dockerfile](Dockerfile/Dockerfile) for easy setup, please execute the following command to build the docker image and install cuda extensions:
```bash
docker build -f Dockerfile/Dockerfile -t bevcalib .
docker run --gpus all -it -v$(pwd):/workspace bevcalib
### In the docker, run the following command to install cuda extensions
cd ./kitti-bev-calib/img_branch/bev_pool && python setup.py build_ext --inplace
```

## Dataset Preparation
### KITTI-Odometry
Coordinates reference: https://developer.aliyun.com/article/855136
We release the code to reproduce our results on the KITTI-Odometry dataset. Please download the KITTI-Odometry dataset from [here](https://www.cvlibs.net/datasets/kitti/eval_odometry.php). After downloading the dataset, the directory structure should look like
```tree
kitti-odometry/
â”œâ”€â”€ sequences/         
â”‚   â”œâ”€â”€ 00/            
â”‚   â”‚   â”œâ”€â”€ image_2/  
â”‚   â”‚   â”œâ”€â”€ image_3/   
â”‚   â”‚   â”œâ”€â”€ velodyne/
â”‚   â”‚   â””â”€â”€ calib.txt 
â”‚   â”œâ”€â”€ 01/
â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ 21/
â”‚       â””â”€â”€ ...
â””â”€â”€ poses/            
    â”œâ”€â”€ 00.txt        
    â”œâ”€â”€ 01.txt
    â””â”€â”€ ...
```

### CalibDB
Coming soon!

### Custom Dataset
We provide a tool to prepare your custom dataset from ROS bags. See [PREPARE_CUSTOM_DATASET.md](PREPARE_CUSTOM_DATASET.md) for detailed instructions.

**Quick Start:**
```bash
# Prepare dataset from ROS bags (optimized for speed)
python tools/prepare_custom_dataset.py \
    --bag_dir /path/to/bags \
    --config_dir /path/to/config \
    --output_dir ./data/custom_dataset \
    --batch_size 500 \
    --num_workers 4

# View extracted point clouds (PLY format for easy visualization)
python tools/view_pointcloud.py ./data/custom_dataset/temp/pointclouds/000000.ply

# Validate the dataset
python tools/validate_kitti_odometry.py --dataset_root ./data/custom_dataset
```

**Key Features:**
- ðŸš€ **5-8x faster** with parallel processing and optimized batch size
- ðŸ‘ï¸ **PLY format** for temporary point clouds (easy to view with CloudCompare/MeshLab)
- ðŸ”„ **Automatic conversion** to BIN format for training
- ðŸ“Š **Built-in visualization** tool for data verification
- ðŸŽ¯ **Auto-detect sequences** - automatically finds all available sequences for training

**Training on Custom Dataset:**
```bash
# Prepare dataset
python tools/prepare_custom_dataset.py \
    --bag_dir /path/to/bags \
    --config_dir /path/to/config \
    --output_dir ./data/custom_dataset

# Train (automatically detects all sequences)
python kitti-bev-calib/train_kitti.py \
    --dataset_root ./data/custom_dataset \
    --log_dir ./logs/custom_model \
    --batch_size 4 \
    --num_epochs 100
```

See [CUSTOM_DATASET_TRAINING.md](CUSTOM_DATASET_TRAINING.md) for detailed training guide.

## Pretrained Model
We release our pretrained model on the KITTI-Odometry dataset. We provide two ways to download our models.
### Google cloud
Please find the pretrained model from [Google Drive](https://drive.google.com/drive/folders/1r9RkZATm9-7vh5buoB1YSDuL3_DslxZ3?usp=share_link) and place it in the `./ckpt` directory. For your convenience, you can also run `pip3 install gdown` and run the following command to download the KITTI checkpoint in the command line.

```bash
gdown https://drive.google.com/uc\?id\=1gWO-Z4NXG2uWwsZPecjWByaZVtgJ0XNb
```
### Hugging face
We also release our pretrained model on [Hugging Face page](https://huggingface.co/cisl-hf/BEVCalib). You should download huggingface-cli by `pip install -U "huggingface_hub[cli]"` and then download the pretrained model by running the following command:
```bash
huggingface-cli download cisl-hf/BEVCalib --revision kitti-bev-calib --local-dir YOUR_LOCAL_PATH
```

## Evaluation

### evaluate_checkpoint.py - Checkpoint è¯„ä¼°å·¥å…·

è¯„ä¼°å·²ä¿å­˜çš„ checkpointï¼Œç”Ÿæˆè¯¦ç»†çš„è¯¯å·®æŠ¥å‘Šå’Œå¯è§†åŒ–ç»“æžœã€‚

#### åŠŸèƒ½ç‰¹æ€§
- âœ… åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡åž‹æ€§èƒ½
- âœ… ç”Ÿæˆè¯¦ç»†çš„è¯¯å·®ç»Ÿè®¡ï¼ˆå¹³ç§»ã€æ—‹è½¬ã€RPYåˆ†è§£ï¼‰
- âœ… ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆå¯è§†åŒ–å›¾åƒï¼ˆInit/GT/Pred ä¸‰åˆ—å¯¹æ¯”ï¼‰
- âœ… ä¿å­˜å¤–å‚çŸ©é˜µå’Œè¯¯å·®æŠ¥å‘Šï¼ˆæ–‡æœ¬æ–‡ä»¶ï¼‰
- âœ… æ”¯æŒè‡ªå®šä¹‰æ‰°åŠ¨èŒƒå›´
- âœ… æ”¯æŒæ‰¹é‡å¤„ç†ï¼ˆå¯é™åˆ¶è¯„ä¼°æ ·æœ¬æ•°ï¼‰

#### å‚æ•°è¯´æ˜Ž

| å‚æ•° | ç±»åž‹ | é»˜è®¤å€¼ | è¯´æ˜Ž |
|------|------|--------|------|
| `--ckpt_path` | str | å¿…å¡« | Checkpoint æ–‡ä»¶è·¯å¾„ (*.pth) |
| `--dataset_root` | str | å¿…å¡« | æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„ |
| `--angle_range_deg` | float | 20.0 | è¯„ä¼°æ—¶çš„æ‰°åŠ¨è§’åº¦èŒƒå›´ (åº¦) |
| `--trans_range` | float | 1.5 | è¯„ä¼°æ—¶çš„æ‰°åŠ¨å¹³ç§»èŒƒå›´ (ç±³) |
| `--target_width` | int | 640 | ç›®æ ‡å›¾åƒå®½åº¦ |
| `--target_height` | int | 360 | ç›®æ ‡å›¾åƒé«˜åº¦ |
| `--batch_size` | int | 8 | Batch size |
| `--max_batches` | int | 5 | æœ€å¤šè¯„ä¼°çš„batchæ•°ï¼ˆ0=å…¨éƒ¨ï¼Œ5=å¿«é€Ÿæµ‹è¯•ï¼‰|
| `--validate_sample_ratio` | float | 0.1 | éªŒè¯é›†æ¯”ä¾‹ï¼ˆ0.0-1.0ï¼‰|
| `--deformable` | int | 0 | æ˜¯å¦ä½¿ç”¨ deformable attention (ä¸Žè®­ç»ƒæ—¶ä¿æŒä¸€è‡´) |
| `--bev_encoder` | int | 1 | æ˜¯å¦ä½¿ç”¨ BEV encoder (ä¸Žè®­ç»ƒæ—¶ä¿æŒä¸€è‡´) |
| `--xyz_only` | int | 1 | æ˜¯å¦åªä½¿ç”¨ XYZ åæ ‡ (ä¸Žè®­ç»ƒæ—¶ä¿æŒä¸€è‡´) |
| `--vis_points` | int | 80000 | å¯è§†åŒ–çš„æœ€å¤§ç‚¹æ•° |
| `--vis_point_radius` | int | 1 | å¯è§†åŒ–ç‚¹çš„åŠå¾„ï¼ˆåƒç´ ï¼‰|

#### ä½¿ç”¨ç¤ºä¾‹

**åŸºç¡€ç”¨æ³•ï¼š**
```bash
python evaluate_checkpoint.py \
    --ckpt_path logs/model/checkpoint/ckpt_100.pth \
    --dataset_root ./data/custom_dataset \
    --angle_range_deg 20.0 \
    --trans_range 1.5
```

**è‡ªå®šä¹‰æ•°æ®é›†è¯„ä¼°ï¼ˆB26Aï¼‰ï¼š**
```bash
python evaluate_checkpoint.py \
    --ckpt_path logs/B26A_model_small_3deg_v6.5/checkpoint/ckpt_500.pth \
    --dataset_root /mnt/drtraining/user/dahailu/data/bevcalib/bevcalib_training_data_fix \
    --angle_range_deg 3.0 \
    --trans_range 0.15 \
    --target_width 640 \
    --target_height 360 \
    --batch_size 8 \
    --max_batches 10
```

**å¿«é€Ÿæµ‹è¯•ï¼ˆå°‘é‡æ ·æœ¬ï¼‰ï¼š**
```bash
python evaluate_checkpoint.py \
    --ckpt_path logs/model/checkpoint/ckpt_100.pth \
    --dataset_root ./dataset \
    --max_batches 2
```

**å®Œæ•´è¯„ä¼°ï¼ˆæ‰€æœ‰éªŒè¯é›†ï¼‰ï¼š**
```bash
python evaluate_checkpoint.py \
    --ckpt_path logs/model/checkpoint/ckpt_100.pth \
    --dataset_root ./dataset \
    --max_batches 0  # 0 è¡¨ç¤ºè¯„ä¼°å…¨éƒ¨
```

#### è¾“å‡ºç»“æžœ

è¯„ä¼°å®ŒæˆåŽä¼šåœ¨ checkpoint åŒçº§ç›®å½•ç”Ÿæˆè¯„ä¼°æ–‡ä»¶å¤¹ï¼š
```
logs/model/checkpoint/
â”œâ”€â”€ ckpt_100.pth
â””â”€â”€ ckpt_100_eval/                    # è¯„ä¼°ç»“æžœç›®å½•
    â”œâ”€â”€ sample_0000_projection.png    # å¯è§†åŒ–å›¾åƒï¼ˆ3åˆ—ï¼šInit/GT/Predï¼‰
    â”œâ”€â”€ sample_0001_projection.png
    â”œâ”€â”€ sample_0002_projection.png
    â”œâ”€â”€ ...
    â””â”€â”€ extrinsics_and_errors.txt     # è¯¦ç»†è¯¯å·®æŠ¥å‘Š
```

**extrinsics_and_errors.txt å†…å®¹ç¤ºä¾‹ï¼š**
```
Checkpoint: epoch_100
Evaluation on validation set (perturbation: 20.0deg, 1.5m)
================================================================================

Ground Truth Extrinsics (LiDAR â†’ Camera):
  ...4Ã—4 çŸ©é˜µ...

================================================================================

Sample 0000
--------------------------------------------------------------------------------

Predicted Extrinsics (LiDAR â†’ Camera):
  ...4Ã—4 çŸ©é˜µ...

Translation Errors (in LiDAR coordinate system):
  Total:   0.015234 m
  X (Fwd): 0.008123 m
  Y (Lat): 0.003456 m
  Z (Ht):  0.012890 m

Rotation Errors (axis-angle):
  Total:       0.234567 deg
  Roll (X):    0.123456 deg
  Pitch (Y):   0.089012 deg
  Yaw (Z):     0.178901 deg

================================================================================
...æ›´å¤šæ ·æœ¬...

================================================================================
AVERAGE ERRORS ACROSS ALL SAMPLES
================================================================================

Total samples evaluated: 40

Average Translation Errors (in LiDAR coordinate system):
  Total:   0.012345 Â± 0.006789 m
  X (Fwd): 0.007890 Â± 0.004321 m
  Y (Lat): 0.003210 Â± 0.001987 m
  Z (Ht):  0.010234 Â± 0.005678 m

Average Rotation Errors (axis-angle):
  Total:       0.198765 Â± 0.089012 deg
  Roll (X):    0.098765 Â± 0.045678 deg
  Pitch (Y):   0.067890 Â± 0.032109 deg
  Yaw (Z):     0.134567 Â± 0.056789 deg

================================================================================
```

#### ç»ˆç«¯è¾“å‡ºç¤ºä¾‹

```
================================================================================
è¯„ä¼° Checkpoint: logs/model/checkpoint/ckpt_100.pth
================================================================================

1. åŠ è½½æ¨¡åž‹é…ç½®...
   âœ“ ä»Ž checkpoint åŠ è½½å‚æ•°
   âœ“ è®­ç»ƒå™ªå£°: 20.0Â°, 1.5m
   âœ“ è¯„ä¼°å™ªå£°: 20.0Â°, 1.5m

2. åˆ›å»ºæ¨¡åž‹...
   âœ“ æ¨¡åž‹ç»“æž„: BEVCalib
   âœ“ Deformable Attention: å¦
   âœ“ BEV Encoder: æ˜¯

3. åŠ è½½æ•°æ®é›†...
   âœ“ è‡ªåŠ¨æ£€æµ‹åˆ° 1 ä¸ªåºåˆ—: ['00']
   âœ“ æ•°æ®é›†: 1234 ä¸ªæ ·æœ¬
   âœ“ éªŒè¯é›†: 123 ä¸ªæ ·æœ¬

4. å¼€å§‹è¯„ä¼°...
   è¾“å‡ºç›®å½•: logs/model/checkpoint/ckpt_100_eval
   æ‰°åŠ¨å‚æ•°: 20.0Â°, 1.5m
   
   å¤„ç†æ ·æœ¬ 0... âœ“ (Trans: 0.0152m, Rot: 0.23Â°)
   å¤„ç†æ ·æœ¬ 1... âœ“ (Trans: 0.0134m, Rot: 0.19Â°)
   å¤„ç†æ ·æœ¬ 2... âœ“ (Trans: 0.0167m, Rot: 0.28Â°)
   ...

5. è¯„ä¼°å®Œæˆï¼
   âœ“ æ€»æ ·æœ¬æ•°: 40
   âœ“ å¹³å‡å¹³ç§»è¯¯å·®: 0.0123 Â± 0.0068 m
   âœ“ å¹³å‡æ—‹è½¬è¯¯å·®: 0.199 Â± 0.089 deg
   âœ“ ç»“æžœå·²ä¿å­˜åˆ°: logs/model/checkpoint/ckpt_100_eval
   
================================================================================
```

#### æç¤ºä¸ŽæŠ€å·§

**1. å¿«é€Ÿæµ‹è¯• vs å®Œæ•´è¯„ä¼°**
```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆ2ä¸ªbatchï¼Œçº¦16ä¸ªæ ·æœ¬ï¼‰
--max_batches 2

# å®Œæ•´è¯„ä¼°ï¼ˆæ‰€æœ‰éªŒè¯é›†ï¼‰
--max_batches 0
```

**2. è°ƒæ•´æ‰°åŠ¨èŒƒå›´**
```bash
# å°æ‰°åŠ¨ï¼ˆç²¾åº¦æµ‹è¯•ï¼‰
--angle_range_deg 3.0 --trans_range 0.15

# å¤§æ‰°åŠ¨ï¼ˆé²æ£’æ€§æµ‹è¯•ï¼‰
--angle_range_deg 20.0 --trans_range 1.5
```

**3. æŸ¥çœ‹å¯è§†åŒ–ç»“æžœ**
```bash
# ä½¿ç”¨å›¾åƒæŸ¥çœ‹å™¨æ‰“å¼€
eog logs/model/checkpoint/ckpt_100_eval/sample_0000_projection.png

# æˆ–æ‰¹é‡æŸ¥çœ‹
cd logs/model/checkpoint/ckpt_100_eval
ls sample_*.png
```

**4. åˆ†æžè¯¯å·®æŠ¥å‘Š**
```bash
# æŸ¥çœ‹æ±‡æ€»ç»Ÿè®¡
tail -30 logs/model/checkpoint/ckpt_100_eval/extrinsics_and_errors.txt

# æŸ¥çœ‹å…·ä½“æ ·æœ¬
grep "Sample 0000" -A 30 logs/model/checkpoint/ckpt_100_eval/extrinsics_and_errors.txt
```

---

### inference_kitti.py å‚æ•°è¯´æ˜Ž

| å‚æ•° | ç±»åž‹ | é»˜è®¤å€¼ | è¯´æ˜Ž |
|------|------|--------|------|
| `--dataset_root` | str | å¿…å¡« | æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„ |
| `--ckpt_path` | str | å¿…å¡« | è®­ç»ƒå¥½çš„æ¨¡åž‹æ£€æŸ¥ç‚¹è·¯å¾„ |
| `--log_dir` | str | `./logs/inference` | æŽ¨ç†æ—¥å¿—ä¿å­˜ç›®å½• |
| `--batch_size` | int | 1 | æ‰¹é‡å¤§å° |
| `--xyz_only` | int | 1 | æ˜¯å¦åªä½¿ç”¨xyzåæ ‡ (1=æ˜¯, 0=å¦) |
| `--angle_range_deg` | float | 20.0 | æ‰°åŠ¨è§’åº¦èŒƒå›´ (åº¦) |
| `--trans_range` | float | 1.5 | æ‰°åŠ¨å¹³ç§»èŒƒå›´ (ç±³) |

### ä½¿ç”¨ç¤ºä¾‹

**è¯„ä¼° KITTI æ•°æ®é›†:**
```bash
python kitti-bev-calib/inference_kitti.py \
    --log_dir ./logs/inference \
    --dataset_root /path/to/kitti-odometry \
    --ckpt_path ./ckpt/kitti.pth \
    --angle_range_deg 20.0 \
    --trans_range 1.5 \
    --batch_size 16
```

**è¯„ä¼°è‡ªå®šä¹‰æ•°æ®é›† (B26A):**
```bash
# æŸ¥çœ‹å¯ç”¨çš„æ£€æŸ¥ç‚¹
ls ./logs/B26A_model_B26A_fix/B26A_scratch/checkpoint/

# ä½¿ç”¨æœ€æ–°çš„æ£€æŸ¥ç‚¹è¿›è¡Œè¯„ä¼°
python kitti-bev-calib/inference_kitti.py \
    --log_dir ./logs/inference_origin \
    --dataset_root /mnt/drtraining/user/dahailu/data/bevcalib/bevcalib_training_data_fix \
    --ckpt_path ./code/BEVCalib/logs/B26A_model_B26A_origin/B26A_scratch/checkpoint/ckpt_500.pth \
    --angle_range_deg 20.0 \
    --trans_range 1.5 \
    --batch_size 16
```

**å¿«é€ŸèŽ·å–æœ€æ–°æ£€æŸ¥ç‚¹å¹¶è¯„ä¼°:**
```bash
# æ‰¾åˆ°æœ€æ–°çš„æ£€æŸ¥ç‚¹
LATEST_CKPT=$(ls -t ./logs/B26A_model_*/*/checkpoint/ckpt_*.pth 2>/dev/null | head -1)
echo "Latest checkpoint: $LATEST_CKPT"

# è¿è¡Œè¯„ä¼°
python kitti-bev-calib/inference_kitti.py \
    --dataset_root /path/to/dataset \
    --ckpt_path $LATEST_CKPT
```

### è¾“å‡ºè¯´æ˜Ž

è¯„ä¼°å®ŒæˆåŽä¼šè¾“å‡ºä»¥ä¸‹æŒ‡æ ‡:
- **Translation Loss**: å¹³ç§»æŸå¤± (ç±³)
- **Rotation Loss**: æ—‹è½¬æŸå¤± (åº¦)
- **Translation xyz error**: X/Y/Z å„è½´å¹³ç§»è¯¯å·® (ç±³)
- **Rotation ypr error**: Yaw/Pitch/Roll å„è½´æ—‹è½¬è¯¯å·® (åº¦)

## Training

### Training on KITTI-Odometry
We provide instructions to reproduce our results on the KITTI-Odometry dataset:
```bash
python kitti-bev-calib/train_kitti.py \
        --log_dir ./logs/kitti \
        --dataset_root YOUR_PATH_TO_KITTI/kitti-odometry \
        --save_ckpt_per_epoches 40 \
        --num_epochs 500 \
        --label 20_1.5 \
        --angle_range_deg 20 \
        --trans_range 1.5 \
        --deformable 0 \
        --bev_encoder 1 \
        --batch_size 16 \
        --xyz_only 1 \
        --scheduler 1 \
        --lr 1e-4 \
        --step_size 80
```

### Training on Custom Dataset

**Quick Start (B26A Dataset):**
```bash
# Train from scratch (basic usage)
bash train_B26A.sh scratch > logs/train_B26A_scratch_$(date 
+%Y%m%d_%H%M%S).log 2>&1 &

# Train with specific GPU and TensorBoard port
nohup bash train_B26A.sh scratch --dataset_root /mnt/drtraining/user/dahailu/data/bevcalib/bevcalib_training_data --log_suffix B26A_origin --cuda_device 4 --tensorboard_port 6006  > logs/train_B26A_scratch_$(date +%Y%m%d_%H%M%S)_origin.log 2>&1 &

# train2
nohup bash train_B26A.sh scratch --dataset_root /mnt/drtraining/user/dahailu/data/bevcalib/bevcalib_training_data_fix --log_suffix B26A_fix --cuda_device 5 --tensorboard_port 6007  > logs/train_B26A_scratch_$(date +%Y%m%d_%H%M%S)_fix.log 2>&1 &

# train3
nohup bash train_B26A.sh scratch --dataset_root /mnt/drtraining/user/dahailu/data/bevcalib/bevcalib_training_data_fix --log_suffix B26A_opt --cuda_device 6 --tensorboard_port 6008  > logs/train_B26A_scratch_$(date +%Y%m%d_%H%M%S)_opt.log 2>&1 &

# train4 - scratch
nohup bash train_B26A.sh scratch --dataset_root /mnt/drtraining/user/dahailu/data/bevcalib/bevcalib_training_data_fix --log_suffix B26A_finetune --cuda_device 7 --tensorboard_port 6009  > logs/train_B26A_finetune_$(date +%Y%m%d_%H%M%S).log 2>&1 &

# stop trainnning 
pkill -9 -f "train_kitti.py" && pkill -9 -f "train_B26A.sh" 

# Train with custom dataset path and log suffix
bash train_B26A.sh scratch \
    --dataset_root /path/to/your/dataset \
    --cuda_device 0 \
    --log_suffix my_experiment

# Use tensorboard to monitor training
tensorboard --logdir ./logs/B26A_model --port 6006

# Fine-tune from KITTI pretrained model
bash train_B26A.sh finetune --cuda_device 0

# Resume from last checkpoint
bash train_B26A.sh resume --cuda_device 0
```

**ðŸš€ Multi-Terminal Parallel Training:**

The script now supports training multiple datasets in parallel across different terminals with automatic port and GPU management:

```bash
# Terminal 1: Train dataset1 on GPU 0
bash train_B26A.sh scratch \
    --cuda_device 0 \
    --dataset_root /path/to/dataset1 \
    --log_suffix dataset1 \
    --tensorboard_port 6006

# Terminal 2: Train dataset2 on GPU 1
bash train_B26A.sh scratch \
    --cuda_device 1 \
    --dataset_root /path/to/dataset2 \
    --log_suffix dataset2 \
    --tensorboard_port 6007

# Terminal 3: Fine-tune dataset3 on GPU 2
bash train_B26A.sh finetune \
    --cuda_device 2 \
    --dataset_root /path/to/dataset3 \
    --log_suffix dataset3 \
    --tensorboard_port 6008
```

**Script Options:**
- `--cuda_device ID`: Specify CUDA device ID (e.g., 0, 1, 2). If not specified, uses all available GPUs.
- `--tensorboard_port PORT`: Specify TensorBoard port (default: 6006, auto-increments if in use).
- `--dataset_root PATH`: Custom dataset root directory.
- `--log_suffix SUFFIX`: Add suffix to log directory (useful for distinguishing multiple runs).

**Features:**
- âœ… **Automatic port detection**: Finds available TensorBoard ports automatically
- âœ… **GPU isolation**: Each training instance can use a specific GPU
- âœ… **Log separation**: Use `--log_suffix` to keep logs organized
- âœ… **Port conflict detection**: Warns if specified port is already in use

**Manual Command:**
```bash
python kitti-bev-calib/train_kitti.py \
        --log_dir ./logs/custom_model \
        --dataset_root /home/ludahai/develop/data/eol/B26A_online/YR-B26A1-1_20251117_031232_lidar/bevcalib_training_data \
        --save_ckpt_per_epoches 20 \
        --num_epochs 100 \
        --label custom_20_1.5 \
        --angle_range_deg 20 \
        --trans_range 1.5 \
        --deformable 0 \
        --bev_encoder 1 \
        --batch_size 4 \
        --xyz_only 1 \
        --scheduler 1 \
        --lr 1e-4 \
        --step_size 40
```

**Parameter Recommendations for Custom Dataset:**
- `--batch_size`: 4-8 (smaller than KITTI due to potentially different data size)
- `--num_epochs`: 100-200 (adjust based on dataset size)
- `--save_ckpt_per_epoches`: 20-40 (save checkpoints more frequently)
- `--step_size`: 40-80 (learning rate decay step)
- `--lr`: 1e-4 (default learning rate)

**Fine-tuning from KITTI Pretrained Model:**
```bash
python kitti-bev-calib/train_kitti.py \
        --log_dir ./logs/custom_finetuned \
        --dataset_root /home/ludahai/develop/data/eol/B26A_online/YR-B26A1-1_20251117_031232_lidar/bevcalib_training_data \
        --pretrain_ckpt ./ckpt/kitti.pth \
        --num_epochs 50 \
        --batch_size 4 \
        --lr 5e-5
```

**Notes:**
- Change `--angle_range_deg` and `--trans_range` to train under different noise settings
- Use `--pretrain_ckpt` to load a pretrained model for fine-tuning
- The dataset loader automatically detects all sequences in the dataset
- For parallel training, ensure each terminal uses a different GPU (`--cuda_device`) and TensorBoard port (`--tensorboard_port`)
- Use `--log_suffix` to distinguish logs from different training runs

**ðŸ“š Documentation:**
- [TRAINING_GUIDE.md](TRAINING_GUIDE.md) - Detailed training parameters and recommendations
- [CUSTOM_DATASET_TRAINING.md](CUSTOM_DATASET_TRAINING.md) - Custom dataset preparation guide

## Acknowledgement
BEVCalib appreciates the following great open-source projects: [BEVFusion](https://github.com/mit-han-lab/bevfusion?tab=readme-ov-file), [LCCNet](https://github.com/IIPCVLAB/LCCNet), [LSS](https://github.com/nv-tlabs/lift-splat-shoot), [spconv](https://github.com/traveller59/spconv), and [Deformable Attention](https://github.com/lucidrains/deformable-attention).

## Citation
```
@inproceedings{bevcalib,
      title={BEVCALIB: LiDAR-Camera Calibration via Geometry-Guided Bird's-Eye View Representations}, 
      author={Weiduo Yuan and Jerry Li and Justin Yue and Divyank Shah and Konstantinos Karydis and Hang Qiu},
      booktitle={9th Annual Conference on Robot Learning},
      year={2025},
}
```
